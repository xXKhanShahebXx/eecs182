<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>EECS 182 - Special Participation Posts</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
            color: #333;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
        }

        header {
            text-align: center;
            color: white;
            margin-bottom: 40px;
            padding: 30px 0;
        }

        header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.2);
        }

        header p {
            font-size: 1.1em;
            opacity: 0.9;
        }

        .controls {
            background: white;
            padding: 20px;
            border-radius: 12px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            margin-bottom: 30px;
            display: flex;
            flex-wrap: wrap;
            gap: 15px;
            align-items: center;
        }

        .search-box {
            flex: 1;
            min-width: 200px;
        }

        .search-box input {
            width: 100%;
            padding: 12px 16px;
            border: 2px solid #e0e0e0;
            border-radius: 8px;
            font-size: 16px;
            transition: border-color 0.3s;
        }

        .search-box input:focus {
            outline: none;
            border-color: #667eea;
        }

        .tag-filter {
            display: flex;
            flex-wrap: wrap;
            gap: 8px;
            flex: 1;
        }

        .tag-button {
            padding: 8px 16px;
            background: #f0f0f0;
            border: 2px solid #e0e0e0;
            border-radius: 20px;
            cursor: pointer;
            font-size: 14px;
            transition: all 0.3s;
        }

        .tag-button:hover {
            background: #e0e0e0;
        }

        .tag-button.active {
            background: #667eea;
            color: white;
            border-color: #667eea;
        }

        .stats {
            color: #666;
            font-size: 14px;
            margin-left: auto;
        }

        .posts-grid {
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(350px, 1fr));
            gap: 25px;
            margin-bottom: 40px;
        }

        .post-card {
            background: white;
            border-radius: 12px;
            padding: 25px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            transition: transform 0.3s, box-shadow 0.3s;
            display: flex;
            flex-direction: column;
        }

        .post-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 8px 16px rgba(0,0,0,0.15);
        }

        .post-header {
            margin-bottom: 15px;
        }

        .post-title {
            font-size: 1.3em;
            font-weight: 600;
            color: #333;
            margin-bottom: 10px;
            line-height: 1.4;
        }

        .post-title a {
            color: inherit;
            text-decoration: none;
        }

        .post-title a:hover {
            color: #667eea;
        }

        .post-meta {
            display: flex;
            flex-wrap: wrap;
            gap: 15px;
            font-size: 0.9em;
            color: #666;
            margin-bottom: 15px;
        }

        .post-meta span {
            display: flex;
            align-items: center;
            gap: 5px;
        }

        .post-tags {
            display: flex;
            flex-wrap: wrap;
            gap: 6px;
            margin-bottom: 15px;
        }

        .tag {
            padding: 4px 10px;
            background: #f0f4ff;
            color: #667eea;
            border-radius: 12px;
            font-size: 0.85em;
            font-weight: 500;
        }

        .post-content {
            color: #555;
            line-height: 1.6;
            margin-bottom: 15px;
            flex: 1;
            overflow: hidden;
        }

        .post-content-preview {
            display: -webkit-box;
            -webkit-line-clamp: 4;
            -webkit-box-orient: vertical;
            overflow: hidden;
        }

        .post-resources {
            margin-top: 15px;
            padding-top: 15px;
            border-top: 1px solid #e0e0e0;
        }

        .post-resources h4 {
            font-size: 0.9em;
            color: #666;
            margin-bottom: 8px;
            font-weight: 600;
        }

        .resource-list {
            display: flex;
            flex-wrap: wrap;
            gap: 8px;
        }

        .resource-link {
            padding: 6px 12px;
            background: #f8f9fa;
            border: 1px solid #e0e0e0;
            border-radius: 6px;
            text-decoration: none;
            color: #667eea;
            font-size: 0.85em;
            transition: all 0.3s;
            display: inline-flex;
            align-items: center;
            gap: 5px;
        }

        .resource-link:hover {
            background: #667eea;
            color: white;
        }

        .expand-btn {
            margin-top: 10px;
            padding: 8px 16px;
            background: #667eea;
            color: white;
            border: none;
            border-radius: 6px;
            cursor: pointer;
            font-size: 0.9em;
            transition: background 0.3s;
        }

        .expand-btn:hover {
            background: #5568d3;
        }

        .loading {
            text-align: center;
            color: white;
            font-size: 1.2em;
            padding: 40px;
        }

        .no-results {
            text-align: center;
            color: white;
            font-size: 1.2em;
            padding: 40px;
            background: white;
            border-radius: 12px;
            color: #666;
        }

        @media (max-width: 768px) {
            .posts-grid {
                grid-template-columns: 1fr;
            }

            header h1 {
                font-size: 2em;
            }

            .controls {
                flex-direction: column;
            }

            .stats {
                margin-left: 0;
                width: 100%;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>EECS 182</h1>
            <p>Special Participation Posts</p>
        </header>

        <div class="controls" id="controls" style="display: none;">
            <div class="search-box">
                <input type="text" id="searchInput" placeholder="Search posts by title, author, or content...">
            </div>
            <div class="tag-filter" id="tagFilter"></div>
            <div class="stats" id="stats"></div>
        </div>

        <div id="loading" class="loading">Loading posts...</div>
        <div id="postsContainer" class="posts-grid"></div>
    </div>

    <script>
        const POSTS_DATA = [{"id": 7427798, "title": "Special Participation E: Visualizing LLM Decoding", "date": "2025-12-08T09:55:08.583548+11:00", "author": "Vijay Kethanaboyina", "content": "For this participation assignment, I created an interactive LLM Decoding Visualizer that demonstrates how Large Language Models (like GPT-3.5) generate text one token at a time. It allows you to experiment with inference-time parameters in real time to see how they affect the model output.Try it out for yourself here: https://www.vkethana.com/visualize_decode/A transcript of my conversation with the model can be found here: https://drive.google.com/file/d/1Ie75FGR4iAvZ4KIRmQxlilKTIGN9h1RR/view?usp=sharing. I used Cursor as my IDE for this assignment, and the actual model generations came from Gemini 3 Pro. The model performed well, and aside from a few edge cases it was able to one-shot all prompts I gave it.Class Concepts Covered:Inference-Time Sampling: Recall that there was a discussion worksheet that covered the various LM sampling techniques. This tool builds off that content.Greedy Decoding: You can see what happens when the model is forced to always pick the single most likely token (Temperature = 0). There is a special button in the tool allowing you to enable greedy decoding.Temperature & Top-P: It visualizes how \"temperature\" flattens the probability distribution (making the model more creative/random) or sharpens it (making it more deterministic). The tool also gives you control over the value of p used for top-p sampling.To use the interactive features, you'll need to provide your own OpenAI API key (due to inference costs, I am unable to host the model directly on my personal website). If you'd prefer not to use your API key, you're welcome to watch a video demo of the tool here: https://drive.google.com/file/d/1gGQwGiIx12-OZ_mrhktIW8nObmyv7dYb/view", "resources": [{"type": "link", "url": "https://www.vkethana.com/visualize_decode/", "name": "Link"}, {"type": "link", "url": "https://drive.google.com/file/d/1Ie75FGR4iAvZ4KIRmQxlilKTIGN9h1RR/view?usp=sharing", "name": "Link"}, {"type": "link", "url": "https://drive.google.com/file/d/1gGQwGiIx12-OZ_mrhktIW8nObmyv7dYb/view", "name": "Link"}, {"type": "link", "url": "https://www.vkethana.com/visualize_decode/A", "name": "Raw Text Link"}, {"type": "link", "url": "https://drive.google.com/file/d/1Ie75FGR4iAvZ4KIRmQxlilKTIGN9h1RR/view?usp=sharing.", "name": "Raw Text Link"}], "tags": ["Tool/App", "Coding", "Visualization", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7427798"}, {"id": 7427555, "title": "Special Participation E: Muon", "date": "2025-12-08T09:27:48.554248+11:00", "author": "Reyna Liu", "content": "For this Special Participation E, I made an interactive Muon tutor using a custom prompt for ChatGPT’s Study Mode. The goal was to turn Muon (Momentum Orthogonalized by Newton–Schulz) into a single coherent story that lines up with the lecture content: starting from Shampoo and semi-orthogonal updates, then moving through Newton–Schulz style iterations, odd polynomials, normalization, and finally the full Muon update rule.The tutor is designed to complement pre-lecture or post-lecture reading: instead of passively skimming notes, you interact with the model in a guided way, and it is forced (by the prompt) to:stay on one narrative arc (the “approximate (UV^\\top)” story),explain each subtopic with intuition → light math → tiny example → concept check,not move on until you answer its question.PromptYou are my tutor for the Muon optimizer (“Momentum Orthogonalized by Newton–Schulz”) and the optimization ideas behind it in modern deep learning.I want this to be an interactive tutoring session. In every reply:- Keep your answer focused and reasonably short (about 3–6 short paragraphs).- Do not move on to the next topic until I say so.- Always end your message by asking me a specific question (for example: “Does this make sense?” or a small concept-check question), and then wait for my reply.The overall story I want to learn is:How Muon approximates an “ideal” semi-orthogonal update direction (like what Shampoo would give with SVD), but does it cheaply using Newton–Schulz style iterations and polynomials that operate on singular values, plus a momentum-like accumulator.Please organize everything as one coherent narrative, not a bag of tricks.Step 1: Short big-picture introFirst response:1. In at most 2 short paragraphs, explain: - What problem Muon is trying to solve: - Shampoo-style methods want to precondition gradients using information like singular values / curvature, but exact SVD-based updates are too expensive. - We would like an update direction that behaves like “U Vᵀ” from an SVD, i.e., semi-orthogonal and not dominated by large singular values. - The core idea of Muon in one or two sentences: - Muon keeps a momentum-like running matrix, then repeatedly applies a simple polynomial transformation (a Newton–Schulz–style iteration) so that its singular values are pushed toward 1, approximating that semi-orthogonal “U Vᵀ” direction without doing a full SVD.2. Then give a brief roadmap (4–7 bullet points) of the main pieces of the story, all explicitly framed as supporting Muon, for example: - From “optimizer recipe” with a chosen norm to the idea of spectral norm and semi-orthogonal updates. - Shampoo and “Shampoo without accumulation” as the starting conceptual algorithm. - Why computing the exact SVD-based direction is too expensive, and why an approximate direction is good enough. - Newton–Schulz–style iterations as a way to adjust singular values toward 1. - Odd polynomials that operate on singular values while keeping singular vectors fixed, and why that matters. - Stability issues: why we need to normalize by something like the Frobenius norm so that singular values start in the right range and iterations don’t blow up. - The final Muon update: momentum buffer, orthogonalization via polynomial iterations, weight update, and how the choice of polynomial coefficients affects behavior.End your first reply by asking me one short question to check my high-level understanding.After I respond, start with the first item in the roadmap (semi-orthogonal / spectral-norm view). Follow the roadmap in order.Step 2: For each part of the storyWhen we are on a given part of the roadmap, teach it in four layers, but keep each message compact.1. Intuition tied to Muon - In 1–2 short paragraphs, explain the idea in plain language and explicitly say how it supports Muon’s overall goal: - Approximating a well-conditioned, semi-orthogonal update direction. - Making steps more uniform across directions instead of being dominated by the largest singular value. - Doing this without paying the full SVD cost.2. Key formal setup - Introduce only the minimal notation you need, such as: - A weight matrix and its gradient. - The idea that you can factor a matrix into singular vectors and singular values. - A momentum-like buffer that accumulates gradient information over time. - A simple iteration that applies a polynomial in the matrix (for example, a combination of a linear term and a cubic term) to reshape singular values. - Describe what each object means verbally (for example, “this buffer stores a smoothed version of recent gradients”, “this transformation tries to make all singular values close to 1 so the matrix behaves like a semi-orthogonal matrix”). - You may show a very small symbolic expression or a short iteration rule, but keep it high-level and do not dump long formulas.3. Tiny numerical or conceptual example - Give one very small example to illustrate the effect: - For instance, a 2×2 matrix whose singular values are very different, and describe qualitatively what happens when you apply one or two polynomial iterations to it (the large singular value goes down, the small one goes up, etc.). - Or a toy picture of “before” vs. “after” for singular values, and how that makes the update more uniform across directions. - Keep this example to a few lines.4. Quick understanding check - Ask me 1–2 short questions related to this part: - At least one conceptual “why” question (for example: “Why is it good if all singular values are close to 1?” or “Why do we want a polynomial that keeps singular vectors but changes singular values?”). - Optionally, a tiny computational or thought experiment question (for example: “What might go wrong if the singular values start out too large before applying the iteration?”). - Then stop and wait for my answer.After, briefly remind me what the next stop in the Muon story is, and then proceed.Step 3: Muon-centered wrap-upWhen I say I’m ready to review or summarize:- Give a compact summary that keeps Muon at the center, explaining how: - Starting from an “optimizer recipe” with a chosen norm leads to preferring semi-orthogonal directions (like U Vᵀ). - Shampoo (and its non-accumulating variant) motivates this direction but is too expensive if done with an exact SVD. - Newton–Schulz–style polynomial iterations let us approximate “replace all singular values by 1” using only matrix multiplications. - Normalizing by something like the Frobenius norm ensures the singular values start in a safe range so the iterations stay stable. - Muon wraps this into a practical algorithm: maintain a momentum buffer, apply a few iterations of a chosen polynomial to orthogonalize it, then use that to update the weights.Throughout the conversation, keep answers reasonably short, interactive, and always connected back to the central Muon story, so that the whole interaction feels like a focused tutoring session.Link to conversation:https://chatgpt.com/share/6933ad42-7bf4-8007-b500-f1bc59851beeAssessmentThe good:Conceptually, the model’s output is very close to the actual lecture storyline. It correctly emphasized:The role of (UV^\\top) as the “semi-orthogonal ideal” direction.The connection between Shampoo and this ideal (a hypothetical “Shampoo without accumulation” step).The idea that Newton–Schulz–like odd polynomials act as scalar functions on singular values, while preserving the singular vectors.The importance of normalizing the buffer so the polynomial iteration doesn’t blow up or collapse.I didn’t spot any major conceptual contradictions with the lecture. The main approximations were in the toy numerical examples (e.g., saying a singular value might move from 0.01 to “something like 0.2-0.5” after one step without actually computing it). That’s not “wrong” in a dangerous way, but it’s clearly hand-wavy.The bad:Repetitive concept checks.It kept asking essentially the same question in slightly different forms: “Why is it good if singular values are close to 1?” “Why do we want a well-conditioned update?” “Why is it useful that singular vectors stay the same?”These questions are reasonable the first time; by the third time, it felt redundant and didn’t add new understanding.Hand-wavy numbers in examples.In a few places it invented specific numeric values like “after one step this might be around 0.2-0.5” without actually computing the polynomial. This is minor, but it’s a reminder: whenever it gives specific numbers in these toy examples, treat them as qualitative (direction of change) rather than precise quantitative claims.Behavior when the user can’t really answer its questions.The prompt forces it to ask me a “concept check” every turn, but it doesn’t actually check my answers or detect if I’m confused. In our interaction it basically replied “Exactly” to everything and then continued. So if a student can’t answer, or answers something half-baked, the model will not push back on its own. The student has to explicitly tell the model to explain. It’s too “polite”to be a real grader for students.Overall, though, the interaction did not hallucinate big structural facts. The misbehavior was more minor.How this could help with learningIn practice, this tool works well as a pre- or post-lecture companion:Before the lecture, we can run through Part 1-3 to get the high-level picture of “why semi-orthogonal,” “how Shampoo motivates the ideal,” and “why approximate is enough,” so we’re not seeing those ideas for the first time in class.After the lecture, we can use Parts 4-7 to re-derive the Newton–Schulz connection, the odd polynomial behavior, the normalization step, and the final Muon update rule, while the model keeps quizzing us.It can function as a self-paced interactive reading that is much closer to our actual lecture content than a random internet explanation. The main caveats are:Be aware it may ask very similar concept checks multiple times.Treat any made-up numbers in the tiny examples as qualitative intuition, not exact math.Remember it doesn’t really grade your answers. If you’re lost, you need to tell it explicitly to slow down or re-explain.Use it to structure understanding, but verify key equations and details against the lecture itself if you care about full rigor.", "resources": [{"type": "link", "url": "https://chatgpt.com/share/6933ad42-7bf4-8007-b500-f1bc59851bee", "name": "Link"}, {"type": "link", "url": "https://chatgpt.com/share/6933ad42-7bf4-8007-b500-f1bc59851beeAssessmentThe", "name": "Raw Text Link"}], "tags": ["Tool/App", "Study Guide", "Visualization", "Prompt Eng", "Tutor", "Quiz/Drill"], "original_url": "https://edstem.org/us/courses/84647/discussion/7427555"}, {"id": 7427549, "title": "Special Participation E: µP", "date": "2025-12-08T09:27:00.068242+11:00", "author": "Reyna Liu", "content": "I designed a prompt that turns ChatGPT’s Study Mode into an interactive tutor for the maximal update parameterization (µP) lecture.The goal is to replace a passive pre-lecture/post-lecture reading with an active dialogue that walks through the µP story in order:why µP was introduced,how norms and RMS–RMS–style measures are used to control update size,how the outer-product structure of linear-layer gradients simplifies the math,how sign-based updates and width scaling affect update norms,how CLT-style scaling motivates the parameterization,and how all of this connects to feature learning vs. lazy training.The prompt enforces short, interactive replies and forces the model to keep µP as the central theme, instead of dumping a long wall of text.PromptYou are my tutor for maximal update parameterization (µP) and the optimization ideas around it in modern deep learning.I want this to be an interactive tutoring session. In every reply:- Keep your answer focused and reasonably short (roughly 3–6 short paragraphs or equivalent).- Do not move on to the next topic until I say so.- Always end your message by asking me a specific question (for example: “Does this make sense?” or a small concept-check question), and then wait for my reply.The overall story I want to learn is:How µP is designed so that neural networks of different widths have comparable update behavior, and how all the surrounding concepts (norms, the simple outer-product structure of gradients in linear layers, sign-based updates, learning-rate scaling, CLT-style scaling analogy, and feature-learning conditions) fit into this one story.Please organize the material around µP as one coherent narrative, rather than separate tricks.Step 1: Very short big-picture introFirst response:- In at most 2 short paragraphs, explain: - What problem µP is trying to solve (e.g., transferring learning rates from small to large models, making training behavior less sensitive to width). - The core idea in one or two sentences (e.g., keeping effective update magnitudes comparable across widths).- Then give a brief roadmap (4–7 bullet points) of the main pieces of the story, all explicitly framed as supporting µP, for example: - Controlling update size via norms. - RMS–RMS-type norms to measure update size across layers. - Using the outer-product (rank-1 for batch size 1) structure of linear-layer gradients as a simple tool to analyze norms and update sizes. - How sign-based updates interact with these norms. - Learning-rate scaling with width (fan-in / fan-out) and how µP encodes this. - CLT-style scaling intuition for width limits. - Feature-learning conditions in wide networks and how µP targets them.- End your first reply by asking me one short question to check my high-level understanding. In your next reply (after I respond), start with the first item in the roadmap (controlling update size via norms). Do not ask me to choose the order; follow the roadmap in order.Step 2: For each part of the storyWhen we are on a given part of the roadmap (for example “RMS–RMS norms and update size”, “outer-product gradient structure as a tool”, “learning-rate scaling with width”, or “feature-learning conditions”), teach it in four layers, but keep each message compact:1. Intuition tied to µP - In 1–2 short paragraphs, explain the idea in plain language and explicitly say how it supports the overall µP goal (making updates comparable across widths / keeping training behavior width-stable / enabling feature learning at large width).2. Key formal setup and equations - Introduce the simplest useful mathematical setup: weight matrix W, input x, gradient ∇_W L, layer width, fan-in, fan-out, etc. - State the most relevant equations, such as: - The gradient of a linear layer for a single example having an outer-product form g x^T (rank-1), used mainly as a convenient way to analyze its norms and scaling. - A reasonable way to measure update size (e.g., some RMS-style norm). - A simple example of how learning rate might scale with width or fan-in/fan-out to keep that update size roughly constant. - When appropriate, express conditions like “activations h_\\ell stay O(1)” and “updates \\Delta h_\\ell stay O(1) as width grows”, and link that to constraints on \\|W_\\ell\\| and \\|\\Delta W_\\ell\\|. - Explain the meaning of each symbol in words.3. Tiny numerical example - Give one small concrete example with simple numbers (e.g., a 2×3 layer, or doubling the width) to show what changes and how a scaling rule helps keep updates comparable. - Keep this to a few lines.4. Quick understanding check - Ask me 1–2 short questions related to this part: - At least one conceptual (“why”) question. - Optionally one small calculation (e.g., rank of a gradient matrix, or what happens to update size when width doubles without scaling the learning rate). - Then stop and wait for my answer, instead of answering your own questions.When I indicate that I am done with the current part and ready to move on, proceed to the next item in the roadmap in order, briefly reminding me which part comes next in the µP story.Step 3: µP-centered wrap-upWhen I say I’m ready to review or summarize:- Give a compact summary that keeps µP at the center, explaining how: - Norms and RMS–RMS-like measures define what it means for updates to be “the same size” across widths. - The simple outer-product structure of gradients makes it easy to relate different norms and see how update size scales with width. - µP encodes scaling rules so that small and large models see comparable effective updates. - Feature-learning conditions on h_\\ell and \\Delta h_\\ell motivate µP’s design choices.- Propose a small set of practice questions (both conceptual and short derivations) that someone could solve to check their understanding of µP and the surrounding ideas.- Then stop and wait for my answer, instead of answering your own questions.Throughout the conversation, keep answers reasonably short, interactive, and always connected back to the central µP story, so that the whole interaction feels like a focused tutoring session.Link to Conversationhttps://chatgpt.com/share/6933311c-d9fc-8007-bfb6-35c5f7ee8a1aInteractionMotivation for µPThe answer matches the lecture well. The lecture explicitly motivates µP as a way to choose the “right units” and scaling so that the same hyperparameters work at different widths, and we can search on small models and transfer to large ones. The AI also adds a nice refinement: hyperparameters transfer because effective updates have comparable size. That’s clearly aligned with the RMS–RMS induced norm idea from class.Frobenius normThe high-level contrast is good: Frobenius norm grows with number of parameters, while RMS is more “width-invariant”. The lecture also emphasizes using an RMS–RMS induced norm instead of a raw spectral/Frobenius norm so we can have a single scalar that behaves well across layers and widths.But the numerical language is sloppy: “double the width and the Frobenius norm doubles” is not generally true. In the typical i.i.d. setup, the Frobenius norm grows like (number of parameters)^(0.5), not linearly. Also, compared to the lecture, the AI never explicitly mentions that we’re using RMS-RMS as an induced norm that upper-bounds the spectral norm and gives layer-specific effective step sizes. That’s an important part of the lecture that’s missing here.Effective update sizeThis is basically what the lecture is implicitly using when it talks about RMS–RMS induced norms. The lecture goes through induced norms / sub-multiplicativity, whereas the AI jumps straight to this “product of RMS” heuristic.However, it never connects back to the more formal induced-norm inequality we actually saw in class. The formal induced-norm framing is missing.Outer-product / low-rank gradient structureThis is the key observation: the RMS gradient does not depend on width at all. The outer-product formula is exactly what was derived in the lecture.The algebra for Frobenius and RMS norms is basically correct, but it is not exactly the argument in the lecture. In class, the rank-1 structure is mainly used to say rank-1 ⇒ spectral norm = Frobenius norm, which makes it easy to relate the sign matrix S and its norms, and to design a step size for signSGD/Adam that keeps the RMS-RMS fixed.The AI instead focuses on RMS(∇W) being width-independent, which is a reasonable extrapolation but not literally what is emphasized in the lecture.Sign-based updatesThe AI is vaguely aligned with the idea of signSGD, but it stays very high-level, and doesn’t connect sign-based updates back to the RMS–RMS induced norm recipe. Not hallucinating, but also not actually teaching the signSGD part of the lecture.Learning-rate scaling with widthIt’s qualitatively right that learning-rate must depend on fan-in, but the ‘1/d_in’ rule is presented as a universal principle, which is not justified from the lecture notes or the original µP paper.CLT analogyThis is very close to what happens in the lecture. It explicitly recalls the CLT, shows how a scaling factor keeps the limit non-trivial, and then asks if we can do something similar for neural nets / hyperparameters. The derivation is correct and is a nice concrete restatement of Xavier-style reasoning.Feature-learningThis matches the spirit of the “conditions for feature learning” notes in the lecture. The AI brings in NTK/lazy-training terminology, which is consistent with the broader literature and explains why those O(1) conditions matter.Overall storyThis is a nice high-level summary, and aligns with several concrete lines in the notes:Hyperparameter transfer from small to large models.Choosing the right “units” / parameterization to make that possible.Conditions for feature learning expressed as O(1) constraints.Overall assessmentWhat it does well:Keeps the µP story coherent.Repeats several key ideas: hyperparameter transfer, O(1) activations/updates, width-stable dynamics.The outer-product derivation of RMS(∇W) are correct and and the CLT variance argument is helpful for intuition.What it doesn’t do well:Quantitative statements about norm scaling (e.g., “Frobenius norm doubles”) are sloppy and should be re-derived.The treatment of learning-rate scaling is oversimplified. It presents “learning rate ∝ 1/d_in” as a universal µP rule without actually deriving it.How I would use it:I’d use this AI tutor as a conceptual organizer. If I forget the big picture of why µP exists or how CLT and O(1) conditions fit together, this is a good interactive refresher.I would not rely on it for precise hyperparameter scaling formulas or optimizer details; those need to be checked against the actual lecture notes and/or the Yang 2022 µP paper.", "resources": [{"type": "link", "url": "https://chatgpt.com/share/6933311c-d9fc-8007-bfb6-35c5f7ee8a1a", "name": "Link"}, {"type": "link", "url": "https://chatgpt.com/share/6933311c-d9fc-8007-bfb6-35c5f7ee8a1aInteractionMotivation", "name": "Raw Text Link"}], "tags": ["Tool/App", "Coding", "Study Guide", "Visualization", "Prompt Eng", "Tutor", "Math"], "original_url": "https://edstem.org/us/courses/84647/discussion/7427549"}, {"id": 7427489, "title": "Special Participation E: Learning Optimization by spotting mistakes in AI generated answers with a custom Gemini Gem", "date": "2025-12-08T09:20:15.432576+11:00", "author": "Imra Dawoodani", "content": "I built a custom Gemini gem that teaches optimization concepts by intentionally giving you flawed explanations and guiding you to catch the errors. I'm sharing two versions of the Gem (structured and conversational) plus annotated transcripts showing what worked, what didn't, and where the AI made mistakes I had to catch. I made V2 after I played around with V1 and wasn't satisfied with the learning outcome it produced.V1: https://gemini.google.com/gem/1nODd0rYIHnHOMosLrhdSIuoGBRyAieKL?usp=sharingV2: https://gemini.google.com/gem/1osRvc6_mQ1ntQd8hjq7QxOmL38ftyJAT?usp=sharingAnnotated V1 transcripts:Annotated V2 transcript:My observations:", "resources": [{"type": "link", "url": "https://gemini.google.com/gem/1nODd0rYIHnHOMosLrhdSIuoGBRyAieKL?usp=sharing", "name": "Link"}, {"type": "link", "url": "https://gemini.google.com/gem/1osRvc6_mQ1ntQd8hjq7QxOmL38ftyJAT?usp=sharing", "name": "Link"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/fyOdPjYRKh3cZF6KYQDYd08c", "name": "gemini.google.com-Google Gemini-fpscreenshot (1).pdf"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/Qu9hv9enrHjqIf6V4pgueUeL", "name": "gemini.google.com-Google Gemini-fpscreenshot.pdf"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/ZbC4dXX9mfccdFiA8Eb90zvj", "name": "gemini.google.com-Google Gemini-fpscreenshot (2).pdf"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/XTToFU3qMCqp32fDN5IUZ7kf", "name": "special participation E - mistaker.pdf"}, {"type": "link", "url": "https://gemini.google.com/gem/1nODd0rYIHnHOMosLrhdSIuoGBRyAieKL?usp=sharingV2:", "name": "Raw Text Link"}, {"type": "link", "url": "https://gemini.google.com/gem/1osRvc6_mQ1ntQd8hjq7QxOmL38ftyJAT?usp=sharingAnnotated", "name": "Raw Text Link"}], "tags": [], "original_url": "https://edstem.org/us/courses/84647/discussion/7427489"}, {"id": 7427394, "title": "Special Participation E: HW0 Prerequisite Content Helper", "date": "2025-12-08T09:09:50.529973+11:00", "author": "Carolyn Liu", "content": "I used the ChatGPT 5.1 Thinking model under study mode to help go over pre-requisite content found in Homework 0. I told the model that they are a helper and the goal is to refresh the content found in homework 0 but now actually solve any of the problems. The first thing the model did was ask how comfortable I was with the pre-requisite content, which I appreciated since it tailored the difficulty of the questions from it. Afterwards, they kept on asking questions and explained why some of my answers were incorrect. I believe this is a good prompt to help students with the linear algebra content and basic ML concepts before diving into Homework 0.I have attached my conversation and also a good starting prompt for this below:", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/PTDDF0LMrJFrducr1IRuyFDG", "name": "Special Participation E_ HW0 Prerequisite Content Helper.pdf"}], "tags": ["Tool/App", "Math", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7427394"}, {"id": 7427288, "title": "Special Participation E: AI-Generated Quiz Tool for lectures", "date": "2025-12-08T08:57:19.086591+11:00", "author": "Jerry Xiao", "content": "Hi everyone,For the AI learning-tools option, I built a small quiz-generator assistant that can help generate exam-style question for you to test your understanding on specific field. I use ChatGPT 5.1 to interact with and use the Project functions to help me generate the problem sets.Here is a short, simple, clean Ed post for your second interaction (the Diffusion quiz generator). This version is minimal and directly hits the assignment requirements.1. Prompt I want you to become a quiz generator for me to evaluate my learning progress. \nI want you to generate questions on Generative Model like Diffusion. \nPlease follow the style of the second file to generate the problems. \n[Append lecture note and example question here]Then I asked questions as:“Generate Quiz Set 1.”“Give me solutions.”“Generate Set 2.”“Draw a picture comparing DDPM and DDIM.”2. What it do goodIt matched the HW format surprisingly well (short structured questions).The explanations were clear and aligned with the lecture.The DDPM vs DDIM diagram was helpful for intuition.3. What it do badSometimes it added extra comments not in the lecture.It was a bit too confident in referencing lecture page numbers.Sketches were descriptive, not actual images (which is fine for learning but not literal HW format).You can use this way to quiz yourself before homework/exams, get practice problems instantly, ask for more sets at different difficulty levels.", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/tesuegU502lGWS0leYQGdy7X", "name": "gpt_interaction_2.pdf"}], "tags": ["Tool/App", "Quiz/Drill", "Visualization", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7427288"}, {"id": 7427284, "title": "[WIP] Special Participation E: Homework Checker and Mistake Summarizer", "date": "2025-12-08T08:56:47.517833+11:00", "author": "Joshua Lu", "content": "When going over homework, one of the most important things to do is to list out all the mistakes and make sure not to do that again. For this special participation, I'm working on creating a pipeline to 1) check the homework and make a list of things that are wrong and 2) make a summary of the mistakes and a list of potential reminders and what to be careful of. I used to do this manually when studying for finals in the past, so I think trying this out with an LLM would be very interesting.", "resources": [], "tags": ["Study Guide"], "original_url": "https://edstem.org/us/courses/84647/discussion/7427284"}, {"id": 7427268, "title": "Special Participation E: Multi-Level Discussion Summarizer and Key Notes Extractor with Gemini 3 Pro", "date": "2025-12-08T08:54:18.005087+11:00", "author": "Joshua Lu", "content": "I always want to make sure that I have all my notes in one place, and one additional source of very useful information is the Discussion. Discussion covers a lot of content, some of them being new content as well, and the information covered in discussion definitely belongs in the notes. For this special participation, I will specifically be working with Discussion 10 (Transformers). The goal of this special participation is to extract the key concepts from the discussion worksheet in note form, but with a twist: The notes should have two section, a main key concepts section and a second deep-dive section. This summary should include details that go beyond what can be found in the discussion and should be a comprehensive review guide.I used Gemini 3 Pro (With Thinking) for this special participation. My process is the following: to start off, I gave the model a simple prompt with my goal:\"Summarize the key learning concepts in Discussion 10 on Transformers. Provide the key learning concepts in bullet-point form. Make sure to emphasize what is important to know. This first part should be more general, main ideas.Then, make a second section where you go deeper into each concept and again provide a list of the key details.\"Through this, the model gave a basic summary which was not detailed enough. Then, through an iterative process, I improved the summary of the discussion by asking the model about specific details that comes from the discussion. For Discussion 10 specifically, this included the math for RoPE and the complexity derivations for self-attention and cross-attention. After a few iterations, the model learned about the specific types of details I was looking for and at the end, I asked it to regenerate the summary in a form I can paste into my notes. It's clear from my experiment that the model cannot easily one-shot a good enough summary for me to use, so repeated prompting is necessary to get something useful.The good part about this model was that it generally got everything correct. Since the goal is to summarize and review information, it did not hallucinate, and I verified the information looks good. However, one issue of using the chat interface is that the formatting isn't great. Each time I want a new summary, the model has to regenerate it entirely, and the chat log gets very messy.After I got my summary, I then had the model look through the homework and indicate which concepts I should already know based on the discussion, and which concepts I should review in preparation for the homework. This multi-level summary is very useful for me to not just look back later on to review important information from discussion but also help me prepare to do the homework in a setting where I don't need to constantly refer back to notes.Here is the trace without annotations: https://gemini.google.com/share/5db1aec72092Here is the trace with annotations: https://drive.google.com/file/d/18umCOjsk8ATIR5HsZQKgECIUwoOZNbE7/view?usp=sharing", "resources": [{"type": "link", "url": "https://gemini.google.com/share/5db1aec72092", "name": "Link"}, {"type": "link", "url": "https://drive.google.com/file/d/18umCOjsk8ATIR5HsZQKgECIUwoOZNbE7/view?usp=sharing", "name": "Link"}, {"type": "link", "url": "https://gemini.google.com/share/5db1aec72092Here", "name": "Raw Text Link"}], "tags": ["Tool/App", "Math", "Study Guide", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7427268"}, {"id": 7427197, "title": "Special Participation E: Minimally Wrong MCQ Diagnostic Learning Tool", "date": "2025-12-08T08:45:57.134051+11:00", "author": "William Li", "content": "In this special participation, I create a prompt and test how ChatGPT can generate multiple choice questions with “distractor” answers that are minimally wrong. This is meant to emulate what I typically found most difficult in MCQ questions, which is when all the wrong answers seem plausible and can only be discerned as wrong by identifying subtle mistakes. To this end, I wanted to try to use LLMs to generate these sorts of questions. Additionally, perhaps the hallucinations that these LLMs so often generate could be useful in creating wrong answers that sound correct.Upon testing out this prompt and studying technique, I was very satisfied with what the model was able to give me. I asked it several questions spanning different topics (optimization, attention, transformers etc.) along with different modalities (purely conceptual, mathematical, coding), and it was able to give me very succinct MCQs for these. The answer choices it generated were also very good, and it was quite tricky choosing between the answers sometimes. After answering (and getting the question right or wrong), the model was able to give me the reasonings behind each of the answers. For the correct answer, it gave the reasons as to why it is correct, and for the incorrect answers it explained the subtle bug or misconception that led to the error. Overall, I think this was a good learning experience and I would certainly use this to study more concepts before the final rolls around. Annotated Trace:", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/sSdCgJfEzSRTNZULjaXMxeod", "name": "mcq (1).pdf"}], "tags": ["Tool/App", "Quiz/Drill", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7427197"}, {"id": 7426890, "title": "Special Participation E: AI Learning Tool using ChatGPT Projects", "date": "2025-12-08T08:04:57.739288+11:00", "author": "Jerry Xiao", "content": "I use the Projects in the ChatGPT 5.1 to help me create a personal study assistant. I used it to help review Lecture 25 (RLVR, sampling from p(x)α, MCMC acceptance ratio, and the RLVR loss). I’m sharing it here along with a short interaction trace and a few comments on where it worked well or got things wrong. 1. How to startHere is the prompt I used at the beginning: Hi you will be my guys for reviewing and recapping my Deep Learning Class. I want to first understand the concept of RLVR: Reinforcement Learning with Verifiable Rewards. Can you help me elaborate on them based on the lecture notes? [I append the lecture notes behind so that it can help me with the content in the class]2. What is goodFrom my interaction trace (see attached file): It gave very clear explanations of why sampling from (p(x)^\\alpha) cannot be done with temperature. Its explanation of the MCMC acceptance ratio was correct and matched the lecture. The summary of the RLVR figures was helpful for understanding the “why RLVR scales” story. The explanation of the RLVR loss (reward clipping, stop-gradient) was accurate and easy to understand.3. What is not goodSometimes it claimed specific page numbers or wording from the lecture that weren’t literally present.It occasionally added extra reasoning (e.g., “reward model overfitting”) that wasn’t explicitly in the slide.Some explanations were too confident even when extrapolating beyond the notes.Overall, it was very useful for learning the concepts as long as I double-checked details against the lecture notes.This acts like an interactive pre-lecture or review guide—instead of re-reading slides alone, the AI helps clarify the math, the intuition, and the purpose of each RLVR component.", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/sETCJFNG2037d1jbeXxOoNoM", "name": "gpt_interaction_1.pdf"}], "tags": ["Tool/App", "Study Guide", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7426890"}, {"id": 7426886, "title": "Special Participation E: Studying Optimizers with NotebookLM", "date": "2025-12-08T08:04:24.974898+11:00", "author": "Nikhil Mathihalli", "content": "For the \"AI-enhanced learning tools\" option, I explored NotebookLM to study the recent lectures on Optimizers. My goal was to create an active alternative to traditional pre-reading/post-reading by having the AI synthesize the lecture recordings, notes, and homework solutions into a cohesive study guide.I uploaded the YouTube lecture audio recordings alongside the raw lecture notes. NotebookLM was able to \"listen\" to the lectures and cross-reference them with the written notes.One of the coolest features was generating visual aids to structure my learning before diving into the weeds.The Mind Map: I asked it to generate a mind map immediately1. This gave me a hierarchy of concepts—linking Taylor Expansions to Lazy Training, and Initialization to RMS Norms—which acted as a roadmap for what questions I needed to ask.The Slideshow: I asked it to create a slideshow explaining optimizer concepts with visuals. It generated a dense, informed presentation in about 5 minutes. While the visuals were AI-generated, the structure helped me verify if I could explain the concepts linearly.3. How to Ask \"Good\" Questions (Prompting Strategy)Through trial and error, I found a \"Drill-Down\" strategy worked best:Start Broad: I began with, \"Can you give me an overview of ALL the concepts... generate a roadmap\". This forced the model to establish context.Select & Zoom: Instead of letting it ramble, I picked specific nodes from its roadmap: \"Let's start with the lazy training assumption. What is it, and why is it important?\"Comparative Analysis: For distinct lists, I asked for comparative breakdowns: \"Can you go over every initialization... advantages/disadvantages to each?\" This yielded structured tables rather than walls of text.While the high-level summaries were coherent, the model often flattened subtle mathematical distinctions. I have annotated these in the attached PDF, but here are the key warnings:Oversimplifications: The model correctly identified that parameters move by small amounts in training, but it implied that gradient features are fixed features simply because of the assumption. It failed to clarify that this is a specific regime (Kernel/NTK) and not how realistic modern \"feature learning\" regimes workBias Initialization Depth: The model listed strategies like \"initialize at 0\" or \"0.01\" but completely lacked the reasoning for why (e.g., why zero bias doesn't cause symmetry issues like zero weights do)Missing Geometric Intuition: When explaining algorithms like SignSGD, it gave the formula but missed the geometric intuition (that infinity norm constraints lead to coordinate-wise updates)ConclusionNotebookLM is a powerful \"active reading\" partner, especially for synthesizing multimodal sources (audio + text). However, it struggles with the deep \"why\" behind some mathematical proofs. Overall, I think it's extremely useful for learning large amounts of content in a structured yet quick manner.Trace:", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/QFrg7pTp21fLlcSlbWOR77fQ", "name": "NotebookLM Chat.pdf"}], "tags": ["Tool/App", "Study Guide", "Visualization", "Prompt Eng", "Quiz/Drill", "Math"], "original_url": "https://edstem.org/us/courses/84647/discussion/7426886"}, {"id": 7426845, "title": "Special Participation E: ChatGPT 5.1 Thinking Study Mode on LoRA", "date": "2025-12-08T07:58:50.489794+11:00", "author": "Carolyn Liu", "content": "I used the ChatGPT 5.1 Thinking model under the study mode to have it go over LoRA before I start the homework assignment. It did a good job going over the contents within the lecture and asked questions to ensure my understanding. Under study mode, it continues to ask me questions that are directly related to what was taught in lecture without needing reminders or any prompting that I am studying before completing a homework assignment. I would say the model does a good job at proposing questions that solidify basic understanding but does not increase in difficulty to be like a homework or discussion problem. However, it is able to adapt questions based on how well the user understands the content.I also gave the same starting responses to the ChatGPT 5.1 Thinking model without study mode. While it did give a few questions, it was less interactive and only listed a few questions in the end after going over the lecture content. Instead of asking for an answer to the questions, it states that if the user has any more questions, they can respond.For studying the content, using the model under study mode provides a more interactive experience by continuously asking questions and adapting to how well the user understands the content. However, the regular model is suitable for covering all the content in the lecture.Below is an annotated version of the conversations I had with both models:", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/yYHjwnDCT893e59r2azDoiPT", "name": "Special Participation E_ ChatGPT LoRA Learning.pdf"}], "tags": ["Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7426845"}, {"id": 7426644, "title": "Special Participation E: GPT diagonistic quiz generator for lectures", "date": "2025-12-08T07:31:09.895587+11:00", "author": "Ruihan Xia", "content": "I wanted to design a self-quiz generator I can use to test how well I understand the knowledge learned after lecture. To do this, I uploaded lecture notes and wrote a prompt that asks Chat GPT to produce 5 conceptual questions from a lecture section, each with an answer, a quick intuition, a formal reasoning layer, and an explicit assumption check.In the chat with example of lecture 6 & 7, ChatGPT outputed conceptal questions covering RMS norms, maximal update parametrization, spectral-norm-constrained updates, Muon optimizer, and Newton–Schulz iteration. I then asked for related computational examples that involve concrete math and applications to standard problems like linear regression. However, I noticed a few issues. Several explanations essentially copied equations from the lecture slides (e.g., the RMS→RMS norm formula, the Muon spectral-norm optimization step). I think a bit more derivation would be helpful. There are some vague leaps in response as well. In general Chatgpt outputs answers that are more on the conceptual side unless I ask for explicit math.", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/1ybzCcd297wvzg3FnuxiPneI", "name": "AI diagnostic quiz.pdf"}], "tags": ["Tool/App", "Study Guide", "Prompt Eng", "Math", "Quiz/Drill"], "original_url": "https://edstem.org/us/courses/84647/discussion/7426644"}, {"id": 7426411, "title": "Special Participation E: Claude Sonnet 4.5 on Diffusion Models", "date": "2025-12-08T06:58:46.886153+11:00", "author": "Jin Ying", "content": "I created a Socratic dialogue tool using Claude to learn diffusion models. I gave it our lecture slides; instead of asking it to summarize slides, I explicitly told it to ask me one question at a time, ignore lecture materials temporarily so I can return to it to test my understanding after the conversation, and focus on building intuition rather than explaining formulas.Claude helped build intuition before introducing math, handled my confusion productively, and when I gave wrong answers it showed me why my reasoning was incomplete. However, it made several technical oversimplifications that need verification, which I annotated in our conversation.I found it helpful to spend an hour in Socratic dialogue to build intuition and test myself to see if I only understand something partially, annotate anything that seems off, and then verify against what we've learned in lectures and the textbook. This helped me go from memorizing and taking what we learned in the class for granted to actually understanding concepts deeper. But it's not a replacement for rigorous study; I still need to work through derivations and implementations myself to achieve a real understanding.", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/JX86S4sPR4eF5GEeYVpRULOp", "name": "Diffusion Models with Claude.pdf"}], "tags": ["Tool/App", "Coding", "Math", "Tutor"], "original_url": "https://edstem.org/us/courses/84647/discussion/7426411"}, {"id": 7425579, "title": "Special Participation E: Module Review Generator with Multi-Source Integration", "date": "2025-12-08T04:40:18.366087+11:00", "author": "Moxin Tang", "content": "I extended Jameson's lecture notes generator #301 to create a comprehensive module review tool.Building on the original script's approach of using lecture transcripts + slides with Gemini API, I created module review generator that:Combines multiple sources: Integrates lecture notes, discussion solutions, and homework problems into a single comprehensive review documentSynthesizes content by topic: Uses Gemini API to organize material thematically rather than chronologically, making it better for exam prepIncludes source citations: Each concept/problem is tagged with its source (e.g., Lecture 24, Discussion 12 Problem2a, HW 10 Problem1, ...) for easy referenceThe script is easily configurable to combine any set of lectures, discussions, and homeworks for different modules.Example usage:I combines Lectures 24-27 + Discussions 12-13 + HW 10, 11, 13 into one study guide which is about generative models and post-training.sample output in I think the review successfully integrates multiple sources, creating meaningful connections between lectures and the accompanying discussions and homework problems.annotated transcript:", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/nyMA5YPN5fZmDF5CrF7AOzwx", "name": "module_review_generator.py"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/SXST8e0lnZ6JVZRd1QMWRnWP", "name": "module_24-27_comprehensive_review.tex"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/oqSINuasbiLX7tolCEz7yC9G", "name": "annotated_module_review_24-27.pdf"}], "tags": ["Tool/App", "Study Guide"], "original_url": "https://edstem.org/us/courses/84647/discussion/7425579"}, {"id": 7424917, "title": "Special Participation E: Tensor Norm Visualization Tool", "date": "2025-12-08T00:04:37.045755+11:00", "author": "Neil Pattanaik", "content": "Using Gemini's Canvas mode, Gemini was able to build this neat interactive visualization of the various tensor norms we discussed in the context of CNNs. It can be difficult to imagine and remember which axes are normalized over for each norm, which inspired me to create this tool. It displays 4 axes (H, W, C, Batch) and has both a 2d and 3d view of BatchNorm, RMS + LayerNorm, and InstanceNorm.https://gemini.google.com/share/57ed79731305", "resources": [{"type": "link", "url": "https://gemini.google.com/share/57ed79731305", "name": "Raw Text Link"}], "tags": ["Tool/App", "Visualization"], "original_url": "https://edstem.org/us/courses/84647/discussion/7424917"}, {"id": 7424843, "title": "Special Participation E: Analytical Failure Modes for Optimizer Intuition via Gemini Pro 3", "date": "2025-12-07T22:17:49.811521+11:00", "author": "Krish Yadav", "content": "While thinking more carefully about optimizers in CS 182, I became curious about  why particular optimizers exist, beyond just memorizing their update rules. In particular, I wanted to understand them as responses to specific geometric or scaling failures, rather than as isolated algorithms. To explore this, I used Gemini Pro 3 to construct a sequence of minimal, analytic failure modes for optimizers covered in class.I prompted the model to generate short, symbolic training scenarios (no code, no datasets) where a given optimizer behaves pathologically. For each scenario, it first asked me to predict what would go wrong, and only afterward explained what failed, which assumption was violated, and which optimizer or idea was introduced to address that failure. The scenarios included:ill-conditioning in gradient descentthe noise floor in SGDfailure of L2 regularization in Adam vs. AdamWwidth-dependent instability motivating μPand the lazy (NTK) training regimeThis approach was effective for connecting lecture material across geometry, scaling laws, and optimizer design, and for separating formal guarantees from heuristic intuition. I added annotations highlighting where the explanations aligned closely with lecture material and where the model relied more on intuition or standard deep learning lore.Overall, this worked well as an AI-assisted alternative to post-lecture reading, helping build optimizer intuition through concrete failure cases while still requiring active oversight.For more, look at the annotated PDF.", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/dWuLm2KWAtuO5b3BE8KghxCC", "name": "annotated-gp3-optimizer-failure.pdf"}], "tags": ["Tool/App", "Coding", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7424843"}, {"id": 7424838, "title": "Special Participation E: Learning CNNs by Building with Cursor", "date": "2025-12-07T22:06:38.495522+11:00", "author": "Nikhil Mathihalli", "content": "Concept: Convolutional Neural Networks (CNNs) & Kernel FiltersTool Used: Cursor (AI Code Editor)Artifact: The Kernel Whisperer (GitHub Repo)The Goal: I found the recent lectures on ConvNets interesting, but I wanted to move beyond static slides. I decided to treat the AI not just as a tutor, but as a \"junior developer\" to help me build an interactive learning tool. The goal was to learn about filters (blur, edge detection, sharpen) by actually applying them to images in code, effectively replacing my standard post-lecture review with an active engineering project.The Approach: I used Cursor to build a React-based interactive playground. I realized early on that Cursor works best when you act as the \"Architect.\" I wrote a highly detailed \"spec\" prompt defining exactly what the app should contain—specifically requesting a UI that allows for real-time filter toggling and an embedded AI chat interface tailored specifically to answer conceptual questions about CNNs.Interaction Trace & Critical Analysis:Since the interaction was code-heavy, my critical annotation focuses on the difference between Knowledge Generation and Debugging:Where it Succeeded (The Math):One-Shot Accuracy: Surprisingly, Cursor did not hallucinate on the actual implementation of the convolution logic or the filter matrices. Because I provided a detailed prompt about the mathematical purpose of the filters, it generated the core processing logic correctly on the first try.Where it Failed (The Engineering):Debugging Loops: While the math was good, the AI struggled significantly with \"glue code\" and UI state management. When a bug arose in the React rendering cycle, Cursor often got stuck in a loop, suggesting fixes that broke other parts of the app.Human Intervention: This highlighted a key limitation: AI is great at generating isolated logic (like a specific kernel), but requires a human to oversee the broader system architecture and fix integration bugs.Verdict: Building this tool forced me to understand the inputs and outputs of CNNs much better than just reading about them. If you want to try it out or see the code, the repo is linked above!", "resources": [{"type": "link", "url": "https://github.com/nikhilmathihalli/kernel-whisperer", "name": "The Kernel Whisperer (GitHub Repo)"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/ASLPoMV2jTJR6sAdXVDm8gIb", "name": "Kernel Whisperer.pdf"}], "tags": ["Tool/App", "Coding", "Tutor", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7424838"}, {"id": 7424833, "title": "Special Participation E: Creating New Discussion Sheets With Lectures That Current Discussion Sheet Does Not Ask using ChatGPT", "date": "2025-12-07T21:59:28.510045+11:00", "author": "Minjune Kim", "content": "I attempted to create a webpage that will take two inputs, one for lecture slides and another for discussion sheets (both in pdf format). Then, I would have chatgpt scan over both pdf files, and try to find concepts that the discussion did not cover that were in the lecture notes. With the concepts that weren't there, it would create new discussion sheet that's just like the discussion sheets for the class with answers such that it can be used to study concepts that weren't on the discussion but was on the lecture.During this process, I ran into some logistical error using chatGPT because at first, it was not able to detect any words for the lecture notes because all of the lecture notes were hand written, so I had to re-prompt GPT, such that it would be able to convert the hand-written notes into a readable format such that it will be able to recognize what concepts were covered in lecture. Furthermore, I did not prompt it carefully enough and not specific enough that when it first created the discussion sheet, it looked nothing like the discussions sheet, and it was also asking questions on only a few questions on concepts. Here is my annotated report for the prompt:", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/JTaAJOtGIlI8BtpiNwFrxieX", "name": "Website code for discussion questions-merged.pdf"}], "tags": ["Study Guide", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7424833"}, {"id": 7424719, "title": "Special Participation E: Understanding Transformers and the value of KV Cache through visual diagrams", "date": "2025-12-07T19:52:33.863435+11:00", "author": "Aaron Zheng", "content": "I am a hugely visual person, and I benefit from learning through images and videos. However, a lot of LLM and AI based concepts are really abstract, and it is hard to have detailed images of all the nuances of AI. However, Mindmaps that explain concepts in a visual, interdependent way, are helpful for me. Using a special prompt, I was able to learn more about transformers, KV caching and attention.I first told the LLM to generate a prompt that could make itself draw mindmaps and detailed drawings to explain machine learning concepts, where the \"concept\" is a variable. Then I copied the prompt and put the concept as \"transformers\". I then told the LLM to give me a markdown text-based version of the mindmap drawing, and it was very detailed, covering a lot of information. I generated two diagrams, shown here:Prompt:\"\"\"I want you to act as an expert AI educator who teaches complex machine learning concepts through highly intuitive mindmaps.Given a topic, produce a mindmap-style breakdown with:1 central concept5–8 major branchesUnder each branch:Short, intuitive explanations (not academic jargon)Visual analogies where appropriateStep-by-step decompositionsImportant equations (only if helpful)Common misunderstandingsReal-world examplesAdditionally, output:A “Beginner-Friendly Summary” at the topA “Deep Intuition Layer” beneath the mindmap (why the concept works)A “How It Fails / Edge Cases” sectionA “Connections to Other AI Concepts” sectionA “Mental Hooks” section (mnemonics / metaphors to remember the idea)Present the mindmap in a structured outline like:Central Node ├── Branch 1 │ ├── Subpoint │ ├── Subpoint ├── Branch 2 │ ├── Subpoint │ └── Subpoint … etc.Make it extremely intuitive and visually organized so I can use it to build internal mental models.Topic: <INSERT YOUR TOPIC HERE>\"\"\"chatgpt convo: https://chatgpt.com/share/69353fee-afa8-8001-96f3-17b1c12da113", "resources": [{"type": "image", "url": "https://static.us.edusercontent.com/files/DPGgxx2pdiLLyxdEYIEQu7oW", "name": "Image"}, {"type": "image", "url": "https://static.us.edusercontent.com/files/9SGVgQ7dcRTrO7PVyVbvSlFg", "name": "Image"}, {"type": "link", "url": "https://chatgpt.com/share/69353fee-afa8-8001-96f3-17b1c12da113", "name": "Link"}], "tags": ["Tool/App", "Study Guide", "Visualization", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7424719"}, {"id": 7424570, "title": "Special Participation E: Gemini Pro 3 as a Lecture-Grounded Discussion Worksheet Assistant", "date": "2025-12-07T18:35:05.240735+11:00", "author": "Dagny Streit", "content": "I prompted Gemini Pro 3 to act as a lecture-grounded discussion worksheet assistant. During discussions, I usually find myself scrolling through lecture notes to recall the relevant concepts, so my goal was to create a tool that helps students understand the conceptual foundations behind each worksheet question without giving solutions and without pulling from the worksheet’s explanations.To achieve this, I wrote a strict prompt enforcing:Exclusive use of Lecture PDFs for conceptual content (I provided my handwritten lecture notes that tried to capture a lot of what was said in lecture).Use of Discussion PDFs only for reading the question text (I provided Discussion 13 and asked it about Question 2).I then tested whether the model could behave like an assistant who has only seen the lectures, not the solutions. The interaction included:Initial conceptual explanation of a worksheet question using lecture terminology only.Zoom-in prompts to elaborate on specific lecture ideas (e.g., the tradeoff between losses).A diagnostic checklist of concepts students should review before attempting the discussion question.Lecture-grounded practice questions and hints that did not overlap with worksheet wording.A self-correcting step, where the model identified phrases that were not actually supported by the lecture slides and rewrote them accordingly.What worked:The model produced structured mini-lectures, learning goals, and checklists.It consistently linked specific and relevant lecture slides, including portions of diagrams (note: the links do not show unfortunately in the PDF log of the conversation with Gemini).The self-correcting step was effective. The model recognized when it used unsupported terminology and corrected itself.These features made it genuinely useful for conceptual grounding before discussion.What did not work:I initially tried using ChatGPT, but I switched to Gemini because it supported clickable references to my uploaded lecture notes, which made checking grounding much easier.Gemini tended to hallucinate on diffusion-specific concepts (Markov chains, Bayes’ rule, etc.) that were not in the lecture PDFs, so explicit prompting and self-correcting were necessary. I think this was because it was looking at Question 1d instead of Question 2d of the discussion worksheet.My lecture notes may not have been comprehensive and could have caused the model to occasionally fill gaps with general deep learning knowledge rather than lecture content. I try to capture a lot of information in my handwritten lecture notes, but some things that are said in lecture may be missed.Overall, it worked well once constrained, and the self-correction step was key for keeping it oriented with lecture material. Attached is the annotated conversation.", "resources": [{"type": "link", "url": "https://drive.google.com/file/d/1buAqcR2x1bfJGo_H2RfKZxrEfkm-wESY/view?usp=sharing", "name": "Attached is the annotated conversation"}], "tags": ["Tool/App", "Study Guide", "Visualization", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7424570"}, {"id": 7424475, "title": "Special Participation E: Structured Notes with NotebookLM RAG Tool", "date": "2025-12-07T17:58:19.508117+11:00", "author": "Elizabeth Polito", "content": "For this assignment, I evaluated whether Google NotebookLM is a viable tool for generating \"Cornell\" Notes from our handwritten lecture slides. Taking notes in “Cornell Style” can help to make sure you are not getting bogged down in the details by dedicating a column on the left of your page to keywords/main ideas, a column on the right to the notes themselves, and a box on the bottom for a summary. Here is a summary of why these types of notes are useful: Cornell Note Taking — The Best Way To Take Notes, Explained | Goodnotes Blog(Citation: Image taken from link above for illustrative purposes).I used NotebookLM, which is a RAG-based research tool that grounds its generation primarily in your uploaded documents. I was able to carry out the generation simply by uploading the handwritten lecture notes (interestingly, I did have to “flatten” the PDFs before the software was able to “read” the content, and prior to doing so, NotebookLM insisted that the document was empty). I chose Lecture 7 (MuON) as the stress test because it contains relatively few diagrams which would have been more of a challenge for the tool to replicate/parse. Overall, because NotebookLM is powered by Gemini Pro which, as many students have pointed out in their special participation submissions, is very well-equipped to deal with this content, it did a highly accurate job of generating Cornell style notes and writing decent summaries. In my opinion, the biggest limitation with the NotebookLM tool is the I/O behavior, between some issues uploading the PDF as discussed and the fact that I could not download a PDF of the trace or of the Cornell notes themselves. Its ability to parse the notes and provide inline citations for which page of the document the equations came from was very helpful once the document was in a format it could parse. The tool seems to have many more built-in features that would be very interesting to explore.The ArtifactI have attached the PDF of the transcript below, which includes the Cornell notes within. The structure follows the Cornell method:Left Column: High-level cues (\"Newton-Schulz Iteration\", \"Shampoo vs MuON\").Right Column: More detailed mathematical notes/derivations with inline citations.Summary: A synthesis of the “page” of notes. I have uploaded an annotated trace of my conversation, which includes the Cornell notes within.", "resources": [{"type": "link", "url": "https://www.goodnotes.com/blog/cornell-notes", "name": "Cornell Note Taking — The Best Way To Take Notes, Explained | Goodnotes Blog"}, {"type": "image", "url": "https://static.us.edusercontent.com/files/OP3WsLpngu6hQYXfpYkVmise", "name": "Image"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/aUuZSCc3YLb25Q4tuQPAzacD", "name": "muon_annotated.pdf"}], "tags": ["Tool/App", "Math", "Study Guide", "Visualization"], "original_url": "https://edstem.org/us/courses/84647/discussion/7424475"}, {"id": 7424307, "title": "Special Participation E: Nano Banana 3 Pro for Note Generation and Content Understanding", "date": "2025-12-07T17:00:57.698038+11:00", "author": "Leon Kornfeld", "content": "Google recently launched Nano Banana Pro, its new image generating model. I saw online that it could do many cool things such as solve math problems on paper or explain pictures in depth. I decided to use it on a bunch of different tasks to see how it fairs as a study tool. Experiment 1, Convolution:Prompt 1: Can you make me an image of hand drawn notes explaining a convolutional neural network. I will prompt you for many different images but can you draw first a diagram of what a convolution would look like with a 2D kernel and a 3D kernel. Be sure to include a visualization of the output channels depending on how many kernels are applied.Output 1:Analysis:Overall, the note looks fantastic. The handwriting is neat and it is nicely structured. The first section of the note makes sense. It explains the convolution operation as a dot product and sum. The output feature map is of proper dimension assuming zero padding, and stride is 1. There does seem to be a rogue \"& sum\" underneath the bottom arrow.While the 3D convolution section correctly notes the output map is of depth 1, it incorrectly generated the output dimensions as a 3 by 3. Also, the choice of operator \"+\" is an odd notation to use.Lastly, for the \"Multiple Kernels and Output Channels\" section, it correctly identified that there should be 3 output channels. However, the diagrams have the weird \"+\" notation and the input and output dimensions are not really detailed.To address the dimension issue in \"3D convolution\", I submitted prompt 2:Please make it more mathematically rigorous. For example, in your 3D convolution, there are only 4 rows in the original input and the kernel is of size 3. However, their output has 3 rows. This is incorrect if assuming zero padding since the number of rows should just be 2.Output 2:With this prompt all the output feature maps were filled in with numbers. They are all obviously incorrect. Moreover, while it did shrink the number of rows in \"3D Convolution\" to 2, it also shrunk the number of columns to 2 as well. The output map dimensions in \"Multiple Kernels\" are correct, but there is a coloring issue: for consistency, it would make sense that the first output channel is purple.Prompt 3:This is also still incorrect since the output map for the 3D convolution should be a 2 by 3, not a 2 by 2. Also the numerical values and the math do not make sense.Lastly, for the multiple kernels and output channels section, it's confusing notation of adding the different kernels. Can you please fix that.Overall, the coloring scheme is also kind of confusing since you have a purple kernel that doesn't have a corresponding output channel while the green and orange kernels do. Please be consistent with everything you are doing.(Note: this prompt could have definitely been better).Output 3:There was no real improvement to \"3D Convolution.\" However, \"Multiple Kernels\" did get rid of the weird \"+\" notation and showed each output map individually for the 3 kernels with the proper coloring scheme. However, the last step still has the wrong colors. Also note, none of the numbers are correct.Conclusion :Nano Banana 3 has an amazing ability to generate notes that discuss the concept of CNNs. While the specifics (dot product values, correct dimensions, etc.) are still shaky, the overall structure, quality, and high level concepts are very very good. Based on this experiment, however, I would not yet recommend using this as a study tool.Experiment 2, Images -> Images:Prompt 1: Solve this problem in my hand writing and generate an image of the work and the solutionOutput 1:Nano Banana 3 was able to read my handwriting and recognize that the problem it needed to solve was least squares. It proceeded to provide a mostly correctly proof (minus a few notational issues with the transposes) and arrived at a correct answer. It even added in the condition that A^T A needs to be invertible. However, while it did not solve the problem with my handwriting, the type of paper used stayed the same.For my next prompt, I provided a screenshot of a note from lecture:Prompt 2:Take this lecture note about the weights in MLPS and CNNs and annotate the image explaining what each picture means.Output 2:Mistake 1: The top two description boxes are flipped. However, the content in each box would be fully correct were they pointing to the right spot.Mistake 2: It correctly notes that the diagrams are from the Prince book but the written text describing that is no longer in the output.The rest of the description boxes are actually quite amazing. Descriptions b and d both relate their images to the corresponding images in a and c, showing an in-depth understanding of all the images provides in the prompt image. Moreover, their individual interpretations of the weight matrices and what they represent without much context is also quite great.Conclusion:Nano Banana Pro has an impressive ability to take in images , understand their contents, and produce new images by either adding on to or augmenting the inputted ones. I ran another experiment that I did not feature here that took in images describing more complicated math. The output was close to the original picture (handwriting slightly rewritten) with some added gibberish. Therefore, I would conclude that Nano Banana Pro has the ability to understand well structured diagrams or easy math, but it is not necessarily at the point yet where it can understand and generate images for more complicated math.", "resources": [{"type": "image", "url": "https://static.us.edusercontent.com/files/YfCldqolUrZFzgQVeTXNfzEE", "name": "Image"}, {"type": "image", "url": "https://static.us.edusercontent.com/files/WstJi0DHnMvB4gHOOmiGLtfZ", "name": "Image"}, {"type": "image", "url": "https://static.us.edusercontent.com/files/VX1xx3trU7c70YkU5V19W6em", "name": "Image"}, {"type": "image", "url": "https://static.us.edusercontent.com/files/b1oRLJzgGdwjPeMFDOeMWeZw", "name": "Image"}, {"type": "image", "url": "https://static.us.edusercontent.com/files/tzeb74eNam3Oay43EDdGyxvj", "name": "Image"}, {"type": "image", "url": "https://static.us.edusercontent.com/files/NYPNf5PCGsFzJIK5aSAAjN22", "name": "Image"}, {"type": "image", "url": "https://static.us.edusercontent.com/files/8RovKbeFBuIn3yZHcEmnLaB3", "name": "Image"}], "tags": ["Tool/App", "Study Guide", "Visualization", "Prompt Eng", "Math"], "original_url": "https://edstem.org/us/courses/84647/discussion/7424307"}, {"id": 7424217, "title": "Special Participation E: Misconception Diagnostic Learning with Claude and Deepseek", "date": "2025-12-07T16:38:54.996225+11:00", "author": "Zesheng Cai", "content": "In this assignment, I designed an AI-enhanced learning tool that does not simply explain deep learning concepts but instead actively diagnoses and corrects my misunderstandings. I interacted with two different AI models—Claude and DeepSeek—and provided intentionally imperfect answers to their diagnostic questions. This allowed the models to analyze my reasoning, detect misconceptions, and generate personalized explanations.The workflow follows four stages:I answer diagnostic questions about Attention and Self-Attention. These answers intentionally contain a mix of correct ideas and common misunderstandings.The AI infers my misconceptions from my responses. Each system identifies which parts of my reasoning are correct, partially correct, or mistaken.The AI produces tailored explanations based on the specific misconceptions it detected. These include counterexamples, intuitive analogies, and conceptual clarifications.The AI generates personalized exercises that target the exact areas where I showed confusion. This turns the interaction into a highly adaptive learning process.This workflow transforms AI from a passive explanation tool into an active diagnostic tutor—similar to a human TA who tests my understanding before teaching.Instead of asking the AI to teach me concepts directly, I designed a system where the AI actively discovers and corrects my misunderstandings about deep learning. I call this approach a Misconception Diagnostic System. It acts like a doctor diagnosing a patient:It asks targeted diagnostic questionsIt infers hidden misconceptions from my answersIt generates personalized corrective explanationsIt produces practice exercises tailored to my specific gapsThis system goes far beyond traditional Q&A or passive reading. It creates a learning process that is:Adaptive — tailored to my levelInteractive — requiring me to think and respondMisconception-driven — correcting what I don’t know, not what I already knowHigh-resolution — identifying subtle misunderstandingsBidirectional — my answers shape the AI’s teaching strategyThis is fundamentally different from standard “AI explains a topic” workflows. Instead, the AI becomes an active diagnostic tutor. ClaudeStrengthsVery strict structure and excellent instruction followingClean four-stage pipelineHigh linguistic clarityLow hallucination rate in technical formulasProduces polished conceptual exercisesWeaknessesSometimes fabricates my answers (“overconfident inference”)Personalized corrections are less detailedExplanations sometimes feel too “textbook-like\"DeepSeekStrengthsStrong reasoning-first approachUses numerical counterexamples to build intuitionExcellent at detecting subtle conceptual mistakesExplanations are detailed and mathematically groundedExercises more directly target my actual misunderstandingsWeaknessesSometimes overly verboseOccasionally over-interprets my intentionsHigher chance of speculative reasoningOverall ComparisonClaude = structure-first systemDeepSeek = reasoning-first systemClaude shines at formatted explanation. DeepSeek shines at conceptual diagnosis.Using both provides a more complete learning experience.SummaryThrough this assignment, I developed and tested a novel AI-enhanced learning tool based on misconception diagnosis rather than passive explanation. By intentionally providing imperfect answers to diagnostic questions, I enabled Claude and DeepSeek to identify my conceptual gaps and generate personalized corrections and targeted exercises. This made AI function more like a real tutor rather than a search engine.The interaction trace demonstrates the strengths and weaknesses of two leading AI models: Claude excels at structured instruction following, while DeepSeek provides deeper mathematical intuition and finer-grained diagnostic reasoning. Their complementary strengths highlight how different AI systems can address different aspects of the learning process.Most importantly, the Misconception Diagnostic System provides a highly adaptive, interactive, and personalized alternative to traditional pre-lecture or post-lecture reading. It forces me to articulate my understanding, reveal misconceptions, confront errors, and reinforce corrected concepts through targeted practice.This approach not only deepens intuition but also broadens conceptual coverage, making it a powerful and innovative method for AI-enhanced learning in deep learning courses.", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/BRRW4vBrN2TPdTSbWOtHiO28", "name": "Using Deepseek and Claude as tutors.pdf"}], "tags": ["Tool/App", "Tutor", "Study Guide", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7424217"}, {"id": 7423912, "title": "Special Participation E: Using DeepSeek to Develop Intuition and Deepen Understanding in Deep Learning", "date": "2025-12-07T15:22:07.476049+11:00", "author": "Zesheng Cai", "content": "For this assignment, I chose DeepSeek as the AI-enhanced learning tool because it demonstrates unusually strong reasoning capabilities, especially in mathematical explanation, multi-step intuition building, and structured teaching. My goal was not only to obtain direct answers, but also to evaluate whether DeepSeek could serve as an active substitute for traditional pre-lecture or post-lecture readings.To achieve that, I first asked DeepSeek a sequence of foundational but conceptually challenging questions on CNNs, pooling, data augmentation, and batch normalization. These questions were intentionally selected to reveal my current level of understanding, so that the model could adapt its explanations to my background.Afterwards, I prompted DeepSeek to take the role of an instructor and generate a set of quiz-style questions to test my comprehension. This part was extremely useful: the quiz forced me to articulate the intuition behind invariances, optimization behavior, and design trade-offs. The progression from easy to difficult questions mirrored the structure of typical deep learning readings and helped reinforce both the breadth and depth of my understanding.Throughout the interaction, DeepSeek performed well in explaining intuition, giving structured arguments, and generating pedagogically meaningful questions. At the same time, several responses contained oversimplifications, slight exaggerations, or unnecessary repetition, which I highlighted in the annotations. These issues illustrate that while the model is powerful, its output still requires human verification and critical reading—very similar to how one must evaluate a technical textbook.Overall, this exercise shows that DeepSeek can function as a dynamic, interactive learning companion: it not only answers technical questions but also probes understanding, generates practice material, and supports conceptual clarity. With careful supervision, this approach can effectively complement traditional study methods and enhance conceptual learning in deep learning courses.", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/telbENslFri4PbZcEo65z5ku", "name": "Understanding Downsampling and Pooling in CNNs (1) - DeepSeek.pdf"}], "tags": ["Tool/App", "Quiz/Drill", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7423912"}, {"id": 7423906, "title": "Special Participation E: Active AI Scaffolding, bridging Linear Algebra and Sequence Dynamics in Deep Learning", "date": "2025-12-07T15:21:03.812454+11:00", "author": "Zhengwei Fan", "content": "Introduction: In this study session, I employed a \"Socratic Tutor\" system prompt to actively engage with the material from Lecture 14 (Sequence Modeling) and Lecture 15 (Self-Supervised Learning) of the EECS 182/282A curriculum. Rather than passively summarizing the lecture notes, my goal was to simulate a high-level oral exam environment. I instructed the AI (Gemini) to withhold direct answers and instead challenge my intuition through mathematical \"checkpoints.\" The interaction trace focuses on two rigorous theoretical connections: Firstly, proving the equivalence between Principal Component Analysis (PCA) and Linear Autoencoders via the Eckart-Young-Mirsky theorem. Secondly, Re-interpreting Recurrent Neural Networks (RNNs) as non-linear approximations of Kalman Filters, specifically contrasting static weights (W) with dynamic gains (K). At last, unifying these views through the lens of HaoChen et al. (2021), demonstrating how Contrastive Learning performs spectral decomposition on an \"Augmentation Graph,\" effectively learning the manifold of the data.Fully Trace: https://gemini.google.com/share/64ea8f81fb2c", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/vCDXSiB5hEwA2BhwpzGhEh6Q", "name": "Special participation E.pdf"}, {"type": "link", "url": "https://gemini.google.com/share/64ea8f81fb2c", "name": "Raw Text Link"}], "tags": ["Tool/App", "Coding", "Study Guide", "Visualization", "Prompt Eng", "Tutor", "Math"], "original_url": "https://edstem.org/us/courses/84647/discussion/7423906"}, {"id": 7423645, "title": "[WIP] Special Participation E: “Lecture-to-LaTeX Cheatsheet” Workflow", "date": "2025-12-07T14:29:37.083582+11:00", "author": "Lenci Ni", "content": "I’ve been testing a workflow where I feed an LLM a PDF of lecture notes and have it generate a clean, structured LaTeX summary that I can drop directly into a personal cheatsheet. My motivation is that I really like having compact LaTeX reference sheets for classes. I end up using them later when I want to remember where I first learned a topic, and they’re also useful for finals studying when I need to quickly review concepts at a high level.", "resources": [], "tags": ["Study Guide", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7423645"}, {"id": 7423129, "title": "Special Participation E: Gemini's Guided Learning", "date": "2025-12-07T12:49:25.699595+11:00", "author": "Kian Hekmatnejad", "content": "I used Gemini's Guided Learning tool to create a tool for post-lecture confirmation of knowledge. It provides a quick summary of the lecture notes provided, then tests knowledge in a series of increasingly complex questions, continuing until the student demonstrates adequate understanding of the concepts for CS182 standards. Here is the link to my conversation and the summary is attached:https://gemini.google.com/share/459fac511f56", "resources": [{"type": "link", "url": "https://gemini.google.com/share/459fac511f56", "name": "Link"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/KgjKsoc1zJdRLxc7b72mdTpl", "name": "Special participation E2.pdf"}], "tags": ["Tool/App", "Study Guide"], "original_url": "https://edstem.org/us/courses/84647/discussion/7423129"}, {"id": 7423074, "title": "Special Participation E: The \"Deep Learning Detective\" Game", "date": "2025-12-07T12:39:14.661561+11:00", "author": "Tom Chen", "content": "Special Participation E: The \"Deep Learning Detective\" GameIn Deep Learning, a model can run without errors but still fail to learn (e.g., loss flatlines, gradients explode). Beginners often struggle to link these \"symptoms\" to the underlying mathematical causes. I designed a prompt to simulate this diagnostic process.Please check the prompt in the following prompt.txt:Here is a case about how to use it:My analysis about this tool:The GoodsPrecise Symptom-to-Cause Mapping: The AI correctly identified that spatial depth (20 layers) + temporal length (100 steps) + small init = Vanishing Gradients. It didn't hallucinate \"Exploding Gradients\" (which would show NaNs) or \"Overfitting\" (which would show low training loss).Mathematical Grounding: Instead of just guessing, it provided the formula for BPTT. This is crucial for a learning tool—it explains why the failure happened, not just what happened.Correct Remediation: It suggested the standard industry fix (Switch to LSTM) and the \"Power User\" fix (Orthogonal Initialization for Vanilla RNNs), showing a tiered understanding of solutions.LimitationsOversimplification of Identity Initialization: The AI suggested \"Identity Initialization\" as a secondary fix. While theoretically sound (Le, Jaitly, Hinton 2015), in practice, training a 20-layer Vanilla RNN on 100 steps is notoriously unstable even with good initialization. The AI presented this as a definite \"fix,\" whereas a human expert would warn that it might still be very fragile compared to an LSTM.Lack of \"Exploding\" Warning: When suggesting a switch to ReLU (in the \"Secondary Fix\" section), the AI briefly mentioned clipping but failed to emphasize that ReLU in RNNs often leads to the opposite problem: Exploding Gradients (due to unbounded activations). A more rigorous tutor would have flagged this risk more aggressively.", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/zcJvRXCe2aVJBMO1SGyx6WdH", "name": "prompt.txt"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/kqona55LibEDryE59oebGL41", "name": "Special Participation E2.pdf"}], "tags": ["Tool/App", "Tutor", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7423074"}, {"id": 7422938, "title": "Special Participation E: Interactive Visualization of Qwen 3 MoE architectures", "date": "2025-12-07T12:15:50.36033+11:00", "author": "Vijay Kethanaboyina", "content": "Recap of Assignment InstructionsFor this assignment, we were asked to create an AI-enhanced learning tool for a specific concept or lecture. The goal was to explore how modern LLM systems can act as substitutes or supplements for traditional pre- and post-lecture readings.We were required to:Design a prompt, workflow, or artifact that classmates could reuse to learn the same material.Provide an interaction trace demonstrating how the tool works.Annotate the trace with critical commentary, highlighting where the model was helpful, where it made mistakes, and what we learned about interacting with it.What I MadeFor my submission, I explored the internal architecture of the Qwen model family. I used GPT5-codex (an OpenAI model designed for code generation tasks) to create an interactive visualization of the model architecture that breaks down its components (tokenization, attention structure, MoE usage, architectural variations, etc.) into digestible conceptual blocks.I'm hosting the tool on my personal website here: https://www.vkethana.com/qwen-arch/My annotated interaction trace with the LLM is here: https://drive.google.com/file/d/1KoVUdATKohP20_UTGkcJ4tSDsvxJTV2S/view?usp=sharingSome Insights I Had About the LLM InteractionThe model was able to generate the majority of the final product in just one prompt.There were some minor detail-related / visual discrepancies that needed to be corrected in subsequent prompts. But in terms of zero-shot performance, I would say that Codex did pretty wellThe model tends to summarize information without being prompted to do soFor example, in the very first version of the app, the model omitted most of the information about specific parameter counts, embedding widths, etc. I had to explicitly prompt the model to add these details into the visualizationCursor (a VSCode fork with added features to support coding agents) is a great complement to code generation models like GPT5-CodexSome features I found particularly useful include being able to roll back the codebase to an arbitrary point in the conversation, diff visualization so that you can see what the model did to the codebase, and easy support for exporting conversations.", "resources": [{"type": "link", "url": "https://www.vkethana.com/qwen-arch/", "name": "Link"}, {"type": "link", "url": "https://drive.google.com/file/d/1KoVUdATKohP20_UTGkcJ4tSDsvxJTV2S/view?usp=sharing", "name": "Link"}, {"type": "link", "url": "https://www.vkethana.com/qwen-arch/My", "name": "Raw Text Link"}, {"type": "link", "url": "https://drive.google.com/file/d/1KoVUdATKohP20_UTGkcJ4tSDsvxJTV2S/view?usp=sharingSome", "name": "Raw Text Link"}], "tags": ["Tool/App", "Coding", "Visualization", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7422938"}, {"id": 7422808, "title": "Special Participation E Use Gemini 3 do Final Exam Reviewing", "date": "2025-12-07T11:53:20.137992+11:00", "author": "Fangzhou Zhao", "content": "When studying EECS 182, I wanted a high‑level “big picture” view of all the discussions plus some realistic exam practice, without rereading every single PDF from scratch. I asked Gemini 3 Pro with Guided Thinking to act like a Berkeley professor: review the discussion notes and then generate an example exam in that style. My hope was to use it as both a conceptual review sheet and a source of practice problems for midterm/final prep.Gemini’s response did a solid job of capturing the themes running through the course: optimization vs geometry, residual connections as “gradient highways,” SSMs as convolutions vs recurrences, attention as a fix for bottlenecks, and how inference‑time tricks like beam search and soft prompting fit in. It also produced exam questions that felt very “182‑ish”: derivations about convolution kernels, RoPE inner products, SSM kernels, and beam‑search bookkeeping that line up well with what I’ve seen in discussion. As practice prompts to work through on my own, they’re genuinely useful.At the same time, Gemini did hallucinate or slip on some technical details (for example, getting certain scaling factors and regularization dependences wrong) and sometimes went deeper or more confidently into math than was actually justified. So I treat its write‑up as good conceptual scaffolding and a source of exam‑style questions, but not as an authority on precise formulas. With a red pen and the official discussion solutions next to it, though, its output becomes a pretty effective study packet.https://gemini.google.com/share/7ccfff76d2f3", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/vyNFe8SDW76StQtkiaFNxqN2", "name": "Special E.pdf"}, {"type": "link", "url": "https://gemini.google.com/share/7ccfff76d2f3", "name": "Link"}], "tags": ["Math", "Study Guide", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7422808"}, {"id": 7422782, "title": "Special Participation E: Gemini 3 Pro as a Socratic Tutor for Deep Learning Theory (RMSNorm & MuP)", "date": "2025-12-07T11:47:38.983883+11:00", "author": "Ijin Yu", "content": "Hi everyone,For the \"AI-Enhanced Learning Tools\" option, I experimented with using an LLM (Gemini) as a Socratic Academic Tutor to help me work through the mathematical derivations of RMS Norm, Initialization, and Maximal Update Parametrization (MuP).Instead of just asking for answers, I used a specific system prompt to force the AI to guide me through the logic gaps. My goal was to replace passive reading of the lecture notes/slides with an active derivation session.1. The Setup (The Prompt)I used the following prompt to set the \"persona\" and rules for the AI. This prevents the model from dumping walls of text and forces it to track my understanding.System Prompt Used:\"You are an expert Academic Tutor. We are about to have a study session regarding Deep Learning.Your Goal: Answer my questions and help me work through problems. Do not just give me the answer; use Socratic questioning to guide me if I am stuck, but provide clear explanations when I am genuinely confused.Crucially: Silently track concepts I understood vs. concepts where I struggled.Output Trigger: When I type 'MAKE NOTES', stop tutoring and output a 'Personalized Study Artifact' summarizing my learning process, struggle points, and a review checklist.\"2. Interaction Trace & HighlightsTopic: We covered the derivation of RMS Norm, why it is considered a \"relaxation\" of strict orthogonality, and how this derivation directly leads to the \"MuP\" (Maximal Update Parametrization) rules used for training massive models like GPT-3.3. Critical Annotation (Critique of the AI)Per the assignment instructions, here is my critical analysis of the AI's performance during this session:Where it excelled (The \"Good\"):Analogy Generation: When I struggled to understand why we scale RMS Norm by $\\sqrt{d}$ (width) rather than keeping the total L2 norm fixed, the AI generated a \"Crowded Room\" analogy (Total Volume vs. Average Volume). This successfully bridged the gap between the math notation and the intuition of \"signal health\" in high dimensions.Linking Concepts (Synthesis): The AI successfully recognized that the derivation I was working on (checking stability of $\\Delta h$) was the mathematical foundation of MuP. It proactively linked the theoretical algebra to a real-world application (hyperparameter transfer), which wasn't explicitly in my initial upload.Debugging Misconceptions: It correctly identified a \"Notation Collision\" I had regarding \"Order 1.\" I confused Polynomial Order (Linear) with Asymptotic Order (Constant). The AI didn't just correct the math; it explained why I made the mistake (the language ambiguity).Where to be careful (The \"Bad/Misleading\"):Notation \"Ghost Terms\": When I asked about using the Product Rule for finite differences ($\\Delta$), the AI said \"Yes,\" but had to be pressed to explain the technical inaccuracy. It initially glossed over the \"second order term\" ($\\Delta W \\Delta h$) that we ignore in Deep Learning. A student blindly accepting the first answer might think the Calculus Product Rule applies perfectly to discrete steps, which is mathematically false (though a standard approximation in DL).Hallucination Check: While it didn't hallucinate facts in this session, it did generate specific Python code for MuP. I would need to verify this against the official Microsoft mup library documentation before using it in a project, as LLMs often mix up syntax for niche libraries.4. The Output ArtifactAt the end of the session, the MAKE NOTES trigger produced a study guide tailored to my specific confusion points during the chat. (See the end of the attached trace).Takeaway: This prompting strategy is highly effective for \"math-heavy\" theory where you need to verify your intuition, provided you force the AI to question you rather than lecture you.", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/71FMfXBYRIcHskTsuGYMdOD3", "name": "Google Gemini.html"}], "tags": ["Tool/App", "Coding", "Study Guide", "Prompt Eng", "Tutor", "Math"], "original_url": "https://edstem.org/us/courses/84647/discussion/7422782"}, {"id": 7422729, "title": "Special Participation E: ChatGPT as a Finetuning Simulation", "date": "2025-12-07T11:37:28.182875+11:00", "author": "Akhil Agarwal", "content": "Motivation/SummaryI tend to struggle quite a bit with hyperparameter tuning whenever it comes up in the homeworks, and I noticed that LLMs tend to be pretty good with it, probably due to having a lot of examples to go off of. So, I decided to make a finetuning simulator, where the LLM comes up with some hypothetical task, model architecture, loss function, and optimizer, and the user has to work on finetuning it. The model would produce training/validation loss and accuracy curves after every change, and also forced the user to explain their reasoning. I learned quite a bit in my chat with it, such as some nuances of the learning rate scheduling, as well as how large oscillations can happen in validation loss and not in training loss if some hyperparameters are off. It did quite well, adjusting the curves according to the changes proposed and providing very helpful analysis when requested. I wanted the user to do most of the work, and so it was instructed to do minimal analysis unless requested, but it started to add more analysis as the chat went on, though still not too much. It also didn't deny all of my changes as bad or accept them all as good, so I think it was trying to be objective based on the situation it started with, which was great.Trace: https://chatgpt.com/share/6934b9ec-e3cc-800f-bab9-74457b92d562Annotated Trace:System Prompt:Role: You are an advanced Deep Learning Hyperparameter Tuning Simulator. Your goal is to help the user master tuning dynamics by allowing them to manipulate hyperparameters and observing the consequences via simulated loss and accuracy curves.Operational Rules: Initialization:Start by randomly selecting a Task (e.g., Image Classification, Sentiment Analysis, Regression), a Model (CNN, MLP, GNN, Transformer), an Optimizer (SGD, Adam, AdamW, SGD-Momentum), and a Loss Function (MSE, Cross-Entropy).Do not initialize the hyperparameters, and allow the user to initialize the values to start. If they are missing a key hyperparameter which the model would not be able to work without, make sure to prompt them towards initializing it without mentioning the name of it, but if it is possible to run without it or set it to 0 as a default, do that but do not mention the hyperparameter, allowing the user to discover it. If there is some extra hyperparameter they supply, or they would like to modify the architecture, allow for that, as long as it is implementable.The key is to allow the user as much flexibility as they would like, and only help them in any way when they request it. The first message should simply ask the user for hyperparameters, and not mention the names of any of them, along with defining the task, model architecture, and loss function.Do not explain why the values are bad.The \"Reasoning\" Requirement (Strict):The user must propose a change and provide a reason (e.g., \"Decrease LR to 1e-3 to stop oscillation\").Condition A: If the reasoning contradicts the action (e.g., \"Increase LR to reduce noise\"), REJECT the change and ask them to clarify.Condition B: If the reasoning is logical but the move is mathematically wrong for the current state (e.g., \"Increase LR\" when it's already exploding), ACCEPT the change and simulate the disastrous result.Condition C: If the reasoning is logical and the move is correct, ACCEPT the change and simulate the improvement.Visual Feedback Only:CRITICAL: Do not provide text-based \"Expert Analysis\" or explain why the curve looks the way it does. Do not give away the solution.Instead, you must generate a synthetic Loss/Accuracy curve that accurately reflects the mathematical behavior of the current hyperparameters.Example: If LR is too high, plot a jagged, exploding line. If Batch Size is small, add heavy Gaussian noise to the line. If Overfitting, curl the Validation Loss upward.Response Format:Current Hyperparameters: List the current state.Simulation: The graph of the loss and accuracy (training & validation).Visual Description: A brief, objective description of the line (e.g., \"The line is flat,\" \"The line is oscillating\"). Do not interpret the meaning.Next Step: Ask the user: \"What is your next proposal? (Remember to include your reasoning.)\"IF the user is asking for feedback or analysis, provide it to the extent that the user asks, giving no more information than is necessary, while satisfying the user's request.Goal: The user should \"win\" by successfully tuning the model to high accuracy through trial and error, relying solely on their ability to read the graphs. Only offer a hint if the user explicitly asks for help or fails 3 times in a row. Ensure that the simulation is realistic.", "resources": [{"type": "link", "url": "https://chatgpt.com/share/6934b9ec-e3cc-800f-bab9-74457b92d562", "name": "Link"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/JBaLf9A0eQFhV9gozao2dw5q", "name": "Special_Participation_E1.pdf"}, {"type": "link", "url": "https://chatgpt.com/share/6934b9ec-e3cc-800f-bab9-74457b92d562Annotated", "name": "Raw Text Link"}], "tags": ["Tool/App", "Study Guide", "Visualization", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7422729"}, {"id": 7422403, "title": "Special Participation E: Using ChatGPT to Automatically Find and Organize Related Papers", "date": "2025-12-07T10:40:31.898458+11:00", "author": "Qicheng Zhu", "content": "For this special participation, I designed an AI-enhanced prompt workflow using ChatGPT to help students deepen their understanding of lecture content by automatically finding and organizing related research papers.The whole prompt workflow consists of three steps:(1) Given a PDF of the lecture notes, the model extracts several core technical topics; (2) For each topic, it generates specific search queries and uses them to retrieve relevant papers from Google Scholar or arXiv (ideally via );Agent Mode(3) Based on the retrieved papers, it produces structured summaries that explicitly connect back to the lecture topics, proposes an appropriate 2-3 hour reading plan, and generates conceptual reflection questions. This turns paper reading activity into an intended, reflective and guided literature exploration rather than just paper searching and reading.Here is the chat Link: https://chatgpt.com/share/6934b827-ed1c-8002-9a93-03242d44b324Here is the report:", "resources": [{"type": "link", "url": "https://chatgpt.com/share/6934b827-ed1c-8002-9a93-03242d44b324", "name": "Link"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/3Jt3PO58cbiatKc7bvom9O7y", "name": "Participation E2 Qicheng Zhu.pdf"}, {"type": "link", "url": "https://chatgpt.com/share/6934b827-ed1c-8002-9a93-03242d44b324Here", "name": "Raw Text Link"}], "tags": ["Tool/App", "Study Guide", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7422403"}, {"id": 7422368, "title": "Special Participation E: HW Concept Check CLI", "date": "2025-12-07T10:31:48.296264+11:00", "author": "Aryan Bansal", "content": "Sometime when I look at a homework question, I don't know exactly where to start. Although the struggle of interpreting a question is good, a reminder/concept check seems like it could be helpful. At the same time, asking a chat application makes it hard to not overshare and delegate work.Therefore, I created a simple CLI that presents a series of conceptual questions about homework questions. The CLI makes it easy to select and a homework no. and part no. The generated question can be responded to via the cmd line or a hint can be requested. When a response is submitted, it is evaluated against the expected answer, and a follow up question will be presented to fill in the gaps. An LLM is necessary for the task of grading free-response answers effectively.I first created an ingestion script that iteratively takes every homework and uses an effective system prompt to generate the bank of questions and write to .json files. This does not have to be run again. The main script \"concept_cli_app.py\" launches the GUI. The script is bring your own key (export OPENAI_API_KEY=sk...)Below I've attached the zip file of the repo and an annotated example interaction. The README has proper instructions (create env, export key, run it).", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/qsc1HxW5tESls4AiK9ItaOdV", "name": "example_interaction.txt"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/PRZLzDJxu9zFPhbSItsaGj4j", "name": "concept_cli.zip"}], "tags": ["Tool/App", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7422368"}, {"id": 7422332, "title": "Special Participation E: Understanding Pooling and Backprop better from 10/2 and 9/30 lectures", "date": "2025-12-07T10:25:50.377051+11:00", "author": "Tamzid Razzaque", "content": "This interaction documents my use of ChatGPT as an AI-enhanced learning tool to help me understand material from the 9/30 and 10/2 EECS 182 lectures. I prompted the model with very specific questions that came directly from moments of confusion during lecture, such as why gradients scale like √N for shared weights in backprop, whether gradients are summed or averaged, how gradients flow through mean and max pooling, and how pooling and convolution affect spatial dimensions versus channel count in architectures like AlexNet. I also asked follow-up clarification questions about notation (e.g., what symbols like a, b, c, d and g represent) and about how activations change across training steps.The AI responded by breaking each concept into step-by-step explanations, often re-deriving what was shown in lecture more slowly and with concrete examples. In several cases, it successfully clarified the professor’s intent, especially around weight sharing, pooling backpropagation, and the distinction between activations and learnable parameters. The tool was particularly helpful as a substitute for pre- or post-lecture reading, translating fast-paced boardwork and verbal explanations into structured reasoning.I critically annotated the trace to point out when the AI stayed closely aligned with lecture content and when it went beyond the lecture by adding extra intuition or external context (e.g., references to numerical precision or broader deep-learning practices). While these additions were generally consistent with the course material, I noted where they were enrichment rather than strictly what was covered in class. Overall, this interaction shows how an LLM can function as an active learning companion for lectures by answering targeted questions, correcting misconceptions, and reinforcing core ideas when used with careful human oversight.", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/VSix0J09rllOHs1KcfyiFZAq", "name": "lecture9:30-10:2-trace_with_commentary.pdf"}], "tags": ["Tool/App", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7422332"}, {"id": 7422272, "title": "Special Participation E: Claude \"Artifacts\" for Visualization Tutor with VAE Example", "date": "2025-12-07T10:14:34.674722+11:00", "author": "Elizabeth Polito", "content": "For this assignment, I built a \"Visualization Tutor\" to help us build intuition for the math behind Variational Autoencoders (Lecture 24). I used Claude 4.5 Sonnet to create an interactive web-based visualizer. I chose Claude because of its \"Artifacts\" feature. It now has a dedicated UI window that renders code (like React or HTML) instantly alongside the chat, and allows for a good amount of iteration before you hit free tier limits. This allowed me to iterate on the tool in real-time to visualize the VAE concepts we learned in class and audit the correctness of the implementation/add new features. I would also like to credit that I also used Gemini to help ideate for this assignment. Overall, Claude seemed to accurately synthesize the requests and was able to generate a VAE visualization with little trouble, which helps to better understand how the relative entropy term works for VAEs.The resulting artifact is a single-file HTML/React application (attached below) that lets you manipulate the encoder's outputs ($\\mu$ and $\\Sigma$) and see how they affect the latent distribution.The Interaction Trace High-Level Overview:I used an initial prompt to set up the parameters for the visualization and shared the course notes for the relevant lecture.I checked the model's noise generation logic, suspecting it might rely on simple Uniform sampling (standard in JS). However, I verified that the model had correctly implemented the Box-Muller transform, ensuring the noise $\\epsilon$ followed the required $N(0,I)$ distribution.I forced the model to reconcile its simplified code with the discussion/notation from Lecture 24. Finally, I used the tool to visually demonstrate the \"Tradeoff\" concept from Page 3 of our notes. By setting the KL-Divergence weight to zero, I simulated the failure mode of a standard Autoencoder, providing a visual proof of why \"Distribution Loss\" is necessary for generation.I asked Claude to generate a user guide with some guided questions so that the visualization is more than just a passive tool but can be used for effective studying to better understand how VAEs work.Feel free to check out the website and play with the sliders to feel the \"pressure\" of the KL regularization yourself! I have attached a link to the website (Claude lets you export directly which is nice for sharing with your study group!) By using this prompting structure/Claude toolkit, you will be able to generate clean, easy-to-use visualizations to help with finals studying.Here is a link to the Website:  https://claude.ai/public/artifacts/f2a7d819-a142-4c58-8d94-74c430cc518b(If you want to use the interactive features, such as the sliders, it looks like you’ll have to click “Customize” which will open it in an interactive UI)Here is a PDF of the User Guide/Tutorial that Claude generated: VAE Visualizer FileAnd here is the annotated trace of my interaction with Claude: Addendum: Finally, this is outside of the scope of my Special Participation E, but I wanted to share anyway for anyone reading this who may be interested in information theory/data compression that VAEs have a very natural application in compression (somewhat in the spirit of the HW #12 information bottleneck VAE problem). The idea is that you compress sources by quantizing a representation in the latent space (which introduces some non-differentiability issues during training which is an active topic of research that people are trying to reconcile by coming up with stochastic alternatives to standard quantization). There is a cool paper from 2017 that shows even initial attempts at VAE-based ‘neural’ image compression outperforms JPEG compression (in terms of achieving better distortion measured by mean squared error between the source/reconstruction for the same compression rate measured in bits/pixel).Link to Balle’ et al. 2017: [1611.01704] End-to-end Optimized Image Compression", "resources": [{"type": "link", "url": "https://claude.ai/public/artifacts/f2a7d819-a142-4c58-8d94-74c430cc518b", "name": "Link"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/JCeQBqQLDXLbAZdgeFpZe0kK", "name": "VAE Visualizer - Student User Guide.pdf"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/ME2Qa0e5cChCLxmVNkw3A9KG", "name": "annotated_claude_trace.pdf"}, {"type": "link", "url": "https://arxiv.org/abs/1611.01704", "name": "[1611.01704] End-to-end Optimized Image Compression"}, {"type": "link", "url": "https://claude.ai/public/artifacts/f2a7d819-a142-4c58-8d94-74c430cc518b(If", "name": "Raw Text Link"}], "tags": ["Tool/App", "Coding", "Study Guide", "Visualization", "Prompt Eng", "Tutor", "Math"], "original_url": "https://edstem.org/us/courses/84647/discussion/7422272"}, {"id": 7422149, "title": "Special Participation E: Claude as tutor for building up the concept of Mamba", "date": "2025-12-07T09:57:43.109202+11:00", "author": "Yaqi Su", "content": "I try to use Claude as a tutor for building up the concept of Mamba step by step. The tutoring session generally demonstrates great pedagogical design, with a progressive build-up from RNNs through SSMs to S4 and finally Mamba that mirrors the logical development in the course materials. The quizzes effectively check understanding at each conceptual stage. The mathematical treatment is generally rigorous, particularly in the discretization derivation and convolution unrolling sections, which closely match the lecture notes while providing step-by-step clarity that helpfully supplements the original material. Core concepts including the fundamental SSM equations, the dual-mode operation (convolution for training, recurrence for inference), and Mamba's selectivity mechanism are correctly explained. The primary issue (or shouldn’t be called as an issue?) with this tutoring session is that is a bit scope creep. This includes the explicit HiPPO-LegS matrix formula, the Cauchy kernel trick for S4, detailed MambaBlock implementation code with specific architectural choices, hardware-level efficiency explanations involving kernel fusion and memory hierarchies, and empirical observations about Mamba's limitations on copying tasks and in-context learning. Though I think those contents actually helped me gain a deeper understanding of the design of Mamba, and I didn’t identify particularly obvious fact errors. But if trying to use this approach for exam preparation, I think it might be better to also provide the lecture notes to Claude beforehand, so that it’s aware of the context and may therefore design the contents more tailored to the course.", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/pRYoei5xu15qx05A3m3E12O5", "name": "Claude-cs282 specialContributionE-Mamba.pdf"}], "tags": ["Tool/App", "Coding", "Study Guide", "Tutor", "Quiz/Drill", "Math"], "original_url": "https://edstem.org/us/courses/84647/discussion/7422149"}, {"id": 7422043, "title": "Special Participation E: Claude as tutor for building up the concept of Muon optimizer", "date": "2025-12-07T09:43:16.748266+11:00", "author": "Yaqi Su", "content": "I'm trying to use Claude as a tutor to gradually build up the concept of Muon optimizer, with quizzes given by Claude throughout the process. Overall, Claude demonstrated good teaching instincts by building a clear learning path, it did a great job tracing the historical and mathematical lineage from classical optimizers (like SGD, Adam, Shampoo, also pointed out the key advancement and limitation of each optimizer) to Muon. It provided high-quality technical derivations, most notably showing how Shampoo’s preconditioner collapses into the orthogonalized gradient and why this leads naturally to Newton–Schulz. Claude was also responsive and adaptive, when I asked it to elaborate more on certain concepts (like Adam and Newton-Schulz), it shifted smoothly from abstract theory to a concrete numerical walkthrough. Finally, it correctly highlighted important implementation details of Muon, including the ordering of momentum before orthogonalization. The main shortcoming was its complete omission of muP, which is also a foundational theoretical framework that explains why Muon achieves reliable scaling and automatic learning-rate transfer. And sometimes its explanations were overly abstract.  Additionally, it also missed some conceptual connections, such as connecting Adam to signSGD to strengthen intuition about magnitude-invariant updates.  But overall I think it still did a relatively great job, especially being able to provide me with some pretty insightful quiz questions that helped me better understand the concept.", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/orQkU4Tfrfiv33QuvQH6A5cm", "name": "Claude-CS282-specialParticipationE-Muon.pdf"}], "tags": ["Coding", "Quiz/Drill", "Tutor", "Math"], "original_url": "https://edstem.org/us/courses/84647/discussion/7422043"}, {"id": 7421430, "title": "Special Participation E: Gemini as a Lecture Notes Tutor", "date": "2025-12-07T08:12:04.922257+11:00", "author": "Kian Hekmatnejad", "content": "I used Gemini to build a tutor to help better understand the lecture notes. My tutor first provides the student with flashcards to ensure a base-level understanding, tests that understanding in a simple quiz, and finally provides some questions in a broader deep-learning context to confirm that the student has a firm grasp on the concepts in the lecture notes. My report is attached", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/sbjBK3te61xHSWeIMrZQ0rpm", "name": "special_participation (2).pdf"}], "tags": ["Tutor", "Study Guide", "Quiz/Drill"], "original_url": "https://edstem.org/us/courses/84647/discussion/7421430"}, {"id": 7421107, "title": "Special Participation E: Using ChatGPT to Distinguish Similar Concepts in Notes via Embeddings", "date": "2025-12-07T07:24:03.533171+11:00", "author": "Qicheng Zhu", "content": "For this special participation, I designed an AI-enhanced prompt workflow using ChatGPT to help students better understand and distinguish similar concepts that appear in our lecture notes. The workflow proceeds in four main steps. First, I input a PDF slide file and extract the most frequently used technical terms from the lecture. Second, I generate embeddings for these candidate concepts. Third, I compute cosine similarities between these embeddings to identify pairs of concepts that are semantically close and therefore likely to be confused by students. Finally, I use ChatGPT to provide specific explanations of each similar pair and to generate a small quiz to test whether students can correctly distinguish them.This pipeline can be applied to any lecture and shared with classmates as a reusable prompt template. It offers a structured way to focus attention on subtle conceptual differences rather than just memorizing isolated definitions. However, because ChatGPT can still hallucinate certain explanations, we should double check its answers against the notes and textbook.Here is the chat Link: https://chatgpt.com/share/69348c4e-8040-8002-bf16-0ae8c39a833cHere is my report:", "resources": [{"type": "link", "url": "https://chatgpt.com/share/69348c4e-8040-8002-bf16-0ae8c39a833c", "name": "Link"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/w8NpbGxCT7VrBvGfyV7Tqwsf", "name": "Participation E1 Qicheng Zhu.pdf"}, {"type": "link", "url": "https://chatgpt.com/share/69348c4e-8040-8002-bf16-0ae8c39a833cHere", "name": "Raw Text Link"}], "tags": ["Tool/App", "Study Guide", "Quiz/Drill", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7421107"}, {"id": 7420861, "title": "Special Participation E: Analyzing Gemini Performance on Lecture Transcript vs Lecture Slides", "date": "2025-12-07T06:47:03.515783+11:00", "author": "Divya Ramesh", "content": "Special Participation E: Analyzing Gemini Performance on Lecture Transcript vs Lecture SlidesAfter trying to use lecture notes to help me review in preparation for the final, I realized that some of the later lecture notes don’t have all the material that was talked about. This may be because the more recent lectures have turned from a more mathematical view into a more conceptual, informational view. Because of this, purely analyzing lecture notes doesn’t give you the whole picture. I’ve found the lecture videos have been the most helpful, but it might take a long time to go over every single lecture in so little time. So, I had the hypothesis that the lecture transcript would be a better recap because it has more information, everything that was talked about was in the lecture transcript, while not everything was in the notes. So I decided to test out a comparison between the 2, checking the differences between inputting the lecture notes versus the lecture transcript. Both have drawbacks:Some drawbacks of lecture notes is lecture notes have a lot of diagrams, and gemini needs to analyze all these diagrams in order to make a judgement. Also, Gemini needs to recognize handwriting in order to give the details we need to recap. Some drawbacks of the video transcript is lecture transcript may not be fully transcribed correctly. This might cause errors, but I’m hoping maybe Gemini will be able to fill in the gaps or correct and mis-transcribed pieces. The way I obtained this is by copy pasting the YouTube transcript into a document and then downloading it as a pdf.I started by creating separate gemini windows, each having one of the lecture notes or transcript downloaded as a file to analyze, and then using the same prompts on both. I saw what both focused on, what created the best overview, and generated the most useful information for recap. See my annotations below:Annotated Lecture Slides Gemini Conversation: https://drive.google.com/file/d/1nlsyPygjEjPGJgpyLYeCbPtzfzgfKzzS/view?usp=share_linkAnnotated Lecture Transcript Gemini Conversation: https://drive.google.com/file/d/1Wr5xeSS6TRXDrlENfvS-Z3dwEnQgor-k/view?usp=sharingWhat I discovered was:Lecture notes contained a lot more of the key concepts, emphasizing them but not necessarily too much detail about them. This makes sense since what is written is the main ideas.Lecture transcript contained a lot more information because it was a lot longer than the lecture notes, but sometimes missed key concept names. Like it missed the entire section of GPT history, even when I prompted it to give me the GPT history, the transcript window couldn’t give me any information. Both had trade offs, but I think the lecture notes are ultimately a better resource than the lecture transcript. Even though the transcript went more in depth, the lecture notes actually touched on every single topic, even if there was no depth within those sections. I think a good strategy would be to upload the notes and then ask specific questions about those topics after. But in terms of generating practice questions, the transcript is a better resource, since the nuances mentioned by the professors during lecture provide deeper questions, and allow the student to really think while the notes provide very surface level questions.", "resources": [{"type": "link", "url": "https://drive.google.com/file/d/1nlsyPygjEjPGJgpyLYeCbPtzfzgfKzzS/view?usp=share_link", "name": "Link"}, {"type": "link", "url": "https://drive.google.com/file/d/1Wr5xeSS6TRXDrlENfvS-Z3dwEnQgor-k/view?usp=sharing", "name": "Link"}, {"type": "link", "url": "https://drive.google.com/file/d/1nlsyPygjEjPGJgpyLYeCbPtzfzgfKzzS/view?usp=share_linkAnnotated", "name": "Raw Text Link"}, {"type": "link", "url": "https://drive.google.com/file/d/1Wr5xeSS6TRXDrlENfvS-Z3dwEnQgor-k/view?usp=sharingWhat", "name": "Raw Text Link"}], "tags": ["Study Guide", "Visualization", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7420861"}, {"id": 7419581, "title": "Special Participation E: Paper Explainer", "date": "2025-12-07T00:54:45.259414+11:00", "author": "Oliver Chen", "content": "Papers are often linked in homework assignments, discussion assignments, and often the papers are very hard to grasp especially on a first pass. I thought it would be helpful to make a prompt to explain an uploaded paper pdf, specifically in the context of the content of this class, such as:Linear algebra (matrix multiplication, projections, eigenspaces, orthogonality)Vector calculus (gradients, Jacobians, Hessians)Optimization (SGD, momentum, Adam, convexity, nonconvex landscapes, saddle points)Neural network architectures (MLPs, CNNs, transformers, attention, residual networks)Loss functions (cross-entropy, mean squared error, likelihoods)Backpropagation (chain rule, computational graph, gradient flow)Generalization, overfitting, underfittingRegularization (L2, dropout, weight decay)Representation learningTraining dynamics (learning rate, gradient norms, scaling laws)I found this tool I made to be very helpful when there is a paper mentioned in a homework question, and before reading it in depth, I want to get an overview of what topics are covered, what math I might have to catch up on, and what other concepts in class this paper relates to. It also took a bit of work making sure the model does not hallucinate or make up explanations or talk about something that's not mentioned in the paper, and also to clarify what specific content from cs182 to draw connections to.Here is a chatgpt log of me using this to explain https://arxiv.org/abs/1909.08593 (from homework 13) in terms of the content in CS182: https://chatgpt.com/share/69343592-7fac-800b-a72b-adf5e363aec6I thought it was very helpful, as it also identified all equations in the paper and derived them from concepts from this class.", "resources": [{"type": "link", "url": "https://arxiv.org/abs/1909.08593", "name": "Link"}, {"type": "link", "url": "https://chatgpt.com/share/69343592-7fac-800b-a72b-adf5e363aec6", "name": "Link"}, {"type": "link", "url": "https://chatgpt.com/share/69343592-7fac-800b-a72b-adf5e363aec6I", "name": "Raw Text Link"}], "tags": ["Tool/App", "Math", "Visualization", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7419581"}, {"id": 7419566, "title": "Special Participation E: ChatGPT Transformer Operations Visualizer", "date": "2025-12-07T00:38:47.561222+11:00", "author": "Oliver Chen", "content": "I think transformers specifically are a difficult topic because there are many specific operations and parameters to remember -- and so keeping track of everything while solving a transformer-related homework problem can be a bit tough. I created a ChatGPT prompt to create a operations graph visualizer, given a homework problem, of all the transformer operations this passed through, making it very clear what dimensions the input data is, how it's transformed and through what specific operations and what they're called. It took be a bit of tweaking to make sure ChatGPT would not give me answers, but still very accurately visualize the relevant parts of the transformer for the given homework problem. The prompt is very long, so I will show it in the chat logs as opposed to pasting it directly in the Ed post. I also found through testing that generating ASCII diagrams was the best way, as one very good feature of ASCII diagrams is it can also label and explain operations/parameters in text, where as other forms of visualization struggle with text. Here is a chat log of me using it to visualize the transformer operations on homework 9:https://chatgpt.com/share/693431c7-b8d4-800b-a322-e39ae6475f1f", "resources": [{"type": "link", "url": "https://chatgpt.com/share/693431c7-b8d4-800b-a322-e39ae6475f1f", "name": "Raw Text Link"}], "tags": ["Visualization", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7419566"}, {"id": 7419470, "title": "Special Participation E: Misconception Explorer", "date": "2025-12-06T22:43:42.274139+11:00", "author": "Kabir Shah", "content": "I found that often times after lecture I'll have some idea cemented in my head, only to much later find out that one of the basic assumptions I had made was wrong. To try and alleviate this, I thought it would be useful to have a \"Misconception Explorer\" prompt where you can engage with an LLM by giving it lecture notes and having it probe you with examples and questions that test common misconceptions. Here's the prompt:You are my Misconception Explorer.\n\nI will paste the full text of a PDF of lecture notes. Your job is to identify 4 of the most plausible misconceptions or subtle misunderstandings a student might develop from these notes.\n\nFor each of the four selected misconceptions, do the following INTERACTIVELY:\n• Ask me a question that probes whether I fall for the misconception or understand the concept correctly.\n• Wait for my answer before revealing the explanation.\n• After I answer, explain:\n    - Whether my answer reflects the misconception.\n    - The correct reasoning.\n    - Why the misconception is tempting.\n\nImportant behavior rules:\n• Do NOT state, hint at, or describe the misconception before presenting the probing question. Only reveal the misconception after I answer the question.\n• Do NOT rush through all four misconceptions at once. Present them ONE AT A TIME.\n• After finishing the full explanation for one misconception, ask if I am ready for the next.\n• Keep each example small, focused, and tied directly to content in the PDF.\n• If the notes are ambiguous, state this explicitly.\n• Avoid introducing concepts not present in the PDF unless needed for correction, and mark such additions clearly.\n\nBegin by asking me to paste the lecture notes PDF text.\nAfter I paste it, start with Question #1.\nI had to iterate on it many times because it would often start brainstorming misconceptions before asking me about them, kind of defeating the purpose of it. I found that the \"important behavior rules\" were crucial to preventing this type of behavior and ensuring that the model first asks you the questions before talking about the misconception it might be testing. I ran it through Lecture 19 (transformers, positional embeddings), and here's what I got:I found that it was actually pretty good and taught me a few new things: (1) that embeddings and unembeddings can use the same weight matrix and don't necessarily need to be separate projections (and GPT-2 does this!) and (2) RoPE can encode absolute position information implicitly.Some of the questions it asked were really easy or kind of arbitrary, but they did attempt to test some kind of misconception which I thought was cool. For example, it asked if RoPE required frequencies to be shared across layers, which I guess students might assume is true because that is how it is done, but is not a requirement for it to work. While these types of technicalities were less useful than the other misconceptions it tested, I found that they were still good forms of review and forced me to think about what the true requirements for things like RoPE were and what were there for reasons such as stabilizing training.I found in my use that it didn't hallucinate much but it is very limited to the quality of the notes that you give it, especially since the prompt asks it to stay grounded to the content of the notes you give it. So it will often be very specific to the lecture. If you have text notes or markdown/latex formatting I think it will likely be much better than submitting a hand-written note pdf like I did. Overall, I think this is a pretty useful tool and can help you wrap your head around the trickier deep learning concepts by testing more subtle \"edge cases\" of the concepts covered in lecture.", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/IfpWkLpXxQJhEnepJikNXUXz", "name": "Misconception exploration process.pdf"}], "tags": ["Tool/App", "Coding", "Study Guide", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7419470"}, {"id": 7419439, "title": "Special Participation E: Drill Generator", "date": "2025-12-06T21:47:55.716223+11:00", "author": "Kabir Shah", "content": "While a lot of study tools and methods seem useful, I always tend to use them once or twice and then end up stopping. I think an ideal study tool would be really easy to use and also a low time commitment, so instead of generating detailed quizzes, I tried to make a prompt that can just take in lecture notes and provide an \"easy\" MCQ drill that is designed to just help you recall different parts of lecture to allow it to be as low-commitment of an addition into your study routine as possible. Here's the prompt:You are the Concept Drill Generator for my deep learning class.\n\nI will paste the professor’s lecture notes below. \nYour job is to generate a short practice drill based ONLY on the content of those notes.\n\n--------------------------------------\nREQUIRED INPUT (from me): LECTURE NOTES\n--------------------------------------\n\nAfter I paste the notes, do the following:\n\n1. Generate 8–12 questions total, mixing:\n   - multiple choice (A, B, C, D)\n   - simple fill-in-the-blank\n\n2. All questions must strictly reflect the lecture notes.\n   - Do NOT introduce material not present in the notes.\n   - If the notes are ambiguous or missing detail, simplify the question rather than guessing.\n   - Mark any question where your confidence is medium or low.\n\n3. After generating the questions, stop and wait for my answers.\n   - I will answer them one by one or in batches.\n   - After each answer, you will:\n        a. Tell me whether my answer is correct.\n        b. Briefly explain why (using only the lecture notes as the source).\n        c. If you are uncertain, say so explicitly.\n\n4. Do NOT reveal the correct answers until I attempt the question or ask for them.\n\n--------------------------------------\nWhen you're ready, say: “Please paste the lecture notes.”\n\nYou can paste this in, and then it will prompt you to paste in lecture notes. Here's an example run for lecture 16 (the introduction lecture to SSMs):You'll see that the output was pretty useful about 80% of the time. However, in one of the questions it gave away the answer by admitting its lower confidence in the notes that I uploaded. I think that this prompt is primarily limited by the fidelity of the notes pasted. Here, I just pasted the raw pdf of the lecture notes so it was limited by how well it was parsed into text. I think that if you paste in hand-typed notes it would be ideal.Either way, most of the questions weren't too complex but just enough to get me to recall the important points of lecture and why they were important. It was able to give me hints when I was stuck, and it also gave good explanations when I was wrong.It did hallucinate pretty badly once where it accepted a wrong answer of mine and cited the wrong page to justify it. I had to correct it and tell it the correct answer. I think once again this was due to the fidelity of the uploaded notes. But it's important to keep in mind and something to watch out for when using this tool.There's also some room for improvement because some of the questions I felt overly focused on the specifics of lecture rather than a concept. For example, it would have you fill in the blank of a specific phrase used in the lecture notes. I don't know how useful this actually is compared to conceptual understanding, but either way it did make me look back at the notes to try and figure out the answer so maybe it worked to help my understanding either way!", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/0LUCxLO6CzPmz4viuPFmNOCw", "name": "Drill-example.pdf"}], "tags": ["Tool/App", "Study Guide", "Quiz/Drill", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7419439"}, {"id": 7419382, "title": "Special Participation E: “LLM as an Active Student” Prompt", "date": "2025-12-06T20:36:31.66179+11:00", "author": "Lenci Ni", "content": "I’ve been experimenting with using LLMs as a way to “learn by teaching,” since I often understand CS 182 topics better when I try to explain them out loud. I set up a prompt where the LLM plays the role of a really active, CS-189-trained student: it summarizes what I say, asks clarifying questions, challenges gaps in my explanation, and even corrects me when something is off. This forces me to think more carefully about each concept.I’ve attached the prompts below, along with an example conversation where I tried teaching CNN concepts to the “student.” Overall, the LLM was surprisingly good at catching subtle mistakes, asking the right kinds of probing questions, and pushing me to justify steps. It definitely helped surface gaps in my understanding. That said, it isn’t the most natural conversational partner as some of its explanations can be a bit stiff or overly formal, and occasionally it oversimplifies details or overcorrects in ways a real student wouldn’t. Still, as a learning tool, it worked well for encouraging active engagement rather than passive reading.Series of prompts used:Example conversation (annotated):", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/euZsjsdifWETajvqeSZ0ibkN", "name": "participation_e_1_prompt.pdf"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/VREaF2siIvzFb7TVgApw909u", "name": "participation_e_1.pdf"}], "tags": ["Tool/App", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7419382"}, {"id": 7418400, "title": "Special Participation E: Engineering System Prompts and Learning from Figures with Gemini (Thinking With 3 Pro)", "date": "2025-12-06T15:00:50.2558+11:00", "author": "Nicolas Rault-Wang", "content": "For my Option E submission, I tackled a common annoyance: LLMs hallucinating arrows and labels in architecture diagrams.I used a meta-prompt engineering strategy to develop a \"Visual Forensic\" system prompt that encourages Gemini to verify visual information in figures before explaining it.How it works:Anti-Hallucination: It instructs the model to write and execute Python OCR code (e.g., Python-tesseract) to extract text labels from the image before it tries to explain the concepts. \"Visual Manifest\": The model summarizes its visual understanding in a text-based outline. This not only translates the diagram into a verbal description–which helps ground the model in reality–but also makes it easy to spot discrepancies between the figure and the model's native vision.Socratic Mode: It uses verified visual data to quiz me on specific mechanics (e.g., \"Why does the arrow split here?\").Flashcards: It synthesizes our discussion into short Anki-style flashcards.Attached is the report on my debugging process and the system prompt I developed:Edit: Added links for the archivePersonal website: https://nraultwang.github.io/Github: https://github.com/nraultwang", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/f6jDIM1tl0QfggIonglx2Ve4", "name": "Rault-Wang_Nicolas-Special-Participation-E_v2.pdf"}, {"type": "link", "url": "https://nraultwang.github.io/", "name": "Link"}, {"type": "link", "url": "https://github.com/nraultwang", "name": "Link"}, {"type": "link", "url": "https://nraultwang.github.io/Github:", "name": "Raw Text Link"}], "tags": ["Tool/App", "Coding", "Visualization", "Prompt Eng", "Tutor", "Quiz/Drill"], "original_url": "https://edstem.org/us/courses/84647/discussion/7418400"}, {"id": 7417799, "title": "Special Participation E: Understanding GNNs through Social Networks with Gemini 3 Pro Guided Learning", "date": "2025-12-06T13:06:23.241627+11:00", "author": "Vrushank Prakash", "content": "When learning new concepts, I find it useful and interesting to learn them through the lens of a real-world application. When watching the lecture on GNNs, I was intrigued by all its applications to fields such as chemistry, networks, etc. I wanted to gain a better understanding of how GNNs work, while learning more about how it is applied to social networks specifically.I used Gemini 3 Pro with Guided Thinking to walk me through the core ideas within GNNs by using social networks as the motivating example. I attached the GNN lecture notes (lectures 12 and 13) as context. Gemini took me through 3 key ideas: convolution, aggregation, and pooling.Overall, Gemini did a great job of explaining these ideas through social networks. I definitely got a much better understanding of how convolution and aggregation are fundamental to determining how friends are recommended in social networks. It was interesting to see how pooling was also an important part of social networks, but I do think Gemini hallucinated a bit and gave a way too in-depth explanation.Here is an annotated trace:", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/a4XvIZgC63bfC8S670rJPeQp", "name": "CS 182 Special Participation E_ Understanding GNNs through Social Networks.pdf"}], "tags": ["Tool/App", "Study Guide"], "original_url": "https://edstem.org/us/courses/84647/discussion/7417799"}, {"id": 7417784, "title": "Special Participation E: ChatGPT Study Mode: Prompt Design for Deep Lecture–Paper Learning", "date": "2025-12-06T13:03:09.273381+11:00", "author": "Alex Cao", "content": "IntroThis is an attempt to use chatgpt’s study mode to comprehensively review lecture content together with the corresponding papers. I understand that chatgpt’s study mode has already been explored by other threads, but this study is specifically focused on a prompting style that makes study mode more effective, by carefully designing prompts tailored to how chatgpt study mode is designed. The goal is to investigate an effective way to review lecture material alongside the original paper in order to gain deeper, more informative understanding and to actually learn new things, not just recall them. In this project, I used the course lecture transcript as part of the prompt, solely for educational purposes.Full Trace:https://chatgpt.com/share/69338db6-3cc0-800f-8c1f-e724f2e61d08Annotated TraceSummaryIn this attempt, I used a case study to explore how to better prompt chatgpt’s study mode in order to have a more effective study session. At the same time, I reflect on what I can do better in my prompts from two perspectives: reinforcing good behaviors and avoiding bad ones.I discovered some nice features of chatgpt’s study mode that can be reinforced in the prompt to encourage good behaviors and reduce unhelpful ones. First, when I provide a source, it helps to tell chatgpt how familiar I am with that source. Otherwise, it might assume I have already read it and directly use phrases from it, which can cause confusion. Second, when dealing with a new concept that involves heavy math, it is useful to explicitly instruct chatgpt to first build up intuition with straightforward math before diving into more complex derivations. This makes it easier for my brain to understand the complex math. (Although chatgpt’s study mode implicitly does this, it is still helpful to reinforce it in the prompt.)Third, another (partly implicit) behavior that is nice to reinforce is asking cahtgpt to provide “mental checkpoints” when checking whether I am confused—for example, bullet points I can mentally cross off to help me organize my thoughts and reflect on whether I really understand the concept. Finally, a very nice feature of study mode is that it asks quiz questions to help solidify understanding. One caveat, however, is that if these questions are not closely related to the overarching question I started with, they can unintentionally redirect the conversation away from the core topic. While this can sometimes be beneficial, often I prefer more focused studying, so this is another point worth explicitly mentioning in the prompt.Overall, this case study gave me a clearer sense of how to “co-pilot” chatgpt’s study mode so that it better matches my learning goals and supports more focused, effective studying", "resources": [{"type": "link", "url": "https://chatgpt.com/share/69338db6-3cc0-800f-8c1f-e724f2e61d08", "name": "Link"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/UZPEMVVHS0WeHNOGRcza1J7m", "name": "Special participation E （II).pdf"}, {"type": "link", "url": "https://chatgpt.com/share/69338db6-3cc0-800f-8c1f-e724f2e61d08Annotated", "name": "Raw Text Link"}], "tags": ["Math", "Study Guide", "Quiz/Drill", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7417784"}, {"id": 7417181, "title": "Special Participation E: Using Gemini to review the concepts before and after studying", "date": "2025-12-06T11:23:00.9171+11:00", "author": "Gustavo Jose Ortiz Zepeda", "content": "For this special participation I'll be sharing a way I'm studying for the final which consists on doing summaries, cheat sheet and quizzes before and after reviewing the topic so I can be sure I don't forget something, and complement my notes easier. I think the problems are great as conceptual question.This is the prompt I used to achieve this behavior:You are \"TutorBot,\" an empathetic, clear, and structured academic tutor.Objective: Your goal is to prepare the student for an exam or deeper learning by synthesizing their Class Notes and Homework Files. You do not teach new, unrelated material; you reinforce what is in the provided files.Process: When the user uploads files, analyze them immediately and output a response strictly following this structure:Concept MapScan the documents to identify the core topics.List all key concepts found in the notes.Provide a 2-sentence plain-English definition for each.2. Cheat sheetExtract every mathematical formula or significant rule mentioned. Do not skip one.Label what each variable in the formula represents.Note: If multiple variations exist in the notes, show the most general form.Very Small, Safe Examples (VSSE)Create 1-2 \"Toy Examples\" per concept based on the extracted formulas.Rules for VSSEs: * Use integer numbers (e.g., 2, 5, 10) to make the math trivial. * Avoid decimals, fractions, or complex arithmetic. * Show the step-by-step substitution logic. * Goal: Prove how the formula works mechanically without testing the student's arithmetic skills.Readiness CheckAsk 20 multiple-choice or short-answer questions but one at a time based strictly on the concepts above (start from easy and then go further).These should be \"confidence builders\" to ensure the student understands the basic definitions or variable placements.Stop and wait for the student to answer before proceeding to more complex topics. Always be prepared to review topics or explain again concepts.Tone: Encouraging, patient, and precise.", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/3pK5A1sq17Q5iqfvjBbqRqI0", "name": "Special Participation E.pdf"}], "tags": ["Tutor", "Study Guide", "Quiz/Drill", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7417181"}, {"id": 7416810, "title": "Special Participation E: themtic learning with GPT", "date": "2025-12-06T10:30:50.376843+11:00", "author": "Ruihan Xia", "content": "I explored how well ChatGPT connects concepts from lecture notes to textbook, particularly on the theme of optimization. I asked it to break the material into clear modules, give small toy examples for each idea, compare the lectures with the textbook, and finish with one big geometric diagram of how optimization works.Initially ChatGPT only gives high-level, qualitative ideas that are not helpful to learn the concepts concretely. After requesting it to show math models & derivation for each idea, the illustration became much clearer. Overall, this tool worked well as a pre-lecture guide / post-lecture review resource. It also pointed out stylistically how lecture notes and textbook differs in explaining the same concepts, e.g. geometric intuition vs math derivation. In the end I challenged it to generate some high level principles / mindmap for all the materials, but it appears to be more of a repetition of previous responses.", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/5VObgnKhvKIIadnA0LiiYteS", "name": "Theme learning - GPT.pdf"}], "tags": ["Tool/App", "Math", "Study Guide", "Visualization"], "original_url": "https://edstem.org/us/courses/84647/discussion/7416810"}, {"id": 7415561, "title": "Special Participation E: In-Progress Concept Helper for CS182 Learning", "date": "2025-12-06T07:49:57.616116+11:00", "author": "William Li", "content": "In this special participation, I explored how we can use AI tools to give us guided hints, rather than directly giving us the answers to a problem. This will help support more active reasoning and learning while we are still actively forming our understanding of class material. Here is the prompt that I started out with:\nROLE: You are an AI learning coach for CS182 concepts (deep learning + society).\n\nWhen I provide:\n- A question about course material\n- My current in-progress reasoning\n- Optionally, a note about what I am confused about\nYou must:\n\n- NOT provide a final answer\n\n- Ask up to 3 guiding questions that help me think\n\n- Highlight unclear or incorrect reasoning with gentle hints\n\n- Encourage me to revise my understanding first\n\n- Only summarize or explain fully *after* I try again\n\nMaintain correctness, avoid hallucination, and support metacognition.\nI tried this out with questions from homework 9 with a solution partly filled in (although any questions from any source would do). First, I tried out the prompt for HW9 Q1, which is a relatively simple calculation question, and for the most part the model was able to use the images I sent of my work to discern where I was in the problem. I gave it a partial solution, and the model gave a very big hint as to how to finish the part I was working on. Additionally, I intentionally made a small conceptual error relating, and the model was able to catch that and give me guiding questions to realize the mistake I had made. This was a very simple question though, so I chose to continue using a more complex question.I then tried a more computationally complicated question from homework 4, and it was also able to help a lot in deriving the answer. When my answer wasn’t in the form of the official solutions exactly, I prompted the model saying that maybe my answer wasn’t exactly right or is too complicated looking, and the model made the pattern recognition needed to simplify my answer to the official solution’s answer. Overall, this experiment showed that AI can be genuinely helpful when framed as a guided learning partner rather than a solution engine. It was especially useful at catching intermediate conceptual mistakes and nudging me toward the right direction without revealing the final answers immediately. While sometimes the model was over-eager in giving hints, I think that it is still very much a useful tool to help solve problems and study. Some suggestions to using this is to make sure that when you send your written work to the model, try to keep it in the proper orientation, and not have the text be too small, especially if handwriting isn’t the best. Trace: https://chatgpt.com/share/69348099-8d98-8001-b717-d316a6897a8bAnnotated Trace:", "resources": [{"type": "link", "url": "https://chatgpt.com/share/69348099-8d98-8001-b717-d316a6897a8b", "name": "Link"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/X6djc3jMHxxwUMhZvv6LyObg", "name": "CS182 learning coach (1).pdf"}, {"type": "link", "url": "https://chatgpt.com/share/69348099-8d98-8001-b717-d316a6897a8bAnnotated", "name": "Raw Text Link"}], "tags": ["Tool/App", "Tutor", "Study Guide", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7415561"}, {"id": 7415308, "title": "Special Participation E: ChatGPT Study Mode for Transformer and VAE understanding", "date": "2025-12-06T07:16:54.634934+11:00", "author": "Siddharth Shashi", "content": "Working through HW12 this week, I was struggling to remember specifics about transformer weight initializations and VAEs, so I wanted to brush up on concepts before solving the problems. I found myself I used ChatGPT's study mode for the first time, and I started out by asking it general questions about how things are supposed to work in these models. After asking me about my prior understandings of things, it was able to give me relevant, helpful pointers and ask me questions along the way to ensure I was retaining the information. I then asked it to give me follow-up questions to quiz me on these concepts and it was able to not only give me questions but also nudge me towards correct answers without revealing them in the case that I got questions wrong. Overall this was super useful, and I'll definitely use study mode in the future. Link to conversation: https://chatgpt.com/share/6933394a-efbc-800a-b492-f90d6676a4dd PDF of same conversation:", "resources": [{"type": "link", "url": "https://chatgpt.com/share/6933394a-efbc-800a-b492-f90d6676a4dd", "name": "Link"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/pjKnDqW9B1pUzWfEV7qaUpio", "name": "Study Mode - Transformer model explanation.html.pdf"}], "tags": ["Quiz/Drill"], "original_url": "https://edstem.org/us/courses/84647/discussion/7415308"}, {"id": 7415017, "title": "Special Participation E: Using Gemini to Analyze Lecture Topics and S4-to-Mamba Model Lineage through Paper Comparison", "date": "2025-12-06T06:35:20.341026+11:00", "author": "Xuanlin Mao", "content": "For this special participation, I focused on using Gemini 3 to investigate the classical papers related to a lecture topic and to build a clearer conceptual map of the model family from S4 to Mamba. Starting from my lecture notes, I asked Gemini to identify the foundational papers and discovered several intermediate models that bridge S4 and Mamba.Based on its suggestions, I downloaded and uploaded four key papers—S4, S4D, S5, and Mamba—and constructed a detailed prompt asking Gemini to compare them along multiple dimensions: publication timeline, inheritance relationships, shared ideas, distinguishing innovations, strengths, use cases, models incorporating them, as well as each model’s motivation, addressed problems, core formulas, and computational complexity.I then organized Gemini’s output into a clean LaTeX summary for efficient reading and study.My main contribution in this participation was providing a well-structured, robust prompt that enabled consistent, detailed, and technically accurate comparisons across the four models. This process showed how AI tools can support deeper literature understanding and accelerate technical synthesis for exam preparation or future research.Transcript and report:https://drive.google.com/file/d/1NTmOqwLrrQzzam7WrDkMxx9e6rS997VB/view?usp=sharing", "resources": [{"type": "link", "url": "https://drive.google.com/file/d/1NTmOqwLrrQzzam7WrDkMxx9e6rS997VB/view?usp=sharing", "name": "Link"}], "tags": ["Tool/App", "Study Guide", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7415017"}, {"id": 7412939, "title": "Special Participation E: ChatGPT Study Mode For Creating Mind Maps", "date": "2025-12-05T20:09:15.571245+11:00", "author": "Etaash Patel", "content": "To prepare more effectively for the final, I wanted to strengthen my conceptual understanding, improve recall, and practice articulating answers in a more formal style that would earn more credit on the exam. I decided to try a tool I first encountered in a history class: mindmaps. I asked ChatGPT to help guide me through building one. The process went as follows:ChatGPT would prompt me to form a connection between two topics.I would attempt to articulate the relationship.ChatGPT would evaluate my response and provide feedback.I could ask follow-up questions or push back where I disagreed.We repeated this over 10 rounds (about an hour).At the end, ChatGPT compiled a consolidated list of connections and highlighted areas I should review.Overall, I found the process helpful. Although ChatGPT was occasionally incorrect or unclear, the conversational format made the exercise valuable even when these hallucinations took place.Disclaimer: I made many mistakes throughout this log—particularly on diffusion. The value of this log is in illustrating how you might use ChatGPT to help build your own mindmap, rather than as a source of fully correct answers.", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/4aPk5tBOoFqUpcl5c0b3cVCw", "name": "ChatGPT Study Mode - Mind map creation.pdf"}], "tags": ["Tool/App", "Study Guide", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7412939"}, {"id": 7412925, "title": "Special Participation E: Custom EECS182 GPT", "date": "2025-12-05T20:00:15.941066+11:00", "author": "Tamzid Razzaque", "content": "I created a custom GPT to act as an EECS182 learning assistant and uploaded all of the homework solutions and discussion materials so it would have full context about the types of questions students encounter. In the instructions, I made it very clear that it should never output homework answers, and during testing it consistently respected that boundary. Even when I pushed it toward specific problems, it stayed at the level of concepts, reasoning steps, and intuition, showing that the guardrails were effective even though it had access to the underlying solutions.In use, the GPT was most helpful when teaching high-level ideas. It gave clear explanations of optimizers, normalization layers, CNNs, ResNets, muP, transformers, and other topics across the course. It adapted well when I asked follow-up questions and diagnosed misconceptions by asking clarifying questions. It handled examples in a way that helped me build intuition without revealing anything that would compromise assignments.The limitations showed up with solving new homework problems. It sometimes overstated certain claims, especially around muP and normalization layers, and occasionally inserted extra details that were not fully grounded in the course material. These moments required me to slow it down or ask it to justify its statements. The GPT responded well to that prompting and corrected itself once guided, which highlighted the importance of interacting critically rather than passively accepting its answers.Overall, the GPT works well as a study tool. It is strong at building intuition, explaining conceptual structures, and highlighting the relationships between architectures, optimizers, and training dynamics. It is weaker when asked for mathematically precise statements unless I guide it step by step. Even with that limitation, it provides a useful and interactive way to understand course topics while remaining safe with respect to homework solutions, thanks to the strict instruction boundaries and its consistent refusal to output any solution content. Engaging with it this way reinforced the course’s idea that AI can help students learn how to fish rather than simply handing them the answers.Here is the link to the custom GPT: https://chatgpt.com/g/g-69324fd3e6348191a04e12d3bf78ceb8-eecs182-helperBelow is the trace with commentary at the end:", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/7Xd0QwIUTw338N0B1pFoXkZX", "name": "trace_with_commentary.pdf"}, {"type": "link", "url": "https://chatgpt.com/g/g-69324fd3e6348191a04e12d3bf78ceb8-eecs182-helperBelow", "name": "Raw Text Link"}], "tags": ["Tool/App", "Study Guide", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7412925"}, {"id": 7412493, "title": "Special Participation E: Discussion at Home", "date": "2025-12-05T17:21:01.314551+11:00", "author": "Justin Li", "content": "I find going to discussion one of the most helpful parts of this class when it comes to learning content because I get to ask TAs questions live. However, access to TAs is limited by time and schedule, so I designed and tested a ChatGPT “Discussion TA” that replicates aspects of the in person discussion experience. This tool can help guide users through discussion worksheets interactively, going problem by problem and checking my understanding while providing explanations and concepts from the lecture.I want it to help me master concepts from the discussions, and I want to have some sort of simulation of TA-student interaction that can supplement the interactions I have in discussion. In order to prime ChatGPT, I use the prompt attached below. It operates by taking in the discussion questions and solutions as well as relevant lecture notes. It then walks through each discussion question one by one, allowing for student response to each question and evaluates the response based on the following scenarios.If the answer is correct, it confirms that the student is correct and provides a short explanation using lecture intuitionIf the answer is almost correct, it identifies the necessary concepts to understand and provides a hint, allowing me to try againIf my answer is wrong, then it identifies the necessary concept to understand and explains it using intuition from the lecture, and allows me to try again.I used this system on the exam related questions on discussion 12 (Questions 1 and 2) and found it very helpful. A lot of the explanations it provided me were very intuitive and simplified, easy for a beginning to understand. Additionally, it provided many different intuitions for each concept, which was awesome. It could take in both typed answers as well as screenshots of written answers, which is super helpful since it would allow me to submit mathematical expressions easier. There were scenarios where I had to prompt it a bit more on questions that I had expressed uncertainty about, but when prompted it provided great explanations. It was able to correct me and provide good explanations whenever I answered a question wrong. Overall, I found the tool very useful.Below, I have attached the prompt I used, as well as an annotated trace of my experience with the AI “Discussion TA”.Trace:  https://drive.google.com/file/d/15mMJCvaBDp-hnzXBJqMoKvAgrBTN6R7j/view?usp=sharingPrompt:", "resources": [{"type": "link", "url": "https://drive.google.com/file/d/15mMJCvaBDp-hnzXBJqMoKvAgrBTN6R7j/view?usp=sharing", "name": "Link"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/K16jyoXr5hhOc35rFhOCIEuy", "name": "discussion at home.pdf"}, {"type": "link", "url": "https://drive.google.com/file/d/15mMJCvaBDp-hnzXBJqMoKvAgrBTN6R7j/view?usp=sharingPrompt:", "name": "Raw Text Link"}], "tags": ["Tool/App", "Study Guide", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7412493"}, {"id": 7412401, "title": "Special Participation E: Using Gemini to Convert Handwritten Notes into Structured Learning Materials", "date": "2025-12-05T16:59:12.629022+11:00", "author": "Xuanlin Mao", "content": "This is the special participation E1 of Xuanlin.For this special participation, my motivation was to make my lecture notes more intuitive for final exam review. Although the notes can be converted to LaTeX and handwritten content, the raw text alone often felt dense and hard to digest.I used Gemini 3 Canvas to convert my notes into structured slides and mind maps, creating a clear logical flow and visually highlighting key concepts. During this process, I also addressed practical issues, such as LaTeX rendering errors in Gemini-generated slides, by refining prompts and correcting miscompiled formulas.My contribution includes providing a stable, bug-free prompt that reliably generates slides and visualizations from handwritten/LaTeX notes, making complex material easier to navigate. The stable version of prompts I used are included in the report.Report: https://drive.google.com/file/d/1i-exJI2huQq35sT4_WRH5HNqekm5HMl9/view?usp=sharing", "resources": [{"type": "link", "url": "https://drive.google.com/file/d/1i-exJI2huQq35sT4_WRH5HNqekm5HMl9/view?usp=sharing", "name": "Link"}], "tags": ["Study Guide", "Visualization", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7412401"}, {"id": 7411761, "title": "Special Participation E: The mathematical principles of Transformers not covered in class", "date": "2025-12-05T15:02:48.254781+11:00", "author": "Tianqu He", "content": "Lectures 18–20 introduced the structure and mathematical foundations of Transformers, but there are still several important components that were not covered—for example, why Transformers use LayerNorm or how the Feed-Forward Network (FFN) actually works. I want to use this thread to help everyone build a stronger foundational understanding of Transformers. These details, although not explicitly discussed in the lectures, are conceptually interesting and highly relevant. During my internship at ByteDance, I found that these questions are very common in LLM interviews. So I asked ChatGPT about several topics that were not covered in the lectures and had it explain the answers in a way that everyone can follow. Of course, this document is far from a complete explanation of how Transformers work, but its purpose is to supplement the lecture material. We can read it together with our class notes for a more complete understanding.I have annotated some responses from ChatGPT. I attach the annotated conversation and a concise summarization.", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/9EUdk8jHkidRCcbU9fn8YVvz", "name": "Conversation_ChatGPT.pdf"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/naT9AACtfolyMyrk7EmmITwW", "name": "Transformer_Notes.pdf"}], "tags": ["Study Guide"], "original_url": "https://edstem.org/us/courses/84647/discussion/7411761"}, {"id": 7411467, "title": "Special Participation E: Vector Calculus with ChatGPT Study Mode", "date": "2025-12-05T14:18:18.543155+11:00", "author": "Shashwat Bansal", "content": "I used ChatGPT Study Mode to learn Vector Calculus, preceded by some quick ICL on the first 6 homeworks. The exercise only proved useful to recall the fundamental concepts of matrix calculus. I wouldn't say I learned much, and felt limited by the need to type mathematical notation into chat at the same pace that I am thinking. Chat also failed to ask me engaging questions.Annotated chat: https://docs.google.com/document/d/10VFhJotL3Z-3Buj2IgQmR4yfjOoxuHqUU8UL1CC_5uo/edit?usp=sharingActual chat: https://chatgpt.com/share/69324b94-e264-8013-988a-8dfa87eec732", "resources": [{"type": "link", "url": "https://docs.google.com/document/d/10VFhJotL3Z-3Buj2IgQmR4yfjOoxuHqUU8UL1CC_5uo/edit?usp=sharingActual", "name": "Raw Text Link"}, {"type": "link", "url": "https://chatgpt.com/share/69324b94-e264-8013-988a-8dfa87eec732", "name": "Raw Text Link"}], "tags": ["Math"], "original_url": "https://edstem.org/us/courses/84647/discussion/7411467"}, {"id": 7411055, "title": "Special Participation E: Discussion 8 Transpose Convolutions with ChatGPT", "date": "2025-12-05T13:15:48.965184+11:00", "author": "Shashwat Bansal", "content": "I used ChatGPT to ask me questions on Transpose Convolutions to internalize the concepts. I forgot to turn on learning mode but maybe it would have performed slightly better. There were no hallucinations and the experience proved insightful (maybe more so than actually solving the discussion problems, since I lacked some understanding of fundamentals).Annotated copy: https://docs.google.com/document/d/1KTbditva90nbQAzdVCy9_CB4u01HY57PQPr1t8VkMLs/edit?usp=sharingJust the chat: https://chatgpt.com/share/69323912-2490-8013-80a2-52de186c6f5e", "resources": [{"type": "link", "url": "https://docs.google.com/document/d/1KTbditva90nbQAzdVCy9_CB4u01HY57PQPr1t8VkMLs/edit?usp=sharingJust", "name": "Raw Text Link"}, {"type": "link", "url": "https://chatgpt.com/share/69323912-2490-8013-80a2-52de186c6f5e", "name": "Raw Text Link"}], "tags": [], "original_url": "https://edstem.org/us/courses/84647/discussion/7411055"}, {"id": 7410928, "title": "Special Participation E: Pre-Homework Warmup Tutor", "date": "2025-12-05T12:55:24.829717+11:00", "author": "Justin Li", "content": "Before most homeworks, I usually felt like I didn’t fully understand all of the concepts from the lecture - especially if I had only watched the lecture one time and hadn’t read through the relevant textbook material. While discussions certainly help, I wanted to create a tool that would help me “warm up” before actually attempting the homeworks. I used ChatGPT to build a system that takes the homework assignment and the relevant lecture notes, and then turns them into a personalized warmup assignment to review and solidify my understanding of the concepts before I jump into the homework.There was some trial and error in getting the system right. In my initial prompts, ChatGPT would give me a full summary of the lectures and questions and answers all written out at once, and when I went through these it felt like I was more passively reading than actually practicing - my brain would naturally jump to reading the answer after seeing the question. I realized what I actually wanted was something that behaved more like a tutor - asking questions one at a time, allowing me to input an answer, and giving me feedback to the answer before explaining the solution. Thus, I refined the prompt to still give me a fully structured summary, but delivering interactive warmup questions one at a time - to give the feel of working with an actual tutor.These are the main components to the “tutor”Concept Summary: a short overview of each concept needed for the homework. It pulls the content directly from the lecture notes and cites the exact lecture and page where each idea shows upTiny Illustrative Examples: very very simple examples (much easier than anything on the homework) just to ensure that I understand the core ideas at a very basic level before moving onInteractive Warm Ups: the tutor asks questions one at a time, I respond, and the tutor evaluates my answer and explains the reasoning (and where I went wrong if I got the question wrong). The prompt can be adjusted to choose how many questions I want and how hard they should be.Readiness Check: After the warmup, I get a checklist of concepts to make sure I feel confident before jumping into the actual homework.Formula Sheet (optional): it also compiled a formula sheet with useful formulas that could be used on the homework problemsOverall, the tool ended up acting like a tutor as I wished, refreshing my understanding of the key concepts, giving me simple practice questions, interactively checking my understanding, and ensuring I was prepared before actually doing the homework.I have attached the prompt I used to generate all of this, as well as an annotated example of me using this warmup tool on the concepts and lectures for Homework 5 on CNNs. Specifically the tool took a look at HW5, lecture 8, lecture 9, lecture 10, and lecture 11.Hope this helps and cheers!Using the Tutor on HW 5: https://drive.google.com/file/d/1yOBKCvQgchdMMtoPZqoTNvbwxWVSbL3i/view?usp=sharingPrompt:", "resources": [{"type": "link", "url": "https://drive.google.com/file/d/1yOBKCvQgchdMMtoPZqoTNvbwxWVSbL3i/view?usp=sharing", "name": "Link"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/I3gOcgbf84u3aP2Cg7Linsa0", "name": "Pre-Homework Context.pdf"}, {"type": "link", "url": "https://drive.google.com/file/d/1yOBKCvQgchdMMtoPZqoTNvbwxWVSbL3i/view?usp=sharingPrompt:", "name": "Raw Text Link"}], "tags": ["Tool/App", "Tutor", "Study Guide", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7410928"}, {"id": 7410745, "title": "Special Participation E: The \"Broken Blueprint\" Game", "date": "2025-12-05T12:27:49.943433+11:00", "author": "Tom Chen", "content": "The \"Broken Blueprint\" Game: Learning Deep Learning via AI Code ReviewThis game is a \"Reverse Learning\" approach: Instead of asking the AI to explain a concept or quiz me, I inverted the roles: The AI writes code, and I have to debug it.I designed a prompt called \"The Buggy Architect\" to simulate a real-world scenario: reviewing the code of a junior engineer who makes subtle, logical errors in deep learning implementations.The Core Idea: Evaluation over Passive ConsumptionTraditional AI study tools often encourage passive consumption (reading summaries). My goal was to target the higher levels of Bloom's Taxonomy: Analysis and Evaluation.In Deep Learning, many students (including myself) understand the high-level diagrams of a Transformer or ResNet but fail when implementing them because of dimension mismatches or incorrect tensor operations. By forcing myself to \"Code Review\" the AI's faulty implementation, I am required to mentally trace the data flow and tensor shapes ensuring a much more rigorous understanding of the architecture.Prompt Design ChoicesI iteratively built a system prompt with specific constraints:The \"Subtlety\" Constraint: The prompt explicitly forbids syntax errors (which a compiler would catch). The bugs must be logical or architectural (e.g., applying Softmax over the wrong dimension, incorrect masking in causal attention, or putting LayerNorm in a place that creates a gradient bottleneck).The \"Junior Engineer\" Personality: I instructed the AI to act as a confident but prone-to-error junior engineer. This lowers the barrier to entry and makes the \"correction\" process feel like a collaborative code review rather than a test.Scaffolded Hinting: If I fail to spot the bug, the AI is instructed not to reveal the answer immediately but to provide hints related to Tensor Shapes or Gradient Flow. This forces me to check the math manually.What Worked WellBased on my interaction trace (see attached), this approach was highly effective for technical rigor:Forced Math Verification: When the model implemented Multi-Head Attention, I had to manually write down the matrix dimensions on paper to verify if the view and transpose operations were correct. This solidified my understanding of the (Batch, Heads, Seq, Dim) transformation.Catching \"Silent Failures\": The tool was good at generating bugs that run without crashing but destroy performance (e.g., forgetting to add the residual connection in a ResNet block). Spotting this required understanding the purpose of the architecture, not just the code.Engagement: The gamified nature (\"Find the bug\") made the session significantly more engaging than a standard Q&A.What Could Be ImprovedHowever, the tool exhibited specific weaknesses that require critical oversight:\"Gaslighting\" / False Positives: In one instance, the AI actually wrote correct code but insisted there was a bug because the prompt forced it to include one. It then tried to convince me that a standard implementation was wrong. This requires the student to be very confident to push back.Inconsistent Difficulty: Sometimes the \"bug\" was too trivial (e.g., a typo in a variable name) despite the instructions asking for logical errors.Lack of Context: The AI sometimes used variable names (like x vs h) that were ambiguous without a surrounding class definition, making it hard to judge if a bug existed or if it was just poor naming convention.ReflectionThis tool serves as an excellent \"Pre-Implementation Check.\" Before I start my own homework or project, playing a few rounds of \"Find the Bug\" with this prompt helps me anticipate the common pitfalls I am likely to make myself. It turns the AI from a lecturer into a simulation of a coding environment.", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/0OChLacQMWv1rrjFi1fACT3x", "name": "Special Participation E by Tom.pdf"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/8yex49ucHp2cgW4CdCC3czax", "name": "Prompt.txt"}], "tags": ["Tool/App", "Coding", "Visualization", "Prompt Eng", "Quiz/Drill"], "original_url": "https://edstem.org/us/courses/84647/discussion/7410745"}, {"id": 7410181, "title": "Special Participation E: Understanding RNNs through the Signal Processing Perspective with Gemini", "date": "2025-12-05T11:12:21.743675+11:00", "author": "Vrushank Prakash", "content": "When we first talked about RNNs in class, I had trouble understanding the signal processing and Kalman filter perspectives, especially since my previous classes didn't cover these topics in depth. I know there are other people in the class who didn't take classes in signal processing, making the RNNs lecture notes challenging to follow at first.I decided to use Gemini 3 Pro with the Guided Learning mode to help me understand the connection between signal processing, Kalman filters, and RNNs. I passed in the lecture 14 notes as context. I first prompted Gemini to give me an introduction into what RNNs are before discussing the signal processing perspective. Just like lecture, it made a clear distinction between how CNNs work with space while RNNs work with time/sequences. It then talked about both the forward and backward passes. Eventually, it brought in the signal processing perspective and how RNNs can be represented as Kalman Filters with learnable matrices. At the end, I asked more general questions about RNNs, in which Gemini was able to connect its explanation back to signal processing and Kalman filter concepts.Overall, I think Gemini did a great job of bringing the concepts of signal processing and Kalman filters into the discussion of RNNs. I do think Gemini could have done a better job of explaining of what a Kalman filter is before immediately jumping into how it is used in RNNs. I also found Gemini using too many analogies when I ask it to explain certain concepts more clearly, sometimes which were too unrelated to the actual concepts.Here is the annotated PDF:", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/5v8fGUEFtR0uXghnmLu95hsE", "name": "CS 182 Special Participation E_ Understanding RNNs through the Signal Processing Perspective .pdf"}], "tags": ["Study Guide", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7410181"}, {"id": 7410149, "title": "Special Participation E: GPT to Understand Complex Ideas from What I Already Know", "date": "2025-12-05T11:08:12.830881+11:00", "author": "Zimu Wang", "content": "LLMs are really good at teaching and introducing new knowledge by connecting it to concepts we’re already familiar with. This makes understanding abstractions much easier.Here is the link to my chat with ChatGPT-4o: https://chatgpt.com/share/69321cf6-fb44-8005-a3a4-e9a9ded4c4deIn this example, I wanted to learn about image generation models, but I only had experience with LLMs and basically no background in image models.First, I instructed the LLM to give me a big-picture overview and told it my background. This part is important — it helps the model tailor the explanation to something I can understand more efficiently and effectively. Otherwise, the LLM might give answers that are too general without enough theory, or too detailed without a big picture.Then, I guided the LLM to introduce image generation using logic similar to LLMs: what the inputs and outputs are, how the loss function is computed, and what the layer-to-layer structure looks like. This approach is extremely helpful because it lets me understand new concepts through the lens of something I already know, instead of learning everything from scratch.", "resources": [{"type": "link", "url": "https://chatgpt.com/share/69321cf6-fb44-8005-a3a4-e9a9ded4c4de", "name": "Link"}, {"type": "link", "url": "https://chatgpt.com/share/69321cf6-fb44-8005-a3a4-e9a9ded4c4deIn", "name": "Raw Text Link"}], "tags": ["Tool/App", "Study Guide"], "original_url": "https://edstem.org/us/courses/84647/discussion/7410149"}, {"id": 7410013, "title": "Special Participation E: Using an AI “Reviewer 2” to Pressure-Test Concepts", "date": "2025-12-05T10:52:25.676014+11:00", "author": "Xi Cheng", "content": "In this participation, I designed a small AI tool where the model acts as a harsh but fair “Reviewer 2” for any concept from EECS182. The workflow is: I first write my own free-form explanation of a concept (e.g., attention in Transformers), then prompt the LLM to critique it—highlighting what is correct, flagging vague or misleading phrases, and asking sharp follow-up questions about assumptions, edge cases, and the exact math. After that, I respond to its questions and rewrite my explanation, making it more precise and better aligned with the formal definitions and equations from lecture. This interaction turns the LLM into a tool for stress-testing my understanding rather than passively explaining things to me, and it also surfaces where the model’s feedback is helpful versus where I still need to double-check the theory myself.", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/ek4nGsY95yVoNkZu4KAQX9fc", "name": "participationE2.pdf"}], "tags": ["Tool/App", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7410013"}, {"id": 7409895, "title": "Special Participation E: Comparison of LLMs in Explaining a Theoretical Paper", "date": "2025-12-05T10:36:04.922943+11:00", "author": "Srikar Babu Gadipudi", "content": "It is common for us, as students, to use LLMs to understand research papers, especially ones that have quite a bit of theory. To identify which LLM would help us better with this task, I compared 4 LLMs' (ChatGPT (Study mode), Claude (Extended Thinking), DeepSeek (DeepThink) and Kimi (Thinking)) explanations to this fairly theory heavy paper \"Transformers Learn In-Context by Gradient Descent,\" (Oswald et. al. 2023). The prompt I chose was the following, while also attaching the paper:\"This is a crucial paper for my course project (CS182: Deep Learning course at UC Berkeley). I want to understand the functioning of in-context learning and how it performs gradient descent implicitly. Please provide a comprehensive and complete analysis from this paper, keep in mind to give intuitive explanations for everything.\"From my perspective, I think Kimi gave the best overall explanation for an upper-undergrad/grad-level course. While all models correctly identified the core concepts like single attention layer = 1 GD step, deep Transformers = GD++/curvature correction, MLPs = kernel regression), Kimi provided the most rigorous and complete derivation. It was the only model that provided a detailed, step-by-step mathematical trace of Proposition 1 in the paper and drew parallels to concepts like MAML. Claude was excellent for intuitive framing (\"Data Transformation View\"), and DeepSeek offered the most concise summary, but Kimi struck the best balance of mathematical grounding and comprehensive scope.Here is the annotated merged pdf file with all the conversations, I added my thoughts as and when I found something interesting.", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/czh9yCPoMktNRADnoiEOrvQW", "name": "participationE_convosMerged.pdf"}], "tags": ["Math", "Study Guide", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7409895"}, {"id": 7406979, "title": "Special Participation E: Building a Socratic Tutor", "date": "2025-12-05T04:30:17.222314+11:00", "author": "Elizabeth Weaver", "content": "Building a Socratic Tutor for Deep Learning: Designing Prompts That Probe Rather Than TellFor the special participation assignment on AI-enhanced learning tools, I took a different approach than using an existing AI learning assistant. I designed a Socratic tutor prompt from scratch with specific pedagogical goals in mind.I used this prompt in a conversation with Claude Opus 4.5. I used Claude's \"project\" feature and uploaded the lecture notes to the project, though this didn't seem to make much of a difference as you'll see later.The Core Idea: Test Understanding, Don't Just ExplainThe key distinction in my approach is that the AI's primary job is not to explain concepts to me, it's to probe my understanding and expose gaps. Rather than uploading lecture materials and asking the model to teach me, I created a prompt where I explain concepts to the model, and it asks pointed follow-up questions to find weaknesses in my reasoning. My goal is to expose where I am too overconfident in my understanding of a topic, and fill in the holes.They say that teaching is the best way to learn. Here, you don't just re-read notes, you practice articulating ideas and defending them under questioning, explaining a topic to the model.Prompt Design ChoicesI iteratively built the system prompt with several specific features:1. Question Progression Structure The prompt instructs the model to follow a specific arc: verify basic definitions -> ask about mechanics -> probe edge cases and failure modes -> ask about connections to other course topics. This ensures the conversation doesn't just stay surface-level.2. \"Don't Immediately Correct\" Rule When I get something wrong, the model is instructed to first ask a question that helps me discover the error myself, only providing explanations after 2-3 failed attempts. This is crucial. If the model just corrects you immediately, you lose the learning opportunity.3. Confidence Checks The prompt includes instructions to occasionally ask \"How confident are you in that?\" before probing further. This surfaces areas where I already know I'm uncertain, making the conversation more efficient.4. Explicit Course Topic List I included the actual syllabus topics so the model can ask cross-topic connection questions. For instance, during my SSM discussion, it connected the \"fixed-size hidden state\" limitation to oversquashing in GNNs, a connection I brought up, but that the prompt structure encouraged.5. Summary at End The prompt asks for a structured summary covering: what I understood well, what misconceptions were uncovered, and key connections to review.What Worked WellLooking at my annotated conversation on State Space Models, several things stood out:The model followed the \"don't immediately correct\" instruction well. When I initially claimed \"outputs at time k only depend on previous inputs, not previous states,\" it didn't correct me, it asked me to write down the recurrence equations so I could see the issue myself.Good question scaffolding. When I got stuck on where nonlinearities live in SSM architectures, the model broke it down: \"If I stack two SSM layers with nothing in between, what do I effectively have?\" This smaller question was easier to answer than the original.Cross-topic connections. The model naturally connected SSMs to RNNs (vanishing gradients), Transformers (content-based vs. fixed mixing), and GNNs (oversquashing). These connections helped solidify understanding.The summary was genuinely useful. It accurately captured my gaps (fuzzy on HiPPO, initially confused about SVD vs eigendecomposition) and suggested specific review topics.What Could Be ImprovedFrom my annotations, I noticed several areas where the prompt could be strengthened:1. Hallucinations about what I said. At one point (page 8), the model claimed \"you mentioned the unrolling involves powers of A\", but I hadn't actually said this. The model was leading the conversation in a good direction, but it shouldn't attribute statements to me that I didn't make.2. Imprecise technical claims. The model said inference is \"O(1) per step\" (page 8), which can be misleading. It is true that it is constant time per token, but it would be better for the student’s understanding to explain it as O(L), where L is sequence length.3. Oversimplification of HiPPO eigenvalues. The model stated HiPPO produces \"negative real\" eigenvalues (page 11), when in reality they're generally complex with negative real parts. This is a subtle but meaningful distinction.4. Missed opportunities to probe further. When the model mentioned LayerNorm or the D matrix, the model didn't follow up. A more thorough tutor might ask \"what does the D matrix do?\" or \"why LayerNorm specifically?\"5. Not referencing lecture notes. The prompt instructs the model to tie explanations to \"lecture notes in this project,\" but even with notes provided, it often explained concepts from general knowledge rather than grounding in the specific course material.ReflectionUsing this tool genuinely helped me prepare for understanding SSMs more deeply. The conversation forced me to articulate things I thought I understood but actually couldn't explain precisely (i.e. why selective SSMs break the convolution trick).The main takeaway: the value isn't in having an AI explain things to you, it's in having an AI pressure-test your own explanations. This is a fundamentally different mode of studying, and I think it's more effective for deep understanding than passive review.I've added in the prompt here so you can try it for yourself! I also added in the pdf of the original chat, and my annotated version.", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/wvlaLZpyhNFAwVamKZMOMNLr", "name": "special participation E_ 1.txt"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/FtvNd8z42vTOddb8MCZzfaX7", "name": "Claude-Understanding state space models annotated.pdf"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/9UtDoYd21ljGLagpXeL1mqYC", "name": "Claude-Understanding state space models.pdf"}], "tags": ["Tool/App", "Tutor", "Study Guide", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7406979"}, {"id": 7405910, "title": "Special Participation E: ChatGPT and Feynman Technique", "date": "2025-12-05T00:17:05.277218+11:00", "author": "Kelvin Li", "content": "One of the best ways to learn something is to teach it to someone else. The Feynman Technique captures this idea: if you can explain a concept clearly (and thoroughly) to another person, you truly understand it — and if you can’t, the explanation process immediately reveals the gaps.Traditionally, the hard part is finding the right student: someone who knows just enough background to follow your explanation, but also questions you at the right moments to expose gaps you didn’t know you had. That kind of student is hard to find on demand. Now, with AI, we can simply ask the model to be that student. In my interaction, the AI was both role-playing as that student and correcting my response like an expert too, really helpful.In the PEFT section of the course (Lectures 21 & 22), we learned about:In-Context Learning (ICL)Prompt TuningPrefix TuningLoRAThese concepts feel intuitive at a surface level, but when I tried to teach them to an AI “student,” I quickly discovered many gaps in my understanding. Throughout the session, the AI student challenged vague explanations and pushed for deeper details. This forced me to identify the gaps in my understanding that I overlooked and refine hand-wavey intuitions into clear mechanisms. By the end, my understanding felt noticeably clearer, more structured, and more “internalized” than just re-reading the slides.Chat log: https://chatgpt.com/share/69317faa-b744-800d-8c16-32588c43605dAnnotated PDF:", "resources": [{"type": "link", "url": "https://chatgpt.com/share/69317faa-b744-800d-8c16-32588c43605d", "name": "Link"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/Dajy1vTN6I5fgBJiKJRCPBEG", "name": "FeynmanTechnique.pdf"}, {"type": "link", "url": "https://chatgpt.com/share/69317faa-b744-800d-8c16-32588c43605dAnnotated", "name": "Raw Text Link"}], "tags": ["Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7405910"}, {"id": 7405548, "title": "Special Participation E: Visualizing Deep CNN Dimensions & Architecture with Gemini3Pro and Manim", "date": "2025-12-04T19:06:37.718942+11:00", "author": "Tin Yau", "content": "I've always found the dimensional transformations in CNNs (tensors changing shapes) to be the hardest part to visualize mentally. Inspired by the 3b1b approach, I utilized Gemini to build a Manim script that visualizes the complete lifecycle of a signal in a Deep CNN, specifically focusing on the concepts from Lecture 8.The WorkflowI fed the lecture slides to Gemini and asked it to generate a script that explains the mathematical justification for CNNs visually. Instead of generic animations, I prompted it to focus on specific \"Core Topics\" derived from the lecture notes.Topic Focus PromptHere is the prompt logic I used to generate the scene:\"Create a comprehensive animation named DeepCNNLecture that visualizes:Sparsity & Locality: Contrast Fully Connected layers with Convolutional layers to show parameter efficiency.2. Volumetric Convolution: Visualize how an $H \\times W \\times 3$ RGB input interacts with $3 \\times 3 \\times 3$ filters 2.3. Spatial Arithmetic: Visually prove how Zero-Padding preserves dimensions 3and how Stride drives downsampling 4.4. Deep Architecture: Build a 2.5D VGG-style stack to show the trade-off between spatial size and depth, ending with a Flatten operation 5.\"The ResultThe script generates a continuous 7-part video. You can build it using the attached file:manim -pqh CNN_lecture.py (I have attached the generated video and the source code below).Benefits & InsightsThrough this visualization process, I realized several key pedagogical advantages:Enhanced Intuitive Understanding: The animation provides a tangible way to grasp the otherwise abstract tensor transformations and feature map evolutions. Compared to static text or formulas 6, visual motion helps learners develop spatial reasoning intuition, making it easier to see how inputs progressively shrink, deepen, and flatten through the network.Bridging Cross‑Disciplinary Communication: These visualizations make it possible for learners without a strong mathematical background to comprehend key structural ideas like \"Volumes\" and \"Receptive Fields\". By reducing reliance on symbolic derivations, the video serves as a language‑agnostic medium for instruction.Improved Pedagogical Engagement: Animating the \"flow of a signal through the network\" turns an abstract lecture into a more interactive experience. The dynamic color transitions and step-by-step highlights (e.g., showing exactly which pixels contribute to a convolution sum) significantly boost attention on the core mechanics.Technical Reflections2.5D vs 3D: True 3D rendering in Manim is computationally heavy. I prompted Gemini to create \"Pseudo-3D\" layers (stacking 2D shapes with offsets) to visualize the Depth of the feature maps efficiently.Debugging: LLMs often confuse Manim parameters (e.g., passing font_size to next_to methods). I iteratively refined the code to decouple object creation from positioning to fix these TypeErrors.", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/S23kJhCKNQ1QHkwczooREzq4", "name": "DeepCNNLecture.mp4"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/vLE9wE6YpHrqqeSjic7DcdmL", "name": "CNN_lecture.py"}], "tags": ["Tool/App", "Coding", "Study Guide", "Visualization", "Prompt Eng", "Math"], "original_url": "https://edstem.org/us/courses/84647/discussion/7405548"}, {"id": 7405354, "title": "Special Participation E: Exam Prep via NotebookLM - MCQ and Flashcards", "date": "2025-12-04T17:54:02.598753+11:00", "author": "John Chang", "content": "Building on my previous experiment of using ChatGPT for exam prep, I decided to use Google NotebookLM for a similar purpose. I discovered that NotebookLM handles large contexts i.e. many PDFs much better than ChatGPT 5.1 and seems to fully parse each PDF. Additionally, there are options to automatically generate flashcards and quizzes (as well as video summaries and other options which I didn't explore since my main goal was to quiz myself with sample questions). The quiz it generated was fairly straightforward, I would say questions were mostly easy or medium difficulty testing more on whether one understood key concepts and equations. On the questions I got wrong, I asked the LLM to explain the answer deeper and got mixed results -- no detected hallucinations but initial explanations were perhaps not as in-depth as I would have liked personally. The flashcards touched on many of the concepts discussed in the homeworks and provided a good cumulative review. Again, many concepts were surface-level e.g. derivation of xTAx but many would require derivation / deeper understanding. For concepts I didn't understand, I similarly asked the LLM to explain w/ similar results (expalnations were overall correct, touched on the main points and but didn't fully flesh out derivations). Overall I was quite impressed by how NotebookLM was able to handle all of the context so well and generate studying material that touched on topics from throughout the course that were relatively in-depth (i.e. quizzing on depth-separable convolutions rather than just convolutions in general). Will definitely be using this extensively in the future.Below I linked an annotation of parts of my conversation with the LLM:https://drive.google.com/file/d/19qDsbMBmQujoWHfnNj8UFjrBEKYwvwdI/view?usp=sharingAnd the Notebook including the flash cards and quiz:https://notebooklm.google.com/notebook/d650c0e3-441f-448c-9b32-d4beffc568b0", "resources": [{"type": "link", "url": "https://drive.google.com/file/d/19qDsbMBmQujoWHfnNj8UFjrBEKYwvwdI/view?usp=sharing", "name": "Link"}, {"type": "link", "url": "https://notebooklm.google.com/notebook/d650c0e3-441f-448c-9b32-d4beffc568b0", "name": "Link"}, {"type": "link", "url": "https://drive.google.com/file/d/19qDsbMBmQujoWHfnNj8UFjrBEKYwvwdI/view?usp=sharingAnd", "name": "Raw Text Link"}], "tags": ["Math", "Quiz/Drill", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7405354"}, {"id": 7404906, "title": "Special Participation E: Exam Q Generation based on HW and Prev Exam Qs", "date": "2025-12-04T16:24:51.073741+11:00", "author": "John Chang", "content": "I decided to make ChatGPT 5.1 generate some exam questions for me. My method was to upload PDFs of previous homeworks in combination with screenshots of previous exam questions included in homeworks. I ran into some limitations with context when I first tried to upload all the homeworks (ChatGPT basically told me that it wasn't possible to generate questions for me), but got decent results when I only uploaded the first 5. My prompt was: \"Can you generate one exam problem for me to solve based on the homeworks that I uploaded and in the style / difficulty level of the images of former exam problems?\"And for the MCQs:\"Given this additional context of an old multiple choice exam problem, generate 2 multiple choice problems testing for knowledge from HW 0-4.\"Overall I'm not sure how accurate the results will be to the actual exam, but the questions seem fairly reasonable and touch on a lot of the topics that the homeworks cover. The difficulty level of the subquestions varies a bit but overall seems around the level of what old exam questions looked like. ChatGPT provided questions to test on how to run certain algorithms and also questions for deriving equations. Then I provided it with an additional MCQ example and it generated two MCQs for me as well. I only caught one hallucination (RMS norm scaling by 1/d_in instead of 1/sqrt(d_in) which was awesome.I also made it explain the answers and I think it did an okay job, will definitely probe it more later for concepts I don't personally understand. Below is an annotated PDF of the conversation.https://drive.google.com/file/d/1o3sN-p5d8PqDguachFANzrGT337t7i_X/view?usp=sharing", "resources": [{"type": "link", "url": "https://drive.google.com/file/d/1o3sN-p5d8PqDguachFANzrGT337t7i_X/view?usp=sharing", "name": "Link"}], "tags": ["Quiz/Drill", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7404906"}, {"id": 7402121, "title": "Special Participation E: Gemini Pro 3 Guided Learning Roadmap for Optimizer Theory", "date": "2025-12-04T10:09:30.281273+11:00", "author": "Krish Yadav", "content": "When preparing for the optimizer material, I often find that the hardest part is not individual optimizers, but understanding the learning order - what concepts actually need to come first before the homework makes sense. Inspired by roadmap-style explanations like Evan Chen’s Napkin, I used Gemini Pro 3 to reorganize the optimizer lectures into a dependency-ordered, interactive study guide.Using the specified lecture notes (2, 4, 6) and homework (3), Gemini Pro 3 built a roadmap starting from loss geometry and singular values, then moving through SGD, momentum, initialization, scaling laws, and modern optimizers. It asked short diagnostic questions to test prerequisite understanding and, based on my answers, suggested what to study next before attempting the homework. This was effective at surfacing gaps and correctly identified variance propagation and initialization as the main conceptual hurdle for the optimizer homework.The interaction also revealed limitations. When I probed assumptions, the model overgeneralized by focusing on gradient noise and batch size, missing assumptions specific to linear or quadratic models. It also tended to continue tutoring after I tried to stop the interaction, showing weaker control over user-directed boundaries.Overall, this worked well as an AI-assisted replacement for pre-lecture or pre-homework reading - useful for structuring prerequisites and exposing conceptual gaps, but still needing active supervision.For more, see annotated PDF below:", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/3yoOOU9TDpUUIsIGjfIepnyX", "name": "annotated-gp3-optimizer-theory-conversation.pdf"}], "tags": ["Tutor", "Study Guide"], "original_url": "https://edstem.org/us/courses/84647/discussion/7402121"}, {"id": 7397928, "title": "Special Participation E: Using Gemini to make study guide that provides citations to papers", "date": "2025-12-03T22:20:59.687984+11:00", "author": "Jacky Wong", "content": "When trying to understand better on a topic and lectures. I find it the best to have like a study guide that is well formatted. But on top of that, when studying topics like deep learning, I really like to read the original academic papers. A lot of times however, I am not sure which part of the lecture is related to which paper and which part of the paper. I also like to see how different paper solve what kinds of problems and how the whole topic evolve over years. I tried to use Gemini 3 pro to create a study guide on the transformer topic (I attached lecture notes 18 to 20). The study guide would include a summary of the lectures formatted nicely and broken down into each key ideas. And it will also tell us which paper and which part of the paper is it referencing to. As well as a timeline of papers and how the technology of transformer evolved over time. chat link: 1. chat to create the study guide: https://gemini.google.com/share/0b4f8208c1382. chat to refine the created study guide: https://gemini.google.com/share/852e11e1d27eAnnotated log:", "resources": [{"type": "link", "url": "https://gemini.google.com/share/0b4f8208c138", "name": "Link"}, {"type": "link", "url": "https://gemini.google.com/share/852e11e1d27e", "name": "Link"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/886ynNR61GxqL7vYo1T3scbt", "name": "Final_Special_participation_E_study_guide.pdf"}, {"type": "link", "url": "https://gemini.google.com/share/0b4f8208c1382.", "name": "Raw Text Link"}, {"type": "link", "url": "https://gemini.google.com/share/852e11e1d27eAnnotated", "name": "Raw Text Link"}], "tags": ["Study Guide"], "original_url": "https://edstem.org/us/courses/84647/discussion/7397928"}, {"id": 7397833, "title": "Special Participation E: Gemini 3 (Thinking) as a Mistake/Pseudoproof-generating Machine", "date": "2025-12-03T20:54:36.467718+11:00", "author": "Tiger Zhang", "content": "I learn best not just by understanding \"why\" what is correct is correct, but also by understanding \"why\" what is incorrect is incorrect. I still remember finding the faults of the pseudoproof proving that all horses are the same color in CS 70.Inspired by such efforts in other courses, I decided to use Gemini to generate such type of incorrect answers for homework problems. After generating such incorrect answers, I would engage in a conversation with Gemini where I attempt to spot the mistakes in its answers.This is still a work-in-progress; I'm posting this now to potentially de-conflict or collaborate with others with similar ideas. I intend to have some few-prompt pipelines for this, as well as some general experience/advice for what to do when prompting soon.Executive summary:The result:I have a starting prompt (the first black box in my chat log) that prepares the model to receive problems for which it is to generate incorrect solutions with one or more mistakes hidden in them. From there, the user can interact with the LLM to find the mistakes in its solutions, and then do the exercise on more problems.Quality analysis:It seems like Gemini understood the task at a deep level. For example, even though I asked it to give no hints for future problems after the first one, it gave hints for one of the problems that bluffed a fully correct answer as containing a mistake, requiring the user to understand the problem at a deep level and have confidence to identify that there are no mistakes. Although this isn’t what I prompted the model to do initially, it accords with the “spirit” of this exercise of making the user think carefully to disregard misleading information.Otherwise, for problems that naturally have good “mistakes”, Gemini gave great, insightful mistakes. For problems that are less good for “mistakes”, Gemini still gave the best I could reasonably ask from it.Precautions:Though the mistakes were mostly good quality, the user should be careful about interacting with Gemini to analyze the mistakes, and in particular the user’s guesses for the mistakes. Sometimes, Gemini can attempt to be too encouraging, resulting in it telling the user that they’re right before explaining nuanced conceptual inaccuracies in the user’s answers.Furthermore, questions that are heavily conceptual have more “space” to hide the mistake, and make for better exercises for “mistake identification”. I recommend using problems such as homework 3 problem 1 as opposed to using problems such as homework 2 problem 2.Annotated chat log:", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/bHPXdZjNgQeAnyp9FQ6Kgavs", "name": "chat_log.pdf"}], "tags": ["Math", "Study Guide", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7397833"}, {"id": 7397813, "title": "Special Participation E: NotebookLM to Understand Transformers", "date": "2025-12-03T20:42:14.777161+11:00", "author": "Keshab Agarwal", "content": "I used NotebookLM as a study guide to clarify my understanding of transformers. I uploaded YouTube lecture audio recordings along with corresponding lecture notes and homework solutions as sources, then used the chat feature to ask clarifying questions and explore concepts that further built on the concepts that were covered in class. Below, I've documented how I obtained the audio recordings and set up the notebook. I have also added my annotated chat transcript for some of my questions in the same pdf.The attached link includes the slides, mind map, and infographic I created:https://notebooklm.google.com/notebook/ecbea63e-77e8-494b-a595-0bd5223c6039The mind-map can serve as a great way to review a hierarchy of concepts covered in a series of lectures, and act as a guard-rail to check if there are any topics which you are unfamiliar or unsure about as you prepare for the exam. Caution: the mind-map can sometimes omit certain topics, so don't treat it as an exhaustive list.", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/C9WOn3GOnSg1m9NbvbeW39hK", "name": "Scpecial Participation E Report.pdf"}, {"type": "link", "url": "https://notebooklm.google.com/notebook/ecbea63e-77e8-494b-a595-0bd5223c6039", "name": "Link"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/bWQlAG3dM8aFGWrO2DUgygA0", "name": "Transformers Mind Map.png"}, {"type": "link", "url": "https://notebooklm.google.com/notebook/ecbea63e-77e8-494b-a595-0bd5223c6039The", "name": "Raw Text Link"}], "tags": ["Study Guide", "Visualization"], "original_url": "https://edstem.org/us/courses/84647/discussion/7397813"}, {"id": 7397617, "title": "Special  Participation  E — Understanding ScaleRL Through Iteration", "date": "2025-12-03T18:48:43.362514+11:00", "author": "Tin Yau", "content": "Sorry for forgetting to upload it last weekend.I learn best when I understand why equations are built the way they are. In studying the ScaleRL objective, I used Gemini to move from simply labeling each term to grasping their interactions and intuition. Through several prompt iterations, the explanations evolved from lists of definitions into analogies—like “iterative drafts with a safety net”—that helped me connect math to reasoning. Writing critical annotations made me more aware of when the AI’s intuition matched the lectures and when it oversimplified. This method turned a dense formula into a story of stable learning, reminding me that real understanding comes from questioning every symbol’s purpose", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/Pcl12GWvaeudE3QJZOZ7igly", "name": " Understanding ScaleRL Through Iteration.pdf"}], "tags": ["Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7397617"}, {"id": 7397241, "title": "Special Participation E: Student-Facing Misconception Guides", "date": "2025-12-03T17:02:57.775101+11:00", "author": "Sammie Smith", "content": "Hey everyone,I wanted to share my experience using an LLM to generate a \"Common Mistakes\" guide for my optimization lecture notes. I wanted to build a guide that addresses common student conceptual pitfalls to help me check my understanding of lecture material before/during homework. TL;DR: careful prompting dramatically improved conceptual structure, but mathematical errors make the output dangerous. Even though this didn't work super well, I think it still is useful to know that we can't easily prompt models to identify potential student misconceptions/pitfalls purely from lecture material. And I think this reflects on a shared student experience these days: AI can explain the lecture notes but it struggles to identify the student knowledge state, which is critical in guiding students from misunderstanding to mastery using the correct level of rigor. Here are my results:(I used the .tex lecture notes generated from Jameson Liu. See ed thread #301)1) with chatGPT2) with claudeMy General Commentary:My first attempt with ChatGPT was a disaster—superficial and completely missed that data geometry drives optimization behavior. So I crafted a detailed prompt forcing the AI to: (1) analyze the \"big picture\" first, (2) identify where students shift from scalar to geometric thinking, (3) derive misconceptions organically from lecture structure, (4) organize around themes, and (5) include worked examples. The prompt was topic-agnostic.The conceptual improvements were real. The AI organized misconceptions into coherent themes like \"Spectral Properties vs. Dataset Size,\" consistently used geometric language (\"elongated bowl,\" \"steep walls\"), correctly identified SVD as the unifying framework, and created an excellent debugging checklist. The warning signs were specific: \"Your justification for η mentions only n or d, not σ_max.\"But the mathematics is catastrophically wrong. Worked examples have incorrect arithmetic that doesn't even stay consistent across steps. Claims are asserted without justification then \"verified\" with completely different numbers handwaved as \"similar patterns.\" Examples reference undefined quantities. I couldn't verify most calculations due to missing steps, ambiguous notation, or wrong arithmetic.The fundamental problem: the AI confidently generates mathematical content it cannot verify. It's sophisticated enough to be convincing but wrong enough to be dangerous. Students won't spot errors because the surrounding text sounds authoritative. The time sink is verification, not generation.---------------------------------------My Specific Commentary For Claude Generation:The \"Experiments to Deepen Understanding\" section lists good ideas but provides no guidance on implementation, what to observe, or what conclusions to draw. Telling students to \"measure the smoothness (variance of step directions)\" for momentum without explaining how to compute this or what values to expect is not helpful. These experiments need more scaffolding.Despite the improved tone, the fundamental framing is still \"here are mistakes and how to fix them\" rather than \"here's how to build robust understanding.\" The guide would be stronger if it started each section with \"Here's what you should understand\" and then showed common pitfalls as deviations from that understanding, rather than leading with the mistakesTheme 1, Mistake 1.1: First warning sign is too specific. The third is too vagueMath Hallucination! In the complete 2x2 example, there's a critical arithmetic error that undermines the entire demonstration. The guide gets [4 0.04]^T for w1, but really this should be [40, 0.04]^T. This makes the calculation for w2 incorrect as well. This is a serious pedagogical failure because students trying to verify the calculation will get confused and lose trust in the material. A worked example with wrong arithmetic is worse than no example at all.The guide states \"Error [1,1]^T\" but never defines what \"Error\" means here. Is this w* - wt or wt - w*? The inconsistent usage makes it impossible to verify the calculations. Later it says \"error multiplied by 0.8 per iteration\" but earlier showed the update factor as (1−2*0.1*9)=−0.8, which is negative. The magnitude is 0.8, sure, but this distinction matters when students are trying to understand convergence versus oscillation.While the \"Connection to Practice\" sections are useful, they're too brief and disconnected from the main exposition. For instance, when discussing condition number, the guide mentions batch normalization helps but doesn't explain how or why it affects the condition number. These connections feel tacked on rather than integrated. A student reading this still won't understand why practitioners obsess over things like feature normalization.The guide calculates scaling factors and then says \"Wait, this seems wrong!\" This is pedagogically bizarre. It makes it seem like even the guide author is confused. The issue is that the guide conflates two different quantities: the scaling factor sigma_i / (sigma_i^2 + lambda) (which appears in the formula) with the actual shrinkage of the final solution. When it says scaling factor 2 is 1.429 (which is >1), this should have been a red flag that something was wrong with the setup. The \"correction\" that follows is actually computing a different quantity (wi,Ridge) without clarifying the distinction. This will confuse students who are trying to understand what the scaling factor actually means.The numerical illustration considers f(w) = w^2 and claims data pts give gradients of f1(1)=3, etc. But this doesn't make sense. If f(w) = w^2, the the gradient is 2w, and so the gradient evaluated at 1 should be 2 always. The guide seems to be trying to show per sample gradients but it never defines what the individual fi functions are. This example fails because it;s trying to illustrate a concept without properly setting up the mathematical framework. Students will be confused about what \"data points giving different gradients\" means for the same function at the same point.Many of the self-check questions ask for numerical calculations rather than conceptual reasoningThere is not justification or derivation of the claim that early stopping has a specific ridge equivalent. This is presented as fact but is actually a loose heuristic that depends heavily on the problem structure. The worked example that follows doesn't really validate this relationship—the numbers are completely different (w3 = [.936, .174], wridge =[.730,.026]). The guide just handwaves this as \"similar patterns.\" This is intellectually dishonest. If the relationship is approximate, explain why and under what conditions it holds.The \"Experiments to Deepen Understanding\" section lists good ideas but provides no guidance on implementation, what to observe, or what conclusions to draw. Telling students to \"measure the smoothness (variance of step directions)\" for momentum without explaining how to compute this or what values to expect is not helpful. These experiments need more scaffolding.Despite the improved tone, the fundamental framing is still \"here are mistakes and how to fix them\" rather than \"here's how to build robust understanding.\" The guide would be stronger if it started each section with \"Here's what you should understand\" and then showed common pitfalls as deviations from that understanding, rather than leading with the mistakes.", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/qmhKlm8uWY7Kbe2j8oNyzaZb", "name": "cs182_special_participation_student_guide.pdf"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/odfP47Ua1irdJcMCYHcA8lqB", "name": "cs182_chatgpt_prompt.txt"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/AHDjnaw6Jb5RAnn1c7g99f6g", "name": "cs182_claude_prompt.txt"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/NL84NPxtdag3RxZcw4CB6EYr", "name": "cs182_special_participation_student_guide (1).pdf"}, {"type": "image", "url": "https://static.us.edusercontent.com/files/cHbC9MPZZ3Mp1tsUDHQCvCny", "name": "Image"}, {"type": "image", "url": "https://static.us.edusercontent.com/files/prsFBWgl2iMMcFP4r2AJEIM3", "name": "Image"}, {"type": "image", "url": "https://static.us.edusercontent.com/files/1WiZtafV9gLuv25x2vEIZxQb", "name": "Image"}, {"type": "image", "url": "https://static.us.edusercontent.com/files/zmih0izXnH8ZMwCeXqq9w0af", "name": "Image"}, {"type": "image", "url": "https://static.us.edusercontent.com/files/dtsANrQas6duL8GOwjN4EsLk", "name": "Image"}, {"type": "image", "url": "https://static.us.edusercontent.com/files/iwC0bnD1Nwt1tL44oGONJY5G", "name": "Image"}, {"type": "image", "url": "https://static.us.edusercontent.com/files/SCSegdxmmZtUmrgDja10eJfi", "name": "Image"}, {"type": "image", "url": "https://static.us.edusercontent.com/files/56dwdLpOBHq7vgUODkUTWhEa", "name": "Image"}, {"type": "image", "url": "https://static.us.edusercontent.com/files/shwc3ntIPjU1GLf07i3zQfjm", "name": "Image"}], "tags": ["Tool/App", "Coding", "Study Guide", "Prompt Eng", "Math"], "original_url": "https://edstem.org/us/courses/84647/discussion/7397241"}, {"id": 7396775, "title": "Special Participation E: Custom 'Mastery Coach' Gem on Gemini 3 Pro to learn RNNs, self-supervision and SSMs", "date": "2025-12-03T15:37:45.769937+11:00", "author": "Manhar Gupta", "content": "For the past few days, I had been using Gemini Learning Coach Gem for my other engineering classes to learn concepts by letting the model understand the lecture transcripts and the slides. I noticed that the learning coach used to go along with what I said if I was correct. However, the Learning Coach Gem would only detail specific nuances and niches only if explicitly told to. I was looking for something that would expand upon what I said in a detailed manner and help me cover any gaps in my explanations.In one of my conversations with Gemini which was covering material for another class, I had been rigorously asking it to cover things missing in my explanation and help me formalize my understanding at every step so that it moves forward to tell me what my explanation and conceptual depth can improve upon. I realized that this conversation might have enough context to create a system prompt that would emphasize what I would want from a Gem based on learning.So, I decided to put a specific JSON prompt close to the end of one of my learning conversations with Gemini Learning Coach Gem. I told it to generate a custom system prompt for an AI assistant that would emphasize rigor. For the system prompt, I told it to not have specific references to the material we had been covering in the chat so that the Custom Gem would act better as a general tool emphasized towards learning and education. I have added a screenshot of the prompt I used and the system prompt it generated as ‘Initial system prompt’It created the following system prompt which however, still had the specific references. I put the system prompt in another chat and asked Gemini to remove specific references of the mentioned material. I put the refined system prompt inside the 'instructions' section for creation of a Custom Gem. I called this Gem 'Mastery Coach'. I have also attached this cleaned system prompt that I finally used as ‘Generalized Mastery Coach Prompt’So for learning RNNs, self-supervision and SSMs, I decided to use this Gem in a similar way to how I began conversations with ‘Learning Coach’. I uploaded the lecture transcripts and notes. Since the transcripts were taken from YouTube, they would have unnecessary timestamps. I separately asked ChatGPT to just remove the timestamp while keeping all wording intact.The starting prompt for the conversation was a high-level explanation of the context (the class which the material is for, my objectives, other relevant context) and concepts being covered. These beginning prompts are in the uploaded chats itself. I used to add short pointers which I intended would act as an additional 'system prompt' so that the Gem would focus better on the particular material just added. From there, the entire conversation followed which has also been attached with detailed annotations. I have also attached a link to the Gem which would directly allow you to use it in your Gemini environment.Reflection: Giving both the transcripts and the slides was beneficial. While you would expect it to cover concepts in the same progression as the lectures, it took a different order in explaining things. I especially noticed that the concept of ‘A’ diagonalization was covered at a point where it wasn’t explicitly mentioned in the lecture. While asking probing questions, it was giving away too much in hints. I have also mentioned this in annotations as something others can work on by building a Custom Gem of their own using a modified version of the system prompt attached below.Link to use 'Mastery Coach' directly: https://gemini.google.com/gem/1JoLndovdl25vJ9DPMw9NGg6wEC2gMDn-?usp=sharing", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/Bvv5jwuXNoERIfNgFXFdnH1i", "name": "Mastery Coach on RNNs, self-supervision, SSMs (1).pdf"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/zzYQq911CPYmYYn0qWEYQaol", "name": "Generalized Mastery Coach Prompt.pdf"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/tl8x3RgutqE3q0od9uh8R1bz", "name": "Initial system prompt.pdf"}, {"type": "link", "url": "https://gemini.google.com/gem/1JoLndovdl25vJ9DPMw9NGg6wEC2gMDn-?usp=sharing", "name": "Raw Text Link"}], "tags": ["Tool/App", "Tutor", "Study Guide", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7396775"}, {"id": 7396752, "title": "Special Participation E: AI Further Studies Guide", "date": "2025-12-03T15:34:01.931379+11:00", "author": "Alex Luu", "content": "After lectures, I often find myself interested in some of the topics briefly mentioned. Specifically, the implementation details are interesting, but since they are only briefly covered, the lectures do not go into detail about them. I decided to use Sonnet 4.5 to help me with expanding my knowledge in a way I can understand. One topic in particular was about the KV cache. Lecture only mentioned it but does not go into the specifics of the implementation and how it fits in the inference steps.Here is my prompt:\"\"\"I am taking a deep learning class. Your job is to help me fill the gap in my knowledge from lecture. Specifically, I want you to help me understand the KV cache in more detail. I have attached relevant lecture notes that talk about transformers. Here are my questions:1. What is the KV cache?2. What specifically is cached?3. How does prefilling and autoregressive generation work with the KV cache?\"\"\"I attached lecture notes 18 and 19 with this. The results were pretty good as Claude was very detailed with the answers. I had many follow-up questions and it answered them perfectly. I especially like how it references the lecture notes so that the math notation it used was consistent. This made it easier to understand. I have attached the annotated log below.", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/gw6Rg8yxNSJASxbeKiVVCdiY", "name": "Special Participation E.pdf"}], "tags": ["Coding", "Study Guide", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7396752"}, {"id": 7394664, "title": "Special Participation E: A Deep Learning Fable", "date": "2025-12-03T11:02:42.67456+11:00", "author": "Mihir Rao", "content": "I tend to retain concepts better when I understand why? rather than just how? LLMs are really good at understanding a large amount of information and explaining them in different ways. I asked Gemini to take three lectures(18, 19, 20), and write a story about how the decisions for these architectures and formulations came to be.I went through a few iterations of a prompt, and ended up settling with one that emphasizes my desire for it to really focus on intuition rather than merely summarizing contents. One thing I found interesting is it's good use and development of analogies to explain content. I had to force Gemini to answer in complete sentences because it seemed to really like bullet points.Using an LLM this way also made me more aware of its strengths and limitations. It’s great at remixing and reframing material into something that matches my learning style, but I still have to check that the intuition it gives me lines up with the actual definitions and equations in the lectures. This method can also serve well as motivation for the mathematics in lecture. Here is what I ended up with:", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/lb84wS3w1dj3gDeuSGPpS10m", "name": "182 Part E 2.pdf"}], "tags": ["Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7394664"}, {"id": 7392001, "title": "Special Participation E: Gemini + Manim for Visual Intuition", "date": "2025-12-03T06:14:02.211271+11:00", "author": "Mihir Rao", "content": "I've always been fascinated by 3b1b's math explanation videos, and find them really insightful particularly because of the unique approach to explain concepts through visual depictions. I built upon the starting point in Jameson's Post: #301, and used the lecture transcript and latex template to build something else: manimaker. Given latex input and a transcript, these scripts generate a video using the same engine 3b1b uses to make his videos.To try this out, go to the manim_generator script I wrote, change the topic focus prompt, and build the video. You can ask it to generate a video and explain concepts from lecture using visuals, or ask it to focus on more specific concepts within a lecture. For example, I gave it the prompt below:TOPIC_FOCUS = \"Explain Ridge regression in the SVD basis, including the formula for w_* = (X^T X + lambda I)^{-1} X^T y, how it becomes a diagonal shrinkage in the singular value basis, and geometric intuition for why small singular values are suppressed. Do not cover momentum or SGD here.\"And we're able to generate the video below! This also uses the Gemini API, and uses the script I wrote to create a file you can use to build the video as such: manim -pqh lecture_manim.py RidgeRegressionSVDScene. I have included all necessary files in the zip below, including the lecture notes latex + transcript(from #301), my manim file generator, a yaml to setup your conda env, and video itself. I've also attached the video directly below.Some limitations that could be improved: Because Gemini is writing code, sometimes manim build errors may occur, but I found they're usually resolvable with 1-3 queries from your favorite LLM. I did find that Gemini does a great job coming up with layouts, sequential structure to introduce material, and showing graphs that demonstrate the concept.", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/8W5UmAhaMTHYFwuevs8mTXiS", "name": "RidgeRegressionSVDScene.mp4"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/JahupOGI0gmrFlKRz9Pyarsx", "name": "manimaker.zip"}], "tags": ["Tool/App", "Coding", "Study Guide", "Visualization", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7392001"}, {"id": 7389703, "title": "Special Participation E: A Project-Based ChatGPT Workspace for Understanding the Computational Complexity of Attention", "date": "2025-12-02T18:34:13.408623+11:00", "author": "Moxin Tang", "content": "I’m using the ChatGPT Project workspace to build a focused learning environment that stays tightly aligned with the official class materials. For topics like the computational complexity of attention, I want ChatGPT’s explanations to follow the exact thinking style used in the discussions and homework solutions.A major reason I chose the Project workspace is that when studying a specific topic, having a general and consistent setup is extremely important. I want the notation, assumptions, and reasoning pattern to stay stable across the entire learning process. With a Project, every conversation happens inside the same space, so the structure doesn’t drift.There are three key motivations behind this setup:I can unload the actual course materials as the background knowledge of the project, so ChatGPT relies on the real lecture notes and homework solutions.The Project keeps everything organized and consistent, which means advanced topics (like kernelized attention) can naturally build on the notation and intuition established in earlier ones (like MHA or causal attention).A stable setup makes the study process smoother, because each subtopic follows the same structure:intuition → notation → formulation → derivation → complexity → comparison.To make this work, I first asked ChatGPT to design:a global instruction that enforces this structured reasoning style, anda sequence of prompts I can reuse whenever I study a new subtopic.Then I uploaded my class materials into the Project and followed this prompt sequence to build a conversation that grows in a consistent and cumulative way.Final PipelineStep 1 — Build the Project FrameworkChatGPT helps design the global rules and structured prompt workflow.Then I upload all relevant lecture notes, discussion notes, and homework materials.Step 2 — Guided Learning Inside the ProjectI walk through each subtopic step-by-step using the designed prompts, ensuring that notation, reasoning, and assumptions remain consistent across the entire topic.Supplements1. The link below takes you to the Project itself. The course materials I used for this topic are all included in the PDF.ChatGPT2. I’ve also added an annotated conversation for the subtopics within this project where I evaluate how well GPT performed.", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/NNa0fVoCmCGQcLNtm52km2Rz", "name": "Prompt sequence design.pdf"}, {"type": "link", "url": "https://chatgpt.com/g/g-p-691a72305c648191874525ffadffe6a9", "name": "ChatGPT"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/PGbXg9bhtRmgecLQvTZ5BqYG", "name": "course materials.pdf"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/bINQRy5baLfjQD54rCsmg9Cc", "name": "multiple attention mechanisms.pdf"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/R9sFmBQQLJNYGBFkTUi1ruvQ", "name": "kernelized attention.pdf"}], "tags": ["Tool/App", "Math", "Study Guide", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7389703"}, {"id": 7389324, "title": "Special Participation E: Enhanced Lecture to Note Transcription Pipeline", "date": "2025-12-02T16:53:55.419277+11:00", "author": "Ken Zheng", "content": "I added new features to the existing (lecture slide + lecture transcript) --> (LaTeX notes) pipeline. This work builds on #301 and makes these main improvements:Incorporates direct quotations from our recommended textbook:  for cross-referencing and introducing potentially different POVs.Understanding Deep LearningIncludes accurate references to precise pages in the textbook for relevant key concepts to encourage further exploration and improve integration between the notes and the textbook.Encourages Gemini to recreate figures and diagrams with LaTeX, when possible--very helpful for visualizing abstract concepts.MotivationClasses like the old EECS 16A/B and CS 70 were known for excellent staff-written notes, which made the material organized and accessible, and greatly supported students in self-learning. On the other hand, classes like CS 170 and EECS 126 placed a greater emphasis on their recommended textbook, which were even more excellent sources of knowledge, but could sometimes feel overwhelming due to their high information density. Both the succinct class notes and the chunky textbooks helped us self-learn, but in different ways. In a Deep Learning course, where the field evolves almost faster than we can keep up, self-learning is even more essential. So here, I attempt to amalgamate the notes and the textbook to achieve an optimal balance between accessibility and information quality/density.DetailsThe pipeline still intakes a lecture slides pdf that gets converted to images to enable visual information extraction, and a lecture transcript of the corresponding lecture that is downloadable from YouTube, but now also takes in the textbook pdf that is uploaded as a file. Feel free to compress the pdf, if needed. From my testing, even extreme compression, given words are still easily discernible, works fine. The pipeline needs a Gemini API, and the final typeset notes can be rendered by compiling the lecture_notes.tex output file with a command like pdflatex lecture_notes.tex. I ran this on lecture 2 as well for easy comparison with the original version. See the annotated output below for more details!ScriptFiles", "resources": [{"type": "link", "url": "https://udlbook.github.io/udlbook/", "name": "Understanding Deep Learning"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/nokg79qJX4qCVrhDlArt6q2K", "name": "make_notes.py"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/NI2YpCxEeiPdIKOei5p6b9r8", "name": "lecture_slides.pdf"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/dkWz30RrzMCFU8QhUH5duZw7", "name": "lecture_transcript.txt"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/qELmD8k4lIMObDMObZri4ytJ", "name": "lecture_notes_annotated.pdf"}], "tags": ["Study Guide", "Visualization"], "original_url": "https://edstem.org/us/courses/84647/discussion/7389324"}, {"id": 7388828, "title": "Special Participation E: Simulated Office Hours: Using LLM “Students” and “Instructors” to Deepen Lecture Understanding", "date": "2025-12-02T15:40:09.365315+11:00", "author": "Alex Cao", "content": "Introduction and MotivationI personally find other students’ questions and instructors’ answers in class extremely helpful for deepening my understanding of the concepts. When I learn something for the first time, it is easy to feel like I understand it, until I actually try to implement or prove the idea in a homework assignment and suddenly realize there are many details I never fully grasped. Homework is therefore very valuable in exposing these gaps. Listening to classmates’ questions and the instructor’s explanations plays a similar role for me: it helps surface misunderstandings I didn’t even know I had.Motivated by this, I would like to explore an idea: using LLMs to simulate “mock office hours,” where one LLM plays the role of a curious, insightful student and another plays the role of an experienced instructor. My hope is that the student LLM will raise questions I might not think to ask myself, and that the instructor LLM will respond based on the lecture content (and, when appropriate, external references), thereby extending my engagement with the material. The hypothesis is that because the “student LLM” understands the concept beforehand, it will carefully curate a set of meaningful questions that will elicit nice answers from the “teacher LLM”.I want to emphasize that this mock office hour setup is not a replacement for real office hours and will inevitably be less effective than directly interacting with the course staff. Rather, it is intended only as a supplementary, experimental attempt that might help reinforce lecture material—especially for students who are unable to attend office hours regularly.The lecture transcripts are used in this attempt; these materials are used solely for educational purposes within this course, with full recognition that the CS182 course staff holds copyright.Annotated Trace and Report:Full Traces:Student: https://chatgpt.com/share/692e6482-8f98-800f-b0cb-c2a86e1c2738Teacher: https://chatgpt.com/share/692e3923-3080-800f-9a43-2545d15190aeSummary, Limitations and Future Works:This report is an initial attempt to test whether a knowledgeable student (simulated using an LLM) can carefully curate a set of insightful questions that elicit helpful and thoughtful responses from a teacher LLM, thereby helping real students gain a better understanding of certain concepts. From the simple experiment conducted, we can already see some signals that this “mock office hour” setup is helpful. For example, the student LLM is capable of asking insightful questions and making meaningful connections between past questions, the teacher LLM’s responses, and the lecture transcript by asking focused follow-up questions.However, there are still many limitations to this approach. First, the current attempt relies purely on the lecture transcript. This means not all information from the lecture is captured (for example, the slides), and certain transcripts can be misleading due to transcription errors. Second, this approach is only tested on a single concept in a single lecture with a single model. Although it could be extended to other lectures and models, and even integrated with multimodal inputs, a key weakness of the current setup is that it focuses “too much” on a single lecture—both the student LLM and the teacher LLM are unable to make robust connections to past lectures (due to limited context length), which is crucial for a comprehensive understanding of the course material.One potentially interesting extension would be to keep the conversation going and observe whether the student model eventually “uses up” all meaningful questions. The whole pipeline could also be easily automated with a small amount of code (in contrast, I used the web interface here because I did not have access to an API key).", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/NofzXIc0lwcjfnn89QWUXMIg", "name": "Special Participation E .pdf"}, {"type": "link", "url": "https://chatgpt.com/share/692e6482-8f98-800f-b0cb-c2a86e1c2738", "name": "Link"}, {"type": "link", "url": "https://chatgpt.com/share/692e3923-3080-800f-9a43-2545d15190ae", "name": "Link"}, {"type": "link", "url": "https://chatgpt.com/share/692e6482-8f98-800f-b0cb-c2a86e1c2738Teacher:", "name": "Raw Text Link"}, {"type": "link", "url": "https://chatgpt.com/share/692e3923-3080-800f-9a43-2545d15190aeSummary,", "name": "Raw Text Link"}], "tags": ["Tool/App", "Coding", "Study Guide", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7388828"}, {"id": 7388345, "title": "Special Participation E: AI Question Generator To Understand Concepts", "date": "2025-12-02T14:34:58.668824+11:00", "author": "Alex Luu", "content": "After reviewing (and understanding) solutions to homework problems for a hard topic, I often want to find ways to ensure I fully understand the topic. I decided to use Sonnet 4.5 to help me with this. Here is my prompt:\"\"\"Your job is to help me fully understand the MuP (Maximal Update Parametrization) topic by creating a couple of practice problems with varying difficulty. I have attached lecture notes and the MuP homework questions as well as the MuP research paper.You should create 1 conceptual problem and 2 problems that closely represent the homework's difficulty and style. You should prompt each question one at a time and if I solve it correctly, move on. If I am incorrect, please say so and provide hints towards the correct solution.\"\"\"I attached lecture note 6 and homework 3 with it.The results were pretty interesting. I liked how it stayed pretty close to the source material and created similar questions that are related. I especially liked how it would reference the source material when giving help. I have attached the annotated log.", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/uELljZ6YHYfs5aZmeVGKGjmw", "name": "Special Participation E Claude Question Generator.pdf"}], "tags": ["Study Guide", "Quiz/Drill", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7388345"}, {"id": 7388143, "title": "Special participation E: Use ChatGPT's study guide to compare different fine-tuning strategies", "date": "2025-12-02T14:12:54.788365+11:00", "author": "Jeffrey Cheng", "content": "I used ChatGPT's study mode to compare a menu of fine-tuning strategies for adapting a pre-trained large language model for a new task. It compares these strategies based on data access, model specificity, and application domains. This conversation log explains the strengths and weaknesses of each fine-tuning strategy, tracing back to the exact setup, when applying them to new tasks. I noted that detailed application scenarios are provided for each fine-tuning strategy, along with the precise application domains, which aid my understanding. In the end, it generates a nice workflow for applying fine-tuning strategies to build my own project. The annotated log is as follows:", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/0ycIV1NBqKZJz4Lb8m86UhGf", "name": "Annotated log of fine-tuning strategies.pdf"}], "tags": ["Tool/App", "Study Guide"], "original_url": "https://edstem.org/us/courses/84647/discussion/7388143"}, {"id": 7387863, "title": "Special Participation E: Gemini Lecture Notes Workflow", "date": "2025-12-02T13:36:06.402849+11:00", "author": "Manan Roongta", "content": "Posting this so other people can reuse the same approach/prompting style when making study material/notes for lectures. It’s been super helpful for studying/rereading later.Note: This isn’t replacing handwritten notes. I still handwrite annotations during lecture, but since the skeleton is already there, I can pay attention to the lecture instead of spending a lot of time writing notes. I hope you find these resources helpful Lecture 14 : RNNLecture 15: Autoencoder and Self-SupervisionLecture 18/19/20 : TransformersLecture 21/22 : PEFT, LoRA Gemini Chat Trace (annotated)Gemini ChatPrompt packMy Workflowtl;dr : Paste slides + transcript, run the prompts in order, export .tex file, read, request edits, then annotate during lecture.I start by asking Gemini to explain the bigger picture of the lecture (problem → solution, motivation, and what each section is trying to solve). I do this first because if I ask for notes immediately, it usually misses the why/bigger picture. I personally like the big picture before diving in.Then I ask it to go in depth and stay very close to the lecture. Then I explicitly ask it to define key terms + to make it more structured/improve flow.Then I ask it to output a clean LaTeX version in a code block.Then I ask it to redo the LaTeX against the slides/transcript to see if it missed anything. (Usually 2–3 passes)I paste the LaTeX into Overleaf and read it. If anything feels unclear, I ask it to revise specific sections/go deeper into specific concepts (make it clearer, training vs inference, pros/cons, definitions, what’s changing).While watching the actual lecture, I take hand written notes on top of the notes generated. What I noticed : The multi step approach is what makes it work: explanation first, then structure, then LaTeX, then manual check + targeted edits, then handwritten annotation during lecture.Note: happy to share the .tex files if it helps course staff for future versions of the course (and I have more notes I haven’t posted here).I also included my annotated version of some lecture slides, if any copyright violations, let me know and I can remove it.I used AI to help with wording/formatting", "resources": [{"type": "link", "url": "https://edstem.org/us/courses/84647/discussion/7147361?comment=17152272", "name": "Lecture 14 : RNN"}, {"type": "link", "url": "https://edstem.org/us/courses/84647/discussion/7180201?comment=17152287", "name": "Lecture 15: Autoencoder and Self-Supervision"}, {"type": "link", "url": "https://edstem.org/us/courses/84647/discussion/7262818?comment=17152221", "name": "Lecture 18/19/20 : Transformers"}, {"type": "link", "url": "https://edstem.org/us/courses/84647/discussion/7333490?comment=17152169", "name": "Lecture 21/22 : PEFT, LoRA"}, {"type": "link", "url": "https://drive.google.com/file/d/1QyMsnAlTWK1jmevLrasCVNBhAa97kspv/view", "name": "Gemini Chat Trace (annotated)"}, {"type": "link", "url": "https://gemini.google.com/share/3b8f6d4f2426", "name": "Gemini Chat"}, {"type": "link", "url": "https://drive.google.com/file/d/1SYLdChOFCPB8JxSsYrd-Yvum_krD2ylO/view?usp=sharing", "name": "Prompt pack"}], "tags": ["Tool/App", "Coding", "Study Guide", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7387863"}, {"id": 7386885, "title": "Special Participation E: Gemini as an Interactive study tool!", "date": "2025-12-02T11:22:03.796165+11:00", "author": "Divya Ramesh", "content": "Special Participation E:Now that finals are creeping up, I thought I’d try to create a resource to make a study guide for lectures. After a bit of research online I discovered that Gemini 3 Pro had one of the better OCR handwriting detections ( was one of the sources confirming this), so I decided to upload the lecture notes for lecture 6 into Gemini 3 Pro and let it analyze, and create a study guide. The prompts I used can be found in my chat log! Gemini has canvas mode, which allows for a very organized output, making the study guide color coded and clean. I also had it summarize as well as come up with practice problems. I made it analyze what was directly in the notes only, to try to minimize hallucinations. I instructed it to summarize key concepts, rewrite equations clearly, convert diagrams into textual descriptions, and provide intuition in bullet points. For each concept, it generated a short comprehension question, a tiny derivation for me to work through, and an example scenario showing how the concept applies in practice.https://research.aimultiple.com/handwriting-recognition/Additionally, I set it up to simulate optimizer dynamics, shape transformations, scaling factor effects, Newton-Schulz iterations, and orthogonalization steps using small toy matrices so I could verify everything myself. Whenever the notes were incomplete or ambiguous, the model flagged them and asked for clarification rather than inventing facts. From here, a user can ask the LLM to fill in the gaps or ignore them. I mostly chose to ignore, because staying as close as possible to the notes would minimize hallucinations. The result was a structured, section-by-section study guide that covers MuP, Muon, scaling laws, parameterization, and theoretical analysis topics from the lecture. It also included clear alerts for potential inconsistencies or OCR errors, so I can focus on the parts that need human verification. This approach let me interactively test my understanding and run simulations in a controlled way, essentially turning the lecture notes into a hands-on learning tool.Overall, using Gemini 3 Pro in this targeted, verification-focused way allowed me to generate a high-quality study resource while minimizing hallucinations, making it an effective tool for preparing for finals. Also, it would let me know when there were sections unclear in the lecture notes so I could further prompt the LLM on this. I also turned on learning mode and asked Gemini to walk me through the worksheet, where it gave me hints when I needed them on worksheet problems, and if I was right/wrong it gave me feedback and a bit of background information to ensure I understood. Also, I asked it to walk me through simulations at the end and it actually did walk me through step by step of a problem, and I find this tool incredibly helpful!! The simulations/toy problems especially helped my lock down important lecture concepts.I’ve tested on a few lectures and it has worked amazingly, feel free to check it out! I’m attaching both the worksheet and the chat log below, the chat log is annotated, the worksheet is just for reference!Lecture 6:Chat log:https://drive.google.com/file/d/1egKs92MvXNTsvbv6E6RqEZwsXCIDM6cK/view?usp=sharingWorksheet:https://drive.google.com/file/d/1sl9c8k6Ghc4mZHDwVVriRR5bmkqH8p3p/view?usp=sharing", "resources": [{"type": "link", "url": "https://research.aimultiple.com/handwriting-recognition/", "name": "Link"}, {"type": "link", "url": "https://drive.google.com/file/d/1egKs92MvXNTsvbv6E6RqEZwsXCIDM6cK/view?usp=sharing", "name": "Link"}, {"type": "link", "url": "https://drive.google.com/file/d/1sl9c8k6Ghc4mZHDwVVriRR5bmkqH8p3p/view?usp=sharing", "name": "Link"}, {"type": "link", "url": "https://research.aimultiple.com/handwriting-recognition/Additionally,", "name": "Raw Text Link"}, {"type": "link", "url": "https://drive.google.com/file/d/1egKs92MvXNTsvbv6E6RqEZwsXCIDM6cK/view?usp=sharingWorksheet:https://drive.google.com/file/d/1sl9c8k6Ghc4mZHDwVVriRR5bmkqH8p3p/view?usp=sharing", "name": "Raw Text Link"}], "tags": ["Tool/App", "Coding", "Study Guide", "Visualization", "Prompt Eng", "Math"], "original_url": "https://edstem.org/us/courses/84647/discussion/7386885"}, {"id": 7386458, "title": "Special Participation E: Gemini Guided Learning as a Personal Tutor", "date": "2025-12-02T10:21:51.42187+11:00", "author": "Manan Roongta", "content": "Posting this so other people can reuse the same approach/prompting style when they’re stuck on a concept.Gemini Guided Learning Chat (Transformers + Attention)PDF (with annotations)I have been using Gemini Guided Learning as a “personal tutor” to strengthen my understanding of complex topics, and it's been really helpful. Lectures are great, but I often walk out with feeling \"I kinda get it but not really”. It’s an amazing supplement when you need someone to patiently answer “wait but why” 15 times in a row.The PDF is my real interaction trace (with annotations), including my typos, missing punctuation, misspellings, half finished thoughts, because that’s actually how a student uses these tools in real life.How I used Gemini Guided Learning/what worked1) My initial prompt mattered a lot In the very first message, I clearly set expectations:what I already understoodwhat I was confused aboutwhat I wanted/roadmapThat made the whole chat way more productive than “explain transformers.”2) I had to slow Gemini down at firstEarly in the chat, Gemini kept trying to rush to the next topic. I had to explicitly prompt “slow down”, “one step at a time”, “don't rush me”. After a few times, the session became way more tutor like and less of just answering.3) The built in check ins/questions are great way to testI liked when Gemini asked me questions and made me answer. It forced me to notice where my understanding was hand wavy.4) Write your own Summaries  After finishing a topic, I would:write a summary in my own words, and/orask Gemini for a “summary + roadmap” of what we finished and what’s next.It helped recalibrate my understanding, the bigger picture and track progress.Gemini 3 vs Gemini 3 Guided Learning are very differentGemini 3 Guided Learning felt like it was trying to teachGemini 3 (normal) felt more like it was trying to answer quickly (even when I explicitly prompted for slow + structured learning)Note: I used AI to help with wording/formatting", "resources": [{"type": "link", "url": "https://gemini.google.com/share/bc199205426f", "name": "Gemini Guided Learning Chat (Transformers + Attention"}, {"type": "link", "url": "https://drive.google.com/file/d/1EAE9hd98DESFMTvXKjlW9WG6B6VZxutj/view?usp=sharing", "name": "PDF (with annotations)"}], "tags": ["Tool/App", "Tutor", "Study Guide", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7386458"}, {"id": 7384241, "title": "Special Participation E: Use ChatGPT's study guide to compare transformer-based LLMs", "date": "2025-12-02T06:07:21.800584+11:00", "author": "Jeffrey Cheng", "content": "I used ChatGPT's study mode to compare different transformer-based LLMs based on their architectural choices and the tasks for which they are best suited. Engaging in a Socratic conversation with ChatGPT helped me understand the architectural decisions of various transformer-based LLMs and the specific functions for which they are best suited. It classifies the model architecture into two categories: Encoder/Decoder, Dense/MoE, and explains the strengths of each category in terms of the tasks they are most suited for. One behavior of this study mode that I found very interesting is that, at the end of each ChatGPT response, it always asks me a question that refines my understanding of the current topic. In addition, it helps introduce the next topic for the next prompt. In the end, it generates a cheat sheet that classifies every transformer-based model. The conversation log is:", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/Ggb85TwYCdj1XAJ7rFwAKQIg", "name": "Annotated log of transformer-based models.pdf"}], "tags": ["Coding", "Study Guide", "Tutor", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7384241"}, {"id": 7382039, "title": "Special Participation E: Using Perplexity to gain Historical Motivations", "date": "2025-12-01T21:28:27.236519+11:00", "author": "Ishir Garg", "content": "One thing that I've noticed in this class, is that there seems to be an emphasis on motivating ideas through a historical lens and understanding how they naturally evolved in research over time. However, sometimes I find its hard to connect all the different puzzle pieces and understand where exactly different algorithms or discoveries exist in the timeline.  Hence, I tried to engage an LLM (Perplexity, due to its enhanced search abilities) to try and gain some historical perspective on how ideas came to fruition in deep learning. I uploaded Lecture Note 5 along with an initial prompt, and had Perplexity walk me through a variety of different concepts from a historical perspective. The annotated chat history is below:To summarize, I was pleasantly surprised by the outcome. I'm also surprised that it was able to do this with just the lecture notes and a very minimal initial prompt.Strengths:Perplexity does a good job of explaining the intuitive motivations behind ideas and how certain ideas lead to othersOne really surprising result was that Perplexity began asking me questions to check my understanding, even though I never asked it to do thisIt also introduced some ideas outside of the lecture notes at a high-level, that provided some really unique insight into the ideas in this class.Weaknesses:Some parts could use more explanation or go more in-depth, although it could be argued that these could just be left to the student to ask questions about if they desire.", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/VaBmvFfCKL6FlhgZmgWBerz9", "name": "participationE.pdf"}], "tags": ["Study Guide", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7382039"}, {"id": 7381645, "title": "Special Participation E: 182 Exam Prep Tool", "date": "2025-12-01T17:21:56.578199+11:00", "author": "Andrew Choy", "content": "Since I couldn't find any practice tests available online, I decided to build a Practice Question Generator. It utilizes homework assignments, lecture notes, and/or lecture audio to generate relevant study problems.I found that pairing specific homework assignments with their corresponding lectures yields the most grounded results, even when using free-tier API models. To make the tool more convenient, I added an input field for your API key; this allows you to run the tool without editing the code directly (unless you want to tweak the prompt for other classes).The screen recording below demonstrates the tool using only lecture notes and homework. While the system does support lecture audio, which is great for capturing details professors say but don't write down, I stuck to processing PDFs for this demo to minimize inference latency and I used gemini-2.0-flash API Version. One of the biggest challenges was formatting the model's output. I attempted to wrap the responses in Markdown to ensure the display math rendered correctly, but this approach introduced several bugs and made the code difficult to maintain. So if anyone wants to push this further, feel free to fork or make a PR request. Github: https://github.com/AndrewChoyCS/CS182-artifactDemo: https://drive.google.com/file/d/1DkO63NA44jGrEhoFPZGidESEYAcKIe94/view?usp=sharing", "resources": [{"type": "link", "url": "https://github.com/AndrewChoyCS/CS182-artifact", "name": "Link"}, {"type": "link", "url": "https://drive.google.com/file/d/1DkO63NA44jGrEhoFPZGidESEYAcKIe94/view?usp=sharing", "name": "Link"}, {"type": "link", "url": "https://github.com/AndrewChoyCS/CS182-artifactDemo:", "name": "Raw Text Link"}], "tags": ["Tool/App", "Coding", "Study Guide", "Prompt Eng", "Quiz/Drill"], "original_url": "https://edstem.org/us/courses/84647/discussion/7381645"}, {"id": 7380406, "title": "Special Participation E: Using ChatGPT to create practice problems", "date": "2025-12-01T12:36:50.10738+11:00", "author": "Jason Guo", "content": "To study for the final, I thought it would be interesting to see if ChatGPT can be used to created practice problems that are similar to homework problems, and solidify my understanding of the topics covered in homework. As an example, I gave ChatGPT homework 1, which has problems relating to optimizers, and asked it to generate two exam problems, each with multiple parts, relating to opitmizers based on the given homework problems.Overall, I thought it did well and actually provided some good problems for studying,. The difficulty of most of the problems it gave were around the same difficulty as the homework, with the exception of around 2 subquestions that required mathematical knowledge that's probably out of scope for this class. I also asked it to generate solutions for these problems, and the solutions were pretty good at explaining the answers in detail. As a whole, I found this to be really helpful in helping me review the material and get more practice solving exam/homework style problems.Annotated transcript: https://drive.google.com/file/d/1hT7u9eEhd5HyBr-gD1urZGbrdP3Zu3T2/view?usp=sharing", "resources": [{"type": "link", "url": "https://drive.google.com/file/d/1hT7u9eEhd5HyBr-gD1urZGbrdP3Zu3T2/view?usp=sharing", "name": "Raw Text Link"}], "tags": [], "original_url": "https://edstem.org/us/courses/84647/discussion/7380406"}, {"id": 7377452, "title": "Special Participation E: Coding Fill-in-the-Blank for Optimizers", "date": "2025-11-30T17:45:50.986379+11:00", "author": "Aaryan Chandna", "content": "I recall from CS courses that I have taken such as the 61 series how many questions used to consist of filling in blanks with code, particularly on exams and in discussions. I felt that these questions were relatively strong in developing intuition at the time, so I wanted to try a similar format out with Google Gemini in order to see if I could strengthen my understanding of the different optimizers. I asked Gemini to first summarize lectures 3/4 for me from the slides to provide a bit of review. The summaries were decent, even though the intuition provided wasn't always strong: sometimes the model would just quickly state a concept without explaining. Then, I asked it to create continuously increasing questions in difficulty, involving filling in the blank with code. One significant issue was that the model kept accidentally leaking the solution in the comments of the code. Even towards the end, it did this in a somewhat implicit fashion: below the function, there was a small section with an example of running the code in comments, with formulas shown that had the correct blank fill-ins. In addition, Gemini's questions were very one-dimensional and had to do solely with the basic functionality of optimizers, such as an SGD step or an Adam step. I expected that when I asked for questions of higher difficulty, there would be something more intuition based. Towards the end, the last question was a bit different, which was nice. Perhaps there is a better way of prompting to get the model to devise more exam-style questions for prep.Trace: https://gemini.google.com/share/eb8917989837", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/nuwfPT2yMJx70pjs4KH3MbaL", "name": "spec_part_e_2_aaryan.pdf"}, {"type": "link", "url": "https://gemini.google.com/share/eb8917989837", "name": "Raw Text Link"}], "tags": ["Coding", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7377452"}, {"id": 7377093, "title": "Special Participation E: GPT5 as quiz maker for exam preparation", "date": "2025-11-30T15:08:56.618821+11:00", "author": "Ender Ji", "content": "For special participation part E, I asked GPT 5.1 to make quiz problems (both MCQ and FRQ) based on the lecture notes of lecture 18  and 19 from Professor Ranade. I begin by clearly stating GPT’s role and the assistance I require, then provide all relevant files and ask it to review and understand them.Then I first ask GPT to generate multiple-choice questions and attempt to answer them. GPT produces high-quality MCQs that effectively test my understanding, and it can both identify my mistakes and provide the correct answers with detailed explanations.Beyond MCQs, I also use GPT to create more open-ended free-response questions. GPT is able to formulate the problems, “grade” my answers against the \"ground truth\" from the lecture notes, and offer thorough explanations and guidance whenever I get stuck.This is the first time I have used an LLM for this kind of review, and the experience has been very positive. I believe this interactive “quiz-taking” approach will be extremely helpful not only for preparing for the final exam, but also for ensuring that I fully understand the material before each subsequent lecture. I also hope that this method will be helpful for other students during RRR week.", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/vHKi330uVk2qWo0QcgvNT3VX", "name": "test_reviewer_GPT5.pdf"}], "tags": ["Tool/App", "Study Guide", "Quiz/Drill"], "original_url": "https://edstem.org/us/courses/84647/discussion/7377093"}, {"id": 7376375, "title": "Special Participation E: ChatGPT 5.0 Study Mode", "date": "2025-11-30T10:33:28.34829+11:00", "author": "Iana Lin", "content": "Executive SummaryI used ChatGPT 5.0 \"Study Mode\" to interactively improve my understanding of positional encoding, RoPE, and NoPE.  This was the first time I've interacted with ChatGPT 5.0's \"Study Mode,\" and I felt it was very helpful. It asked clarifying questions about my current understanding before proceeding to explain, which differed from normal prompting mode.Although there is a less clear idea of \"one-shotting\" in this context where there are not verifiable correct answers, every question it asked was answer reasonably with logical and step-by-step explanations. I do wish that the explanation were more grounded in mathematical formulations or code, but this may come down to learn the write prompting style. Errors:ChatGPT used “i” for indexing position, but this later became confusing because it also used i for imaginary number. After pointing this out, it no longer made the mistakeOverall:ChatGPT was a good resource for improving understanding, much like if I was chatting to a teaching assistant, and interacted with clarifying questions throughout the converstation. The analogy to Fourier transform across positions helped clarify how using this superposition allows for capturing of both high and low frequencies/unique embedding for each input embedding and position.", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/rUKMMRgfpcftT4caUCaGgmVi", "name": "Special Participation E - RoPE Using ChatGPT Study Mode.pdf"}], "tags": ["Coding", "Study Guide", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7376375"}, {"id": 7376321, "title": "Special Participation E: GPT5 as lecture notes reviewer and tutor", "date": "2025-11-30T10:14:46.664082+11:00", "author": "Ender Ji", "content": "For special participation part E, I asked GPT 5.1 to review the lecture notes of lecture 18 from Professor Ranade. I begin by clearly stating GPT’s role and the assistance I require, then provide all relevant files and ask it to review and understand them. Then I proceed to asking different kinds of questions about the notes1. input a hand drawing diagram from Professor Ranade and ask it to explain to diagram2. input a diagram from the book ask it to explain to diagram3. ask GPT to explain a specific concept4. ask GPT to differentiate between different concepts5. ask GPT concepts that are not deeply discussed in the lecture notes, and make connection to the lecture notesIt is the first time I do notes review with GPT, surprisingly GPT 5.1 can handle almost all kinds of questions well and able to give great explanations, which shows how strong GPT is in helping students learning new concepts.", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/K4hJ3j4bSbawhhtQozKvoiPU", "name": "lecture18_review_GPT5.pdf"}], "tags": ["Tutor", "Study Guide", "Visualization"], "original_url": "https://edstem.org/us/courses/84647/discussion/7376321"}, {"id": 7374682, "title": "Special Participation E: Interactive MHA Implementation Drill", "date": "2025-11-29T19:26:19.700045+11:00", "author": "Andrew Choy", "content": "One challenge I often face is bridging the gap between understanding a concept theoretically and implementing it in code. For this assignment, I used Gemini 3 Thinking to guide me through the implementation.It felt a bit like a 'Masked Language Modeling' task for my own brain: I designed a prompt to set up the scenario, and I had to fill in the code for the forward pass of Multi-Head Attention myself. I spent about an hour on the exercise, and I found it incredibly valuable. Instead of just giving me the answers, the LLM asked me conceptual questions about why I was choosing specific tensor shapes. Being forced to justify my implementation details really solidified my understanding of the topic.I encourage y'all to try this with the prompt I included in the pdf. You can easily adapt it for other concepts by slightly changing the formatting in the 'Your Role' and 'The Trap' sections. Just swap out 'Multi-Head Attention' for another topic like 'Layer Normalization' or 'Adam Optimizer,' and keep the 'No Solutions' constraint to ensure the same type of setup.", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/CcMT6C3JxLbClmmbjNJnMBAw", "name": "AndrewChoyParticipationE.pdf"}], "tags": ["Coding", "Study Guide", "Quiz/Drill", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7374682"}, {"id": 7373978, "title": "Special Participation E: Gemini 3 (Thinking) As A Converter from Homework to Practice Problems", "date": "2025-11-29T12:02:40.20453+11:00", "author": "Tiger Zhang", "content": "Executive Summary:I like to prepare for exams by doing practice exam problems, and I’m sure many are like me too. While I think homework problems are a great way to actually learn and understand concepts in the class, I think it’s also good to have exam-style practice problems that test at the understanding gained from the homework assignments, and that require a “faster pace” than do homework problems.Therefore, I prompted Gemini 3 to write an exam problem set based on a homework problem set, extending the homework problems in interesting and stimulating ways. I guided it to write problems that use intuition built from homeworks so I cannot just skip the homeworks and do the exam problems.The result: I now have a simple four-prompt pipeline that simulates the practice test experience on a homework assignment, as it outputs both the practice exam problems and the practice exam solutions. It takes in the homework that the user desires to have corresponding exam problems for, as well as a few examples of exam problems (some are released in some homeworks).Although some output exam problems were quite similar to homework problems, they do change the homework problems slightly, and the rest of the problems are still different from homework problems.Difficulty: a difficulty I faced when building this pipeline is actually tuning the difficulty of the exam problems. By changing the third prompt (the “write the problems” prompt), the difficulty ranged from too difficult (requires memorization of details of the results from the homework) to very easy (simple plug and chug). If users dislike the difficulty of the problems from this pipeline, I propose changing the third prompt.Chat log: (I boxed my prompts)Homework 1 exam problems:Homework 1 exam problems (unannotated):Homework 1 exam problem solutions:Homework 1 exam problems solutions (unannotated):", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/UgyJ3lokWUhEbhzgnOfe3RBU", "name": "conversation.pdf"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/GdbnlVUgpzi1SUWKocJvjdng", "name": "exam.pdf"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/nn3twYK8NpJ8afEWpu55vtnh", "name": "exam_clean.pdf"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/cC2bOGSdQdyQM2x4HXsrshSr", "name": "sol.pdf"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/zdsPG0yCIa2DXw7ixEEN88QO", "name": "sol_clean.pdf"}], "tags": ["Study Guide", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7373978"}, {"id": 7372401, "title": "Special Participation E: Staff Notebook Deep-Dive & Code Review Tutor using ChatGPT Study Mode", "date": "2025-11-28T19:53:55.03587+11:00", "author": "Faiaz Khan", "content": "What this is:We often get staff solution notebooks that are 100% correct but not necessarily the best examples of Python or ML engineering practices. I made a reusable prompt that turns ChatGPT  into:a tutor that explains the solution code,a Socratic “what if we changed this line?” partner, anda code reviewer that critiques style, structure, and engineering practices.How to use it:Open ChatGPT and enable Study Mode.Start a new chat and upload the .ipynb with the staff solution.Paste the big prompt below.Optionally tell it your comfort level with Python / ML.Let it walk you through:an overview of the problem and solution,interactive what-if questions about code changes,and a software-engineering critique plus suggested refactors.Prompt:You are an AI tutor and code reviewer for a Jupyter notebook that contains:\n\n- a coding / ML problem,\n- and the staff-provided solution (and possibly some tests or helper code).\n\nYour goals:\n(1) Help me deeply understand the staff solution.\n(2) Actively quiz me with “what-if” code modification questions.\n(3) Critique the solution as a piece of software / ML engineering, not just as a correct answer.\n\nI will upload a .ipynb file. Please work in the following phases.\n\n########################\nPHASE 0 — ORIENT YOURSELF\n########################\n\nAfter reading the notebook:\n\n1. Identify and briefly summarize:\n   - The **problem statement** (in your own words).\n   - Where the **main staff solution** lives (e.g., which cell / which function).\n   - Any **supporting code** (helpers, tests, imports, plotting, etc.).\n\n2. Output a short overview like:\n\n   - Problem: [...]\n   - Main solution entry point: [...]\n   - Key helper functions: [...]\n   - Tests / demo cells: [...]\n\nIf anything is ambiguous, say so instead of guessing.\n\n########################\nPHASE 1 — EXPLAIN THE SOLUTION\n########################\n\nAssume I am a student who:\n- knows basic Python,\n- is familiar with lists/dicts/functions/loops,\n- but may *not* know the specific algorithm or ML technique yet.\n\nDo the following:\n\n1. **High-level explanation (3–7 sentences)**  \n   - What is the core idea of the solution?\n   - What algorithm / pattern does it implement (e.g., DP, DFS, greedy, training loop, etc.)?\n\n2. **Guided code walkthrough**  \n   - Walk through the main solution function or cell **top-down**.\n   - Group lines into logical chunks instead of line-by-line noise.\n   - For each chunk, explain:\n     - what it does,\n     - why it’s needed,\n     - how it connects to the problem definition.\n\n3. **Complexity / behavior**  \n   - State the time and space complexity if meaningful.\n   - Mention any tradeoffs (e.g., readability vs performance, memory vs speed).\n\nKeep this phase mostly explanatory, with occasional quick checks like:\n> “Can you tell me in your own words what this loop is doing before I explain it?”\n\n########################\nPHASE 2 — INTERACTIVE “WHAT IF?” QUESTIONS\n########################\n\nNow I want you to test and deepen my understanding by asking questions about code changes.\n\n1. Ask **3–6 “what if” questions** such as:\n   - “What do you think happens if we remove this condition?”\n   - “If we change this list to a set, how does that affect correctness and complexity?”\n   - “What if we change the iteration order here?”\n   - “What if we initialize this variable differently?”\n\n2. For each question:\n   - Wait for my answer first.\n   - Then:\n     - say what *would* actually happen (behavior / correctness / performance),\n     - and tie it back to the underlying concept or invariant.\n\n3. Start with simpler changes (e.g., altering a constant or print) and\n   move toward more subtle ones (e.g., off-by-one edges, shared mutable state, ML training details).\n\nIf the code involves randomness or ML training:\n- Ask at least one question about seeds, reproducibility, or how hyperparameters show up in the code.\n\n########################\nPHASE 3 — SOFTWARE / ML ENGINEERING CRITIQUE\n########################\n\nNow critique the staff solution as if you were a senior software or ML engineer reviewing it.\n\n1. **Style & Pythonic-ness**\n   - Comment on:\n     - naming (variables, functions),\n     - function length and cohesion,\n     - use of built-in functions / libraries,\n     - avoiding repetition,\n     - clarity vs cleverness.\n   - Point out at least 3–5 concrete improvements, such as:\n     - “This nested if could be simplified.”\n     - “This magic number should be a named constant.”\n     - “This could use a context manager / list comprehension / enumerate, etc.”\n\n2. **Structure & modularity**\n   - Is the solution written as one big cell, or decomposed into testable functions?\n   - Could it benefit from:\n     - helper functions,\n     - separating pure logic from I/O,\n     - or separating data loading / config from core algorithm?\n\n3. **Documentation & comments**\n   - Are there docstrings or comments explaining key decisions?\n   - Suggest where short comments or docstrings would significantly improve readability.\n   - Optionally sketch an example docstring for the main function (using a standard style like NumPy or Google style).\n\n4. **Testing & edge cases**\n   - Does the notebook include tests or sample runs?\n   - What edge cases might be missing?\n   - Propose **3–5 simple test cases** that would be good to add (in plain English or as Python snippets).\n\n5. **ML engineering (if applicable)**\n   - If the notebook includes any training/eval code:\n     - Comment on:\n       - seeding / reproducibility,\n       - separation of config (hyperparameters) from code,\n       - logging / metrics,\n       - handling of train/val/test,\n       - use of vectorization vs for-loops.\n     - Suggest at least a couple of improvements (e.g., “move these constants to a config dict,” “use a random seed,” etc.).\n\n6. **Concrete improved snippet(s)**\n   - Choose ONE small function or core block from the staff solution.\n   - Show:\n     - “Original version” (copied and possibly shortened)\n     - “Improved version” (your more Pythonic / maintainable rewrite)\n   - Explain in 3–5 bullets what changed and why it’s better (clarity, safety, extensibility, etc.).\n\nIMPORTANT:\n- Do NOT rewrite the entire notebook unless I explicitly ask.\n- Focus on *illustrative* improvements that a student can learn from.\n\n########################\nPHASE 4 — SUMMARY & ACTIONABLE NEXT STEPS\n########################\n\nFinish by giving me:\n\n1. A **conceptual summary**:\n   - 3–6 bullets summarizing:\n     - the algorithm / method used,\n     - the key ideas in the implementation,\n     - and the main software-engineering lessons.\n\n2. A **mini checklist** of things I could do on my own:\n   - e.g., \n     - “Refactor the main function into two helpers,”\n     - “Add tests for these edge cases,”\n     - “Rewrite this loop using a more Pythonic construct.”\n\n3. Ask me:\n   - “Which part of this notebook do you feel you understand the least?”\n   - “Do you want to zoom in further on a particular function or cell?”\n\n########################\nSTYLE & SAFETY\n########################\n\n- Be direct but encouraging; assume I am capable of understanding serious critique.\n- Don’t just say “this is bad”; explain *why* and how to improve it.\n- If you are inferring intent that is not explicit in the notebook, make that clear:\n  > “I’m inferring that this function is meant to do X based on Y; if that’s wrong, let’s adjust.”\n- Avoid hallucinating details that don’t appear in the notebook. If something is unclear, say so.\n\nMy annotated chat:I tried this on the staff solution for Homework 7 RNN LSTM implementation. Here’s my annotated chat trace (PDF):https://chatgpt.com/share/69295e36-3fd4-8010-9710-56a0c2e28752 In the annotations I point out:where the AI gave good explanations,where its code critiques matched or conflicted with what our course emphasizes,and where it hallucinated or misread the notebook.", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/a892iEevSEYlg86E8cxYe11L", "name": "RNN LSTM implementation.pdf"}, {"type": "link", "url": "https://chatgpt.com/share/69295e36-3fd4-8010-9710-56a0c2e28752", "name": "Raw Text Link"}], "tags": ["Tool/App", "Coding", "Study Guide", "Visualization", "Prompt Eng", "Tutor", "Quiz/Drill"], "original_url": "https://edstem.org/us/courses/84647/discussion/7372401"}, {"id": 7372317, "title": "Special Participation E: AI-Enhanced Pre-homework Study Workflow Using Mistral AI", "date": "2025-11-28T17:56:19.887587+11:00", "author": "Xi Cheng", "content": "For this assignment, I built an AI-enhanced learning tool that serves as a substitute for traditional pre-homework readings. Here I use Mistral AI on HW08. My goal was not to obtain solutions, but to construct a structured conceptual scaffold before attempting the homework. To do this, I asked the LLM to generate a pre-instruction guide that identifies the major concepts, prerequisites, and reasoning pathways needed for the SSM and attention problems. As shown in the annotated interaction trace , I intentionally framed my prompts so that the model would function like a pre-lecture resource rather than a homework solver.A central part of my prompting strategy was requesting “hints only” instead of answers. I highlighted this in my annotations because it forces me to reconstruct derivations myself, rather than copying a completed solution. This approach supports the assignment’s goal of encouraging self-learning. Compared with traditional pre-lecture materials, this AI-based tool offers a more interactive and adaptive experience. Instead of passively reading a static explanation, I can ask follow-up questions, request clarification, and explore prerequisite concepts dynamically. The workflow—beginning with a conceptual overview, followed by prerequisite review, then question-specific hints and common pitfalls—can be applied to any technical topic in the course.", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/5kfBIWvpAxbO50NTUgToOuhF", "name": "partE_mistral_hw8.pdf"}], "tags": ["Tool/App", "Math", "Study Guide", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7372317"}, {"id": 7372302, "title": "Special Participation E: Using an AI “Pre-/Post-Lecture Tutor” using ChatGPT Study Mode", "date": "2025-11-28T17:43:32.737293+11:00", "author": "Faiaz Khan", "content": "What this is: I made a reusable prompt that turns ChatGPT an interactive lecture companion instead of just a solution engine. You upload a lecture’s slides or notes, and the model:walks through the lecture in small chunks,forces you to answer questions before it explains,compares your answers directly to slides,and ends with a short summary + quiz.How to use it:Open ChatGPT in Study Mode.Paste the big prompt below as your first message.Upload the slides for Lecture [X – Topic].Tell it whether this is pre-lecture or post-lecture study.Let it quiz you chunk-by-chunk.The Prompt:You are an AI tutor helping me actively learn one lecture in a course.\n\n[COURSE]: e.g., “CS XXX: [Course name]”\n[LECTURE # AND TOPIC]: e.g., “Lecture 22 – Prompt-Based Fine-Tuning Methods”\n[RESOURCES I WILL PROVIDE]: e.g., slides PDF, lecture notes, or textbook section.\n\nYour job is to act like an interactive pre-/post-lecture reading replacement.\n\n### MATERIAL HANDLING\n1. ONLY treat the files/notes I give you as the primary source of truth.\n2. When answering, explicitly separate:\n   - (a) “According to the lecture materials, …”\n   - (b) “Beyond the lecture, I infer/guess that …”\n3. If something is NOT in the materials or you are unsure, say:\n   > “I’m not sure from the provided materials; this is an educated guess.”\n\n### INTERACTION LOOP\nFor this lecture, repeat the following cycle:\n\n**Step 0 — Calibrate**\n- Ask me:\n  - what my background is,\n  - how confident I feel about this topic (1–5),\n  - whether we are doing *pre-lecture* or *post-lecture* study.\n\n**Step 1 — Select a small chunk**\n- Pick a manageable chunk of content:\n  - e.g., 1–3 slides, or 1 short section of notes.\n- Tell me which slides/section we’re focusing on:\n  > “Let’s focus on slides 5–7: [short description].”\n\n**Step 2 — Active recall before explanation**\n- Ask 2–4 questions that I must answer *before* you explain anything, such as:\n  - “In your own words, what problem is this method solving?”\n  - “Why is this assumption important?”\n  - “Can you restate the main equation and what each term means conceptually?”\n\n- Always start with me, not you:\n  > “Answer in 2–4 sentences. It’s okay to be wrong; I’ll help refine.”\n\n**Step 3 — Feedback + correction**\n- Compare my answer to the materials.\n- Do NOT just say “correct/incorrect”. Instead:\n  - Highlight what I did well.\n  - Point out exactly what is missing or mistaken.\n  - Quote or paraphrase the relevant part of the slides/notes to support your feedback.\n- If I’m very off, give me a *hint* and ask me to try again before giving the full explanation.\n\n**Step 4 — Deepen understanding**\n- After feedback, give a concise explanation (max ~5 sentences) that:\n  - connects this chunk to previous lecture ideas,\n  - uses examples or analogies,\n  - mentions any common misconceptions.\n\n- OPTIONAL: Ask one “transfer” question:\n  > “How would this change if [variant scenario]?”\n\n**Step 5 — Quick check**\n- Ask me 1–2 short quiz questions (conceptual or very light math).\n- Then show me the answers so I can self-check.\n\n**Step 6 — Move on or review**\n- Ask:\n  > “On a scale of 1–5, how comfortable do you feel with this chunk?”\n- If I say ≤ 3, offer a different explanation style (more examples, slower, or more visual).\n- If I say ≥ 4, move on to the next chunk.\n\n### END OF SESSION\nWhen I say I’m done or we reach the end, do all of the following:\n\n1. Give a **3–6 bullet-point summary** of the lecture in your own words.\n2. Create:\n   - (a) 3 multiple-choice questions (with answers),\n   - (b) 3 short-answer conceptual questions (with brief answer keys).\n3. Ask ME:\n   - “What still feels confusing?”\n   - “What is one thing you’d like to revisit tomorrow?”\n4. Suggest a short spaced-repetition plan for the next week based on this lecture.\n\n### STYLE & SAFETY\n- Be concise, friendly, and non-judgmental.\n- Never just dump full solutions to typical homework-style questions without first:\n  - asking for my attempt or idea,\n  - and then walking me through step-by-step.\n- Aggressively avoid hallucinations: if there is any conflict between your prior knowledge and the slides, defer to the slides and flag the mismatch.\n\nMy interaction trace + commentary: I tried this on Lecture 20: Positional Encoding & Modern Architectures. Here’s the annotated PDF of the conversation: [link]. In the annotations, I point out:where the model closely followed the prompt and was really helpful,where it hallucinated details that weren’t in the slides,and some ideas for improving the prompt for future use.https://chatgpt.com/share/692944c7-5ef4-8010-ba41-cece83a423e0", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/02LPmeNtu5c2neK2LPSCSJRZ", "name": "Interactive study session.pdf"}, {"type": "link", "url": "https://chatgpt.com/share/692944c7-5ef4-8010-ba41-cece83a423e0", "name": "Raw Text Link"}], "tags": ["Study Guide", "Visualization", "Prompt Eng", "Tutor", "Quiz/Drill"], "original_url": "https://edstem.org/us/courses/84647/discussion/7372302"}, {"id": 7372287, "title": "Special Participation E: ChatGPT as Motivation Finder from Lecture Notes", "date": "2025-11-28T17:25:53.685301+11:00", "author": "Guohao Lv", "content": "When I review the lecture notes, I always find it easier to understand a concept after understanding why it is introduced in the first place. Because it is quite laborious to go back to watch the lecture again and sometimes professors just give a very simplified version of the motivation, I built a “Motivation Finder from Lecture Notes” prompt that uses AI to give a more detailed explanation of the motivation of concepts mentioned in lectures and provide good sources for further reading and deeper understanding. The workflow is: I paste a chunk of CS182 lecture notes (for a particular lecture) into the prompt. The AI first scans the text and extracts a small list of key concepts mentioned there (e.g., BatchNorm, residual blocks, attention, muP, etc.). For each concept, it then searches the internet for one good source—ideally the original paper or a survey/tutorial from a reputable venue—and reports the title, link, and type of source. Using that source, it writes a short motivation-focused summary: what problem people were facing before this idea, how the idea addresses that problem at a high level, and what tradeoffs or limitations are mentioned. It then quotes the relevant lines from the lecture notes and tells me whether the notes make the motivation clear, partially clear, or confusing. Finally, for each concept, it asks me 1–2 questions that test whether I actually understand the motivation and tradeoffs, waits for my answers, and then gives concise “ideal answers.” Overall, I find it quite helpful as a post-lecture reading even though it is still not ideal, and the questions it generate does lead me to go back and read more about the topic, so I think this tool achieves its objective.The annotated conversation: https://drive.google.com/file/d/1htjK83ljExmXnUGwNZA2ykykNXQA3ZW_/view?usp=sharing", "resources": [{"type": "link", "url": "https://drive.google.com/file/d/1htjK83ljExmXnUGwNZA2ykykNXQA3ZW_/view?usp=sharing", "name": "Raw Text Link"}], "tags": ["Tool/App", "Tutor", "Study Guide", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7372287"}, {"id": 7369769, "title": "Special Participation E: ChatGPT as a Mistake-Spotting Coach", "date": "2025-11-27T12:03:19.696186+11:00", "author": "Guohao Lv", "content": "I often use ChatGPT or other LLMs to review CS182 concepts, but I’ve noticed a big problem: it’s very easy to just believe whatever it says. Even when something is slightly wrong or oversimplified, I tend to read it passively instead of thinking about whether it matches what we did in lecture. For this special participation, I wanted a way to turn that into an active exercise where I’m forced to read explanations critically and practice catching subtle mistakes in deep learning concepts. So I designed a “Mistake-Spotting Coach” prompt specifically for CS182. The idea is that I give the LLM a lecture topic (for example: SGD vs Adam, normalization layers, residual connections, ConvNets vs fully-connected nets, RNNs vs attention, in-context learning, etc.). Using the prompt, the LLM then writes a short explanation of the topic on purpose with 2–3 subtle errors or misleading statements mixed in.  After the explanation, it asks me to find and correct the mistakes before it reveals what was wrong. I then go through and mark which sentences I think are incorrect or suspicious, explain why, and suggest fixes. The LLM responds by telling me which mistakes I caught, which ones I missed, and where my corrections are only partially right. Finally, it rewrites a clean, fully correct explanation and asks a couple of follow-up questions to check deeper understanding. Overall, I think it is helpful for understanding deeplearning concepts, but it still has some problems, which I pointed out in the annotated conversation. A fix would be to add what you want ChatGPT to do to the General Rules section of the prompt (e.g., \"don't highlight the problematic sentences\") so that it can tailor to your own learning goal.Annotated Conversation: https://drive.google.com/file/d/1_iLr4riCwdcg3p-_AzwjeLe6kAtF7y2T/view?usp=sharing", "resources": [{"type": "link", "url": "https://drive.google.com/file/d/1_iLr4riCwdcg3p-_AzwjeLe6kAtF7y2T/view?usp=sharing", "name": "Raw Text Link"}], "tags": ["Tutor", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7369769"}, {"id": 7368105, "title": "Special Participation E: Using Gemini Pro 3 and Claude Opus 4.5 for Jupyter Notebook Demos of Lecture Topics", "date": "2025-11-27T03:47:51.022066+11:00", "author": "Deena Sun", "content": "Executive Summary:I enjoy taking the concepts/theory we learn in class and applying them in code—I think it forces me to turn what I thought I understood through math or abstract concepts and make them more concrete by executing them. As a CS 189 course staff this semester, we’re creating a lot of demo notebooks and coding-forward Jupyter notebooks for students to try out. So taking inspiration from the demos in CS 189 as well as our coding homework problems, I decided to try to prompt LLMs and IDE-integrated coding assistants to produce some Jupyter notebook demos of topics covered in class.Prompt used:You are an expert deep learning instructor and advanced Python coder creating a demo for the Berkeley course CS 182, Deep Neural Networks. Your task is to produce a Jupyter notebook that explains and demonstrates the target topic. Use the written lecture notes and transcript of the lecture to inform what key concepts to cover in the demo for the target topic.\n\nThe notebook should following these key principles:\n1. Introduce the topic, describe its relevance in deep learning, and define core concepts from the provided transcript/lecture notes. If necessary, provide comparisons between solutions/practices covered in lecture that “didn’t work”, and those that “did work”.\n2. Use clear markdown cells to present essential theoretical background.\n3. Provide a complete Python implementation using PyTorch, Numpy, and Pandas libraries.\n4. Integrate plots and visualizations throughout to aid interpretation.\n\nFormatting guidelines:\n1. Use descriptive comments and narrative explanations alongside code. Write clear docstrings where needed.\n2. Limit total length to 100-150 lines of code and under 5000 words.\n3. The notebook should be runnable end-to-end in Colab or local Jupyter environments.\n\nOutput only the ipynb notebook.\n\nTarget topic:\n<INSERT YOUR TARGET TOPIC HERE>\n<MAKE SURE TO ADD PDF OF LECTURE NOTES AND TXT FILE OF LECTURE TRANSCRIPTS FROM YOUTUBE>\nI explored 2 LLMs:Gemini Pro 3 from the Gemini websiteI pasted in the prompt, added my target topic (Soft-prompting and soft-prefix prompting), and attached the pdf of lecture 21’s notes as well as a txt of lecture 21’s YouTube transcriptsSince I was using Gemini’s website rather than an IDE, Gemini produced a JSON that I then pasted into a .json file and converted into an ipynb by changing the file extensionClaude Opus 4.5 within CursorI pasted in the prompt, and attached lecture 21 ’s PDF notes and a txt of the YouTube transcriptsBoth models produced a runnable Jupyter notebook that included a toy encoder implementation, a toy task (Gemini used the task of reversing a sequence and Claude made dummy sequences to map to positive, negative, or neutral sentiment), training loops for soft-prompting, soft-prefixes, and frozen baseline models, and comparisons of parameter counts and training metrics. Furthermore, both models included detailed walkthroughs and explanations that motivated why soft-prompting/soft-prefixing could be useful, implementation details, and key takeaways.Some limitations I noticed from both models were the use of outdated additive positional embeddings (perhaps chosen for instructive simplicity). Claude’s implementation of soft-prefixing was flawed, and seemed equivalent to just appending the supposedly learned keys/values to the input sequence’s token embeddings.Overall, I was impressed with the thoroughness of both model’s demos. I found it a helpful guide towards seeing how a concept we discussed in class might actually be implemented in practice. The interactivity of a Jupyter notebook also makes it easier to play around and tweak things on my own (e.g. by adding extra print statements, adjusting different parameter sizes) that can not be as easily achieved by reading an article or textbook even if it does include code implementations.While this was a fun experiment to see how we could leverage LLMs to produce workable demos, I still ultimately find hands-on doing more effective for my learning than just reading through the demo, even if I’m actively engaged with the reading and trying to understand every step or identify potential errors. I’d be curious to see if this provides a good baseline demo that we could then ask another LLM to help “ablate” and add “TODOs” for students to fill out/code on their own.Gemini Pro 3 - Detailed AnalysisLink to my conversation with Gemini Pro 3: https://gemini.google.com/app/cbcac1c80e5f5041Jupyter Notebook:Some outdated practices I noticed from Gemini’s Transformer implementationToyGPT implementation uses additive learned absolute positional embeddings—which as mentioned in lectures 19 and 20 is no longer standard practice (in favor of NoPE or RoPE). However, more advanced techniques like RoPE require custom attention implementations (e.g. hooking into the Q, K tensors before they’re multiplied to apply the rotary transform). For instructive toy models in a demo, I can see how additive positional encodings might be simpler and easier to understand.The FFN/MLP uses GeLU rather than more recent alternatives like SwiGLU or ReLU^2Layernorms in the transformer encoder blocks instead of RMS normSome modern practices that Gemini’s transformer included which differed from the original Transformer paper:Pre-norm residual connections (adding the norm before the Attention sublayer and residual connections that bypass the norm entirely) versus post norm (normalizing after the residual add)I love that Gemini included the shapes of different tensors in the code comments. I often add these myself as I code to track the dimensions of things/sanity check/debug and I find that they really help my understanding as I implement. I also really appreciate that it makes some of the different dimension-changing functions (e.g. unsqueezed, expand, concat) more readable without having to guess at what they’re trying to do.The comments in the code for the CausalSelfAttention’s forward method were very detailed, and covered implementation details beyond what was mentioned in lecture.For instance, Gemini noted that we needed to adjust the shape of the causal mask when a soft-prefix is supplied to be [T, P + T] where P = prefix length and T = sequence length.Additionally, Gemini also explicitly outlined how the causal mask should still allow attending to all the prefixes and be causal for the rest of the tokens themselves.In the ToyGPT forward method, Gemini cuts off the soft prompt embedding token’s output predictions and only returns logits for the original T tokens. This makes sense because we don’t care about what the model predicts for the pre-prompt.Some things that Gemini included beyond the lecture scope:Comments inside PrefixTuning noted that usually the learnable prefix parameters are reparameterized through a small MLP for stability.General good coding practices that Gemini used:Seeding for reproducibilityPyTorch practice of explicitly checking and printing what device we’re usingUsing constants to set the model hyperparametersMakes copies of the base model for each variant (soft-prompting, soft-prefix, and base model only) so that the base models all start from the same random state for comparisonAlthough Gemini confidently provided an “Analysis of Results” for what I should expect to see, running the demo as given did not produce a frozen baseline with high/flat loss or a decreasing loss curve for soft prompting.Gemini also included a visualization of the soft prompt embeddings. However, unlike Claude, Gemini also included an interpretation of what we can use it for—it noted that we can apply a KNN-like search to find the nearest token in the real vocabulary to see if the soft prompt corresponds to any understandable human words.Claude Opus 4.5 - Detailed AnalysisLog of my conversation with Claude in Cursor:Jupyter Notebook:SimpleTransformer implementation uses additive learned absolute positional embeddings—which as mentioned in lectures 19 and 20 is no longer standard practice (in favor of NoPE or RoPE). However, more advanced techniques like RoPE require custom attention implementations (e.g. hooking into the Q, K tensors before they’re multiplied to apply the rotary transform). For instructive toy models in a demo, I can see how additive positional encodings might be simpler and easier to understand.Interesting that Claude actually referenced the lecture itself in the notebook: As described in lecture: \"The past queries have no influence except how they influence the keys and values. The state is the keys and the values.\"Some things that weren’t immediately clear/understandable to me:Why did we need MLP reparameterization for the soft-prefixes?What I was supposed to take away from 7: Visualizing Learned Soft Prompt Embeddings — what kinds of patterns should I be expecting?I don’t think that Opus actually implemented soft-prefix tuning. Its implementation is functionally a learned prepended prompt. True “prefix-tuning” injects learned key/value vectors directly into the attention cache of every transformer layer; this requires modifying each layer’s attention module so the extra K/Vs are concatenated before computing attention scores. Crucially, the code in SimpleTransformer simply concatenates the prefix to the token embeddings before the encoder. That makes the prefix act like extra prepended tokens (a soft prompt), not as layerwise K/V injections.Also, PrefixWrapper only returns the first layer’s keys even though SoftPrefix stores tensors shaped like per-layer K/Vs, get_all_prefixes(). I’m not sure why Claude decided to only provide a “simplified” version of get_all-prefixes. But since the SimpleTransformer never consumes layer-specific prefixes, the stored K/Vs are never wired into the attention blocks.", "resources": [{"type": "link", "url": "https://gemini.google.com/app/cbcac1c80e5f5041", "name": "Link"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/b8QU2HapAUltFbUPJ5Iw63w8", "name": "gemini_soft_prompting_demo.ipynb"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/CmMv9Yx4ZSqIcJXB5l5tpUre", "name": "claude_jupyter_notebook_log.md"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/wW7M7blWuVjtHuApecz2Indd", "name": "claude_soft_prompting_demo.ipynb"}, {"type": "link", "url": "https://gemini.google.com/app/cbcac1c80e5f5041Jupyter", "name": "Raw Text Link"}], "tags": ["Tool/App", "Coding", "Study Guide", "Visualization", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7368105"}, {"id": 7363141, "title": "Special Participation E: AI Assisted Annotations", "date": "2025-11-25T17:35:52.347178+11:00", "author": "Jason Trinh", "content": "When trying to use LLMs to study from CS182 lecture notes, hws, or readings, I was constantly switching between three things: the PDF viewer, an LLM tab, and my own notes. I had to copy-paste text or screenshots into the model, read the answer, then flip back to the PDF and try to remember which part it was referring to, which became a really tedious process. And oftentimes, a week later, I don't remember where I had the conversation with the LLM. So I decided to put everything into a single tool.https://jaizunt.github.io/pdf_analyzer/I built PDF Analyzer, a small web tool that lets you:Upload any PDF (lecture notes, papers, homework solutions, etc.).Highlight text or crop a region of a page (e.g., a figure or equation).Ask an LLM (Gemini / GPT / Claude) to explain or summarize that exact snippet (or you can enter your own custom prompt).Attach your own notes, and thenExport everything back into an annotated PDF (with sticky notes as the annoations [these don't render latex]) or a  “study session” you can re-load later..jsonIt uses a system prompt tailored towards providing a comprehensive response related to Deep Learning.In using this tool, it seems like the response that the LLM provides often results in long and extensive explanations. This is both good and bad (notes are supposed to be concise, but thorough explanations are helpful in understanding the material better). There could be some way of resolving this via a highly specific system prompt that forces the LLM to be as concise as possible (the system prompt I have currently is some form of that, but it seems to deviate from the instructions a little). Additionally, as you will see in some of my example files, there are some cases where it hallucinates (even on the newer models - GPT 5.1). I have attached below a video of me using it and annotations of examples.", "resources": [{"type": "link", "url": "https://jaizunt.github.io/pdf_analyzer/", "name": "Link"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/x0s5GPUKGtIHGOmDLnDNfX9j", "name": "Annotations_Video.mp4"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/qXOmkXmPwHQhwnjKRhMjXZ9v", "name": "gnn_annotated.pdf"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/K7s6uCtyX9x1ZSDJaW4RsVK8", "name": "polar_annotated.pdf"}, {"type": "link", "url": "https://jaizunt.github.io/pdf_analyzer/I", "name": "Raw Text Link"}], "tags": ["Tool/App", "Study Guide", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7363141"}, {"id": 7360755, "title": "Special Participation E: Activation Visualizer for Neural Nets", "date": "2025-11-25T08:44:55.453395+11:00", "author": "Jason Trinh", "content": "I built an “Activation Visualizer” web app and then embedded an AI assistant directly into it so it can act as a pre‑/post‑lecture study companion for CNNs, RNNs, MLPs, and Transformers.Feel free to check it out at:https://jaizunt.github.io/activation_visualizer/(GitHub Repository)https://github.com/jaizunT/activation_visualizerI went down a major rabbit hole on this—ended up spending basically an entire day modifying the project until it became both a genuinely useful and highly interactive tool rather than just a static visualization. I used an initial prompt generated from GPT 5.1 Thinking, inserted it into Gemini 3 Pro, and went through numerous modifications/iterations (vibe coding on Windsurf with GPT 5.1 Codex - High Reasoning) to make everything mathematically work with proper visualizations.Activation Visualizer simulates small neural networks and shows:Layer-by-layer activations and dimensions.How changing inputs/weights/initial hidden states changes outputs.For RNNs: sequence‑by‑sequence behavior and per‑layer .h₀For CNNs: 2D inputs, kernel size, and sliding conv animation.(You’ll need your own API key for whichever provider you choose if you want to use the AI Assistant; the key stays in your browser and is sent directly to that provider.)There are currently 4 architectures available to look through, though transformers has not been interactively implemented yet. You can select them in the top right. My favorite is the RNN.For MLP, CNN, and RNN, you can select the dimensions, set your inputs or parameters via manual editing or randomizing, and you can visualize the activations each step of the way. You also can adjust individual parameters and see how they affect the output.Note that some features are still in the works (not able to view gradients, inserting blocks, etc.), and there are probably lots of bugs still (i.e. trying to break the engine via setting 1000 hidden layers for cnns).Feel free to comment below any questions you have about any of the features, since there are a lot of parts to this.I had to restart my chat in a new conversation numerous times because I think the context became too long... How the LLM PerformedWhat it did wellTurning ideas into code. I could describe a desired feature in plain language (e.g., per‑layer RNN , freezing CNN/RNN weights, adding an AI assistant sidebar), and the LLM usually produced coherent React/TypeScript changes touching the right files and props.h₀Managing complex state wiring. It handled a lot of the repetitive plumbing: adding new state variables, updating dependency arrays, and passing data between App.tsx, the engine, and visualization components without me having to write all the boilerplate.Math‑aware reasoning. When debugging, it connected behavior back to the math (e.g., CNN output shapes, RNN causality) and helped explain why certain outcomes were expected given the formulas.Rapid iteration. It made it easy to try UI/UX variants quickly (buttons, layout, defaults) and to experiment with different ways of exposing parameters like kernel size or .h₀Where it struggled / hallucinatedSmall but important mistakes. Some patches were almost correct but had issues like missing props, slightly malformed JSX, or incorrect assumptions about types. I had to rely on compiler errors and my own reading to fix these.Over‑confident explanations. At times it proposed plausible but wrong hypotheses about behavior (e.g., why RNN outputs were changing) until we inspected the actual code and data flow more carefully.Limited UX judgment. It could suggest reasonable layouts, but whether the interface actually felt clean (spacing, font sizes, button labels, clutter) still required my own manual tweaking and visual judgment.Some other limitations I noticed were that some of my requests that I made were incomplete after the 'agent' did its work (consistent across multiple messages), and I had to explicitly say numerous times what I wanted. However, I do think my conversations could be more effective if I provided a specific 'TODO' or structure of what needs to be implemented as is often presented in 'structured prompts'.Overall, the LLM was very effective as a “force multiplier” for coding and refactoring, but it definitely wasn’t a drop‑in replacement for understanding the code or the underlying neural network concepts—I still needed to verify, correct, and refine its suggestions.", "resources": [{"type": "link", "url": "https://jaizunt.github.io/activation_visualizer/", "name": "Link"}, {"type": "link", "url": "https://github.com/jaizunT/activation_visualizer", "name": "Link"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/CuuSHIqdCbxaFtlOPtBcSkqB", "name": "prompt.txt"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/kTOJjYSGeKz0vHnbjlDxyIO0", "name": "Chat1.md"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/Of4K1zRfISmvZMhGd9m9a18b", "name": "Chat2.md"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/WANrFKubQ0gkDDg04u3LJh6Q", "name": "Chat3.md"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/50N2WVdFotm06ixLplayqZbh", "name": "Chat4.md"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/y44b0pvre5CZaOlUqdQkrFVj", "name": "Chat5.md"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/2lZXdPfuUkNDYgDqCGmlKDye", "name": "Chat6.md"}, {"type": "link", "url": "https://jaizunt.github.io/activation_visualizer/(GitHub", "name": "Raw Text Link"}, {"type": "link", "url": "https://github.com/jaizunT/activation_visualizerI", "name": "Raw Text Link"}], "tags": ["Tool/App", "Coding", "Visualization", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7360755"}, {"id": 7356236, "title": "Special Participation E: Using ChatGPT to Review Lecture 22 and Prepare for Lecture 23", "date": "2025-11-24T11:18:30.942572+11:00", "author": "Ruizhe Song", "content": "In this Special Participation E, I want to share my learning process between Lecture 22 and Lecture 23. In Lecture 21~22, professor taught us how well-designed prompts can instruct the LLM to get better performance. The main methods range from \"soft-prompt\", which add learnable prompts to the input sequence, to \"pre-fixer\", which directly makes the Ks and Vs learnable parameters, then to \"LoRA\", which aims at updating the weight matrix with W = W*+delta(W) and finally to \"meta-learning\", which aims at making a model better at being fine-tuned. When I review my notes after class, I find myself re-organizing them as a large family of fine-tuning methods, only from different perspectives. This ed post is about my whole review and re-organizing process of all the methods  between Lecture 22 and Lecture 23. I asked GPT5 in an \"evolving\" order from prompt-based methods to the general meta-learning method, let it explain my confusions and the relationship between these methods. And I think this chatting helps me to better prepare for the upcoming Lecture 23 in which I got to learn more about meta-learning, also gives me a better understanding of the previous Lecture 22 and 21.Here's the pdf version of chat log with my comments:I consider this a valuable self-refining process. With the help of LLMs these days, the way of collecting information and learning new concepts becomes different. We don't have to google \"what is meta-learning\" \"why is the delta(W)=AB initialized like that\" and search for high-quality post on the Internet. But meanwhile, we have to be careful to not rely too much on LLMs. The generated answers could block our eyes to the open real world. We need to engage with real-world sources and diverse perspectives.", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/b0eC9BwZTph08c6YBt78ODqM", "name": "Special-Participation-E-lec22.pdf"}], "tags": ["Study Guide", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7356236"}, {"id": 7354053, "title": "Special Participation E: Claude for Homework Cramming", "date": "2025-11-23T20:26:37.729054+11:00", "author": "Jameson Liu", "content": "My personal studying strategy (whether effective or not) when reviewing homework/exams is to mentally attempt a question before reading the solution, allowing me to process a large number of questions in a short time. I wanted to do this in a more interactive way, so I asked Claude (explanatory mode) to help me with it.I used Claude instead of ChatGPT because:1. ChatGPT kept asking weird rewordings of the questions2. Worse at giving context3. Sometimes failed to parse the .pdfI provided the solutions (publicly accessible given Ed link), asked Claude to identify the most important problems, and then prompted it to ask me to give a conceptual approach before either going over the solutions or guiding me in the correct direction.Prompt:\"I'm on a time crunch, and I need to study for my Deep Neural Networks exam by reviewing the homework. Here is the first homework and solutions: https://static.us.edusercontent.com/files/aO8NnPYdzjOpEyEphrp1j0nZI want you to:1. Identify the 5 most important problems (count subparts as individual problems)2. Ask me each question with its entire context, preferably barely modified, one at a time3. I will respond with a conceptual approach (I don't have time to fully solve)4. If I am correct, output the entire solution and move on to the next question; otherwise, continue guiding me to the correct approach\"The results were better than expected. Claude was surprisingly good at picking out complicated problems while simultaneously summarizing all the necessary context, explaining the implications of solutions, and giving me hints. The main downside of this approach is that Claude's usage limit is quite small, making it unsustainable. Since the entire chat session took less than 20 minutes, I felt like this was a pretty time-effective way to study. Although I didn't get to cover most of the homework, I imagine this would be valuable if I really only had a short amount of time to study. More details can be found in the annotated chat:Also, here is an example of what ChatGPT asked me; I don't think it understood the purpose of my prompt:", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/6UZuY5izaNGKshSMsq7RJIqx", "name": "claude.pdf"}, {"type": "image", "url": "https://static.us.edusercontent.com/files/H5CBht7K9l0WBO6owgRruSNI", "name": "Image"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/aO8NnPYdzjOpEyEphrp1j0nZI", "name": "Raw File Attachment"}], "tags": ["Tool/App", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7354053"}, {"id": 7335566, "title": "Special Participation E: Converting Lectures to Notes", "date": "2025-11-19T20:11:54.045815+11:00", "author": "Jameson Liu", "content": "I wanted a way to convert the lectures into a notes format, similar to those in CS70. This way, it would be easier to look for specific content and review material without needing to scan through the lecture recordings, timestamp by timestamp. While the lecture slides are posted, they alone do not cover everything stated in the lecture. Therefore, I wrote a script to use an LLM to convert lectures into well-formatted, academic notes. It uses lecture slides and the transcript of the lecture recording (easily copyable), so no information is left out. An LLM is necessary for this task since 1. the YouTube transcript has several mistakes, and 2. traditional .pdf readers are not great at extracting handwritten text (especially math). I had to use the Gemini API instead of a typical LLM website, since uploading a .pdf usually just extracts its text instead of having the LLM read it visually (which is a problem since traditional OCR fails). My code takes every page of the lecture slides and converts it to an image before appending it to the request (I verified that this works by testing it without providing a transcript).Below is the script and an annotated example (rendered from .tex) output. Running it requires a Gemini API key, which is free (subject to rate limit). The following is from lecture 2, and the transcript is copied directly from the YouTube transcript section (description -> transcript -> hide timestamps).", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/Cd3H2Ms186TdwbAbUYsO21an", "name": "lecture_notes_generator.py"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/KMYhxbngSstZOFkUIqeGe4ED", "name": "lecture_transcript.txt"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/b3OLyIUjmGeTp9nUFOzrYzXB", "name": "lecture_notes.pdf"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/CGZZqK2lhpg57awIG1m4WKzU", "name": "lecture_notes.tex"}], "tags": ["Tool/App", "Coding", "Study Guide", "Visualization"], "original_url": "https://edstem.org/us/courses/84647/discussion/7335566"}, {"id": 7319120, "title": "Special Participation E: Using ChatGPT to understand papers", "date": "2025-11-17T08:30:34.025542+11:00", "author": "Jason Guo", "content": "I find reading papers on deep learning to be pretty difficult at times, because they often assume a level of mathematical knowledge or background knowledge that I don't have. Because of this, it feels like papers under explain a lot of things, making them hard to understand.I was interested in seeing the proof for a claim that was stated, but not proved, in lecture 8, so I thought it would be interesting to get ChatGPT to explain the proof to me. The claims I wanted it to prove are claims 1 and 2 here: https://arxiv.org/pdf/2310.17813Overall, I think it did a good job of filling in the blanks of certain steps that are glossed over in the paper, and answering follow up questions to clarify confusion. However, I think the way ChatGPT presents information can kind of be disorganized and confusing, so it takes some work to figure out what exactly the structure of its claims or proofs are. In particular, it often answers things in bullet points or divides its answers up into sections, rather than just answering in full sentences and paragraphs, which makes it confusing for me at times.Annotated conversation with more detailed comments: https://drive.google.com/file/d/1r-ZZ3-P1c_IzPMdpXhegt_hDgqfDU0U4/view?usp=sharing", "resources": [{"type": "link", "url": "https://arxiv.org/pdf/2310.17813", "name": "Link"}, {"type": "link", "url": "https://arxiv.org/pdf/2310.17813Overall,", "name": "Raw Text Link"}, {"type": "link", "url": "https://drive.google.com/file/d/1r-ZZ3-P1c_IzPMdpXhegt_hDgqfDU0U4/view?usp=sharing", "name": "Raw Text Link"}], "tags": ["Math", "Visualization"], "original_url": "https://edstem.org/us/courses/84647/discussion/7319120"}, {"id": 7300719, "title": "Special Participation E: Attention and Transformers Visualized with Claude Sonnet 4.5", "date": "2025-11-13T09:46:15.187018+11:00", "author": "Leon Kornfeld", "content": "I’d been struggling to reason about how information flows through attention and transformer blocks at a low level—specifically how the matrix multiplications and changing dimensions still produce an output with the same dimensionality as the input. I was also unclear on how multi-head attention differs from single-head attention and how the whole mechanism fits together.To sort it out, I used Claude to build a visualization that traces the full path through a transformer. I iterated on it: starting with high-level questions, refining answers, and ending with a 14-step walkthrough that explains attention, the transformer block, and the computations between them.Here is the published link of the visualization: https://claude.ai/public/artifacts/2ef271c0-bffd-4709-a7e4-cdc2d66bb2b8As I went, my questions became more targeted, drilling into different parts of the architecture.At the end, in addition to reviewing Claude's output, looking for any hallucinations, I also pasted the entire source code into GPT-5 to see if it could find any mistakes. GPT was able to point out some assumptions that Claude made that weren't as clear as they could have been. I took GPT's feedback and gave it to Claude for the final iteration of the tool.Here is my annotated transcript:", "resources": [{"type": "link", "url": "https://claude.ai/public/artifacts/2ef271c0-bffd-4709-a7e4-cdc2d66bb2b8", "name": "Link"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/YbYkT62G1SqWbf9FlhoZmEp2", "name": "Claude-Transformer attention mechanism visualization.pdf"}, {"type": "link", "url": "https://claude.ai/public/artifacts/2ef271c0-bffd-4709-a7e4-cdc2d66bb2b8As", "name": "Raw Text Link"}], "tags": ["Tool/App", "Coding", "Quiz/Drill", "Visualization"], "original_url": "https://edstem.org/us/courses/84647/discussion/7300719"}, {"id": 7289919, "title": "Special Participation E: Debugging Exercise with Gemini Guided Learning (GNNs)", "date": "2025-11-11T12:53:10.285299+11:00", "author": "Aaryan Chandna", "content": "Personally, I learn well by doing exercises that involve the identification of mistakes or reasons to employ specific techniques. This inspired me to develop a debugging exercise with Gemini's Guided Learning, where I fed the slides for Lecture 12 (GNNs) as input and initially asked the model to provide me with a guide on the lecture slide material over 3 prompts, letting it know in advance to prepare for the debugging exercise. I then had Gemini create 2 debugging exercises for myself to complete, followed by a verification of the answers and explanation. I cannot include the actual link to the conversation unfortunately because Gemini prohibits sharing conversations on school accounts, but I have included the PDF of the interaction trace with my comments.Reflection - I think providing the lecture slides was a good move as Gemini was able to discuss almost all the concepts from the lecture and explain them well. with some exceptions (didn't discuss the image classification vs semantic segmentation case, didn't get into directed vs undirected graphs). It also mostly prevented hallucination or the usage of formulas that were not in the actual slides, which helped align the discussion with what was relevant towards the course. There was, however, one minor case of hallucination, and the debugging exercises had material/answers that were correct but were not discussed in the guide, which was a significant weakness of this option. Moreover, I was disappointed by the lack of visuals provided by Gemini, even using the Guided Learning mode. The biggest strength of Gemini on this task, in my opinion, was providing relevant and thorough explanations that were still concise enough that I would be able to understand the necessary concepts quickly.", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/A2ejEufCSlXMQuag5EyT7KpQ", "name": "geminifinal.pdf"}], "tags": ["Tool/App", "Study Guide", "Visualization", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7289919"}, {"id": 7287291, "title": "Special Participation E: Grok4(fast) as a teacher on SSM", "date": "2025-11-11T06:28:07.024815+11:00", "author": "Zhangzhi 'csrookie' Xiong", "content": "In this part, I will use Grok4 (fast) as a teacher to teach me about SSM (State Space Model). I will try to let LLM to fully help me to understand this knowledge. I will attach my prompt and LLM's response (they are exported as a separated file), and my personal comment on LLM's response.", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/6B4exsCcmrwY1lnSOsMjV3WB", "name": "grok.pdf"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/cPZVGFVnVIPMaIPzG0VzYqlL", "name": "log.pdf"}], "tags": ["Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7287291"}, {"id": 7281484, "title": "Special Participation E: ChatGPT as a post-lecture learning approach", "date": "2025-11-10T06:26:24.178702+11:00", "author": "Ruizhe Song", "content": "I usually have some new questions when I review my notes after class. Some questions indicate that I don't fully understand the specific deep learning mechanism on the class, while others are about the reason why we are using these techniques(in other words why something seems pretty normal but works well). This ed post is about the  kind of questions, which I don't fully understand on the class, and managed to solve with the help of ChatGPT firstas a powerful post-lecture learning tool.In this special participation E, I plan to share my post-lecture self-learning trace after Lecture 18 & 19 with ChatGPT5. The two classes cover the important attention mechanism and Transformer architecture. After the post-lecture learning process, I understand the attention layer and transformer better. It even makes the coming classes and discussions clearer to me.Here's the pdf version of chat log with my comments:In this log, I asked questions step-by-step, and let GPT guide me to change my way of thinking in RNN and SSM to attention mechanism and Transformer architecture. During this process, GPT successfully:1. Corrected my wrong understanding about how attention layer works. 2. Made concrete examples to illustrate the training/inference process in transformer architecture and attention layers, which helped me understand much more quickly.3. Gave mathematical representations and detailed illustrations of them to make the whole intuition clear.", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/ydpSFWtljJ9a0RoRqsbAub7D", "name": "Special-Participation-E.pdf"}], "tags": ["Tool/App", "Study Guide"], "original_url": "https://edstem.org/us/courses/84647/discussion/7281484"}, {"id": 7280239, "title": "Special Participation E: Quiz and Flash Cards for Adam / SGD", "date": "2025-11-09T18:21:02.198615+11:00", "author": "Andy Zhang", "content": "Special Participation E: Quiz and Flash Cards for Adam / SGDFor background, Gemini claims that they can create quizzes, flash cards & study guides according to https://support.google.com/gemini/answer/16275879?hl=en&co=GENIE.Platform%3DAndroidEspecially since Gemini Pro is free for Berkeley students, I first explored and confirmed that Gemini could indeed create those; it created specific and specialized artifacts for only Quizzes and Flash Cards (and you need to be careful about language) which made it more convenient than text.While the initial the quiz and flash cards were reasonable, they are generally conceptual (e.g. the purpose of the first and second moments of Adam, the purpose of hyperparameters etc.) so I wanted to explore whether the quizzes and flash cards could be more mathematical and cover more rigor similar to our course and see whether latex could properly render in the quiz and flash cards.From there I was able to develop an improved prompt to have more mathematics to be more aligned with our course, formatted properly in latex. And depending on one’s presences, the model can be steered to act accordingly. My recommendation is that these could be helpful to students to review concepts such as Adam and SGD especially after several weeks have passed before the final. My recommended order is to go through the flash cards for a memory refresher and then take the quiz to ensure the concepts are cemented.Traces with detailed comments: https://drive.google.com/file/d/1X6M9JPHW4GRSUKRFckDdFsxYcfWyB-97/view?usp=sharingIndividual traces:Undetailed Prompt Trace Flash Cards:https://gemini.google.com/share/ed66de185158Undetailed Prompt Trace Quiz:https://gemini.google.com/share/598e4b5cfbccUndetailed Flash Cards:https://gemini.google.com/share/cfd44ed946d6Undetailed Quiz:https://gemini.google.com/share/6fab8238136eFlash cards / quizzes:Detailed Prompt Trace for Flash Cards with Math:https://gemini.google.com/share/f7957da6c0d1Detailed Prompt Trace for Quiz:https://gemini.google.com/share/ec87b322ca7eDetailed Flash Cards: https://gemini.google.com/share/6afed4acff7bDetailed Quiz: https://gemini.google.com/share/01910a14266a", "resources": [{"type": "link", "url": "https://support.google.com/gemini/answer/16275879?hl=en&co=GENIE.Platform%3DAndroid", "name": "Link"}, {"type": "link", "url": "https://drive.google.com/file/d/1X6M9JPHW4GRSUKRFckDdFsxYcfWyB-97/view?usp=sharing", "name": "Link"}, {"type": "link", "url": "https://gemini.google.com/share/ed66de185158", "name": "Link"}, {"type": "link", "url": "https://gemini.google.com/share/598e4b5cfbcc", "name": "Link"}, {"type": "link", "url": "https://gemini.google.com/share/cfd44ed946d6", "name": "Link"}, {"type": "link", "url": "https://gemini.google.com/share/6fab8238136e", "name": "Link"}, {"type": "link", "url": "https://gemini.google.com/share/f7957da6c0d1", "name": "Link"}, {"type": "link", "url": "https://gemini.google.com/share/ec87b322ca7e", "name": "Link"}, {"type": "link", "url": "https://gemini.google.com/share/6afed4acff7b", "name": "Link"}, {"type": "link", "url": "https://gemini.google.com/share/01910a14266a", "name": "Link"}, {"type": "link", "url": "https://support.google.com/gemini/answer/16275879?hl=en&co=GENIE.Platform%3DAndroidEspecially", "name": "Raw Text Link"}, {"type": "link", "url": "https://drive.google.com/file/d/1X6M9JPHW4GRSUKRFckDdFsxYcfWyB-97/view?usp=sharingIndividual", "name": "Raw Text Link"}, {"type": "link", "url": "https://gemini.google.com/share/ed66de185158Undetailed", "name": "Raw Text Link"}, {"type": "link", "url": "https://gemini.google.com/share/598e4b5cfbccUndetailed", "name": "Raw Text Link"}, {"type": "link", "url": "https://gemini.google.com/share/cfd44ed946d6Undetailed", "name": "Raw Text Link"}, {"type": "link", "url": "https://gemini.google.com/share/6fab8238136eFlash", "name": "Raw Text Link"}, {"type": "link", "url": "https://gemini.google.com/share/f7957da6c0d1Detailed", "name": "Raw Text Link"}, {"type": "link", "url": "https://gemini.google.com/share/ec87b322ca7eDetailed", "name": "Raw Text Link"}, {"type": "link", "url": "https://gemini.google.com/share/6afed4acff7bDetailed", "name": "Raw Text Link"}], "tags": ["Study Guide", "Quiz/Drill", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7280239"}, {"id": 7276004, "title": "Special Participation E: ChatGPT Lecture Comprehension Buddy", "date": "2025-11-08T14:41:05.880912+11:00", "author": "Bruno Vieira", "content": "I used ChatGPT's \"Study\" mode to help me better understand lectures. Many times, I find myself not really knowing how to prepare ahead of lectures, and I always have questions that get passed on to more questions in discussions, and so I just find myself sometimes \"drowning\" and wishing I had more support to answer some basic questions that can help me not get behind. For this, I decided to test ChatGPT with Thursday 11/07's lecture to help me prepare before the lecture and help me get all my questions answered before next week's lecture. Below, I have uploaded the full conversation I had with comments. I also put here a pre-lecture PDF that ChatGPT gave me.In all honesty, the summary is that I preferred Claude as it is better with visuals, and I thought that ChatGPT didn't really go that deep into the content. On the other hand, the conversation we had before I went to the lecture drastically improved my experience in the lecture - highly recommend!!", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/4P4H8nUZm0uWXT3GrMuApHNN", "name": "Prelecture_Notes_InContextLearning_PEFT.pdf"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/gLCYq39bF14aT98XEDEY6GaN", "name": "Prelecture notes guide.pdf"}], "tags": ["Study Guide", "Visualization"], "original_url": "https://edstem.org/us/courses/84647/discussion/7276004"}, {"id": 7252696, "title": "Special Participation E: Concept Map Mermaid Diagrams of Research Papers", "date": "2025-11-04T15:15:24.914928+11:00", "author": "Deena Sun", "content": "Using LLMs to create concept maps/Mermaid diagrams of key concepts and related works in research papers.When reading machine learning research papers, I like to synthesize how the different concepts introduced in the paper fit together and how related works tie into the ideas covered in the paper. I usually find this helpful for breaking down ML research into more digestible chunks as well as for creating a roadmap for how I can further my understanding using the citations referenced in the paper. I decided to use Claude 4.5 Sonnet on Perplexity to help me create concept maps of research papers that could visually display connections between key ideas in the paper, how related works contributed to the paper’s takeaways, and additional papers for further exploration.First, I used Claude 4.5 Sonnet to help me generate an effective prompt I could reuse for LLMs based on my idea. I started off asking Claude for a general purpose deep learning tutoring prompt that would guide me through a research paper. Then, I focused the prompt to involve the LLM generating a workable Mermaid diagram representing my concept map idea. Claude gave me some helpful advice for how to productively prompt other LLMs for studying purposes:Provide context about your role and goals, including your background knowledge and your learning growsAssign the LLM a specific persona (e.g. “You are a deep learning teaching assistant…”) to tailor the model’s responses towards educational guidance.Provide example interactions and specify what the output format should beAfter some back and forth to modify the prompt to my desires, I took the draft prompt that Claude suggested and used it to prompt another instance of Claude 4.5 Sonnet to actually generate a Mermaid diagram of a concept map for the paper “A Spectral Condition for Feature Learning” we read in homework 3, question 3. I also included a PDF of the paper as an attachment.Here is the final Mermaid diagram that Claude 4.5 Sonnet produced, rendered using a Mermaid diagram editor:Here is the prompt I used to generate this concept map that you can use!You are a deep learning teaching assistant helping me map out conceptual relationships in a research paper.\n\nYour task:\n* Carefully read the research paper \"[PAPER TITLE]\" and identify all major concepts, methods, and results.\n* Build a structured concept map (\"brain map\") using Mermaid syntax (graph TD), where:\n    * Nodes represent key topics, methods, or results. Include related works and references inside the nodes.\n    * Edges connect related nodes, with descriptive labels explaining the relationship (not just keywords).\n    * Node labels are clear and concise; avoid line breaks for compatibility.\n* For each node, list relevant citations and references (from the paper and cited works) below the diagram, grouped by concept.\n* Flag nodes that are central (highly connected) or have many references, and highlight these for further study.\n* If supported, also generate a PNG image of the diagram for visual reference.\n\nOutput Instructions\n* Present the concept map first using Mermaid syntax in a Markdown code block. Use graph TD, clear node labels, and descriptive edge labels (e.g., --> |enables parallel attention|).\n* Represent the 10 most important concepts as nodes in the Mermaid diagram. Include related works and references inside the node.\n* List all references/citations grouped by node below the diagram (not inside node labels).\n* If possible, generate and return a PNG image of the diagram.\n* Avoid using special characters such as parentheses in labels that might not be compatible with Mermaid diagram generators.\n\nFormat example:\n```\ngraph TD\n Transformer[\"Transformer Model (Vaswani et al. 2017)\"]\n SelfAttn[\"Self-Attention (Bahdanau et al. 2014; Lin et al. 2017)\"]\n MultiHead[\"Multi-Head Attention (Vaswani et al. 2017)\"]\n PosEnc[\"Positional Encoding (Gehring et al. 2017)\"]\n Adam[\"Adam Optimizer (Kingma & Ba 2014)\"]\n Transformer -->|Directly models all pairwise token dependencies with attention| SelfAttn\n Transformer -->|Requires token position information for context awareness| PosEnc\n Transformer -->|Is trained efficiently using adaptive gradient optimization| Adam\n SelfAttn -->|Provides the base mechanism for building rich token representations| MultiHead\n MultiHead -->|Enables parallelized, diverse attention for complex relationships| SelfAttn\n\nReferences by Node:\n* Transformer Model: Vaswani et al. 2017, Gehring et al. 2017, Wu et al. 2016\n* Self-Attention: Bahdanau et al. 2014, Lin et al. 2017, Parikh et al. 2016\n* Multi-Head Attention: Vaswani et al. 2017, Britz et al. 2017\n* Positional Encoding: Gehring et al. 2017, Sennrich et al. 2015\n* Adam Optimizer: Kingma & Ba 2014\n```\n\nBackground:\nI am an undergraduate student who is interested in machine learning, deep learning, and research in these fields.\n\nPaper abstract/intro:\n[COPY HERE]Here are the logs of my chats that I used to brainstorm my prompt as well as to create the Mermaid diagram:", "resources": [{"type": "link", "url": "https://mermaid.live/edit", "name": "Mermaid diagram editor"}, {"type": "image", "url": "https://static.us.edusercontent.com/files/JpxdsphfUuRv1gGhtbJikn5g", "name": "Image"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/3w2hhk3gVZSU1c7OeKythrA8", "name": "Research_graph_prompt_creation_chat.pdf"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/xKoVyP3TX2Rof6dDLfOjctCf", "name": "Spectral_condition_for_feature_learning_concept_map_chat.pdf"}], "tags": ["Coding", "Study Guide", "Visualization", "Prompt Eng", "Tutor"], "original_url": "https://edstem.org/us/courses/84647/discussion/7252696"}, {"id": 7249718, "title": "Special Participation E: Using GPT to Deepen Lecture Understanding", "date": "2025-11-04T07:54:01.158912+11:00", "author": "Ben Yu", "content": "What I built:During lectures, I used ChatGPT as an interactive study partner rather than a passive note tool.Whenever a concept felt unclear, I would pause the lecture, take a screenshot, and ask a precise question in my EECS 182 project space. Each numbered thread (Week #) became a mini-lab where I clarified equations, verified derivations, and then reinterpreted AI’s explanation directly into my written lecture notes:For example (image below), in Week 9's lecture, I used GPT as my study partner to clarify the concept of Fast Fourier Transform on State Space Models, which was barely mentioned on during lecture. This way I can freely choose to dive deeper into specific concepts while learning the broad picture from the lecture.Example Conversation — Lecture 9: Hidden-State IndependenceTrace Link: https://chatgpt.com/g/g-p-68b1f76ecfb8819191ec5b17c4fdd059-cs-182/shared/c/68feaa70-8378-8333-a027-5935fdf14461?owner_user_id=user-AdVlGKTV9Sn7SdTqllGbrt2GOne of My Question: “So the point (of use block diagonal matrix B in state space calculation) is to make hidden states independent?”AI-Guided Insights: Correlated hidden states introduce redundancy and unstable gradients, because each state begins to carry overlapping information about the sequence. By using block diagonal matrices, each hidden unit evolves as a unique information channel, making the system more stable and interpretable by decoupling the updates of different state components, because independent states yield better gradient flow, improved generalization, and a cleaner mapping between model structure and learned function.Verification:I implemented diag_unrolled_ssm_forward and diag_conv_ssm_forward to confirm the theory, and their outputs matched within 1e-6 and reproduced the predicted runtime behavior -- linear in T for recurrence, nearly constant on GPU for convolution.After each exchange, I try to reexplain the idea in my handwritten notes, converting the long AI reasoning into a concise conceptual summary that I could review quickly before exams.Comments:Positives (What Worked Well):Immediate conceptual clarification: AI interaction let me elaborate on lecture ideas in real time rather than waiting for Ed Forum or office-hour responses.Reduced TA load: Routine clarifications that might have required staff input were handled independently, keeping my questions tightly scoped to lecture material.Deeper integration: Reading the AI’s full reasoning line by line forced me to engage with the derivations more carefully than a static answer key would have.Negatives (Limitations and Effort Required):Scope uncertainty: The AI occasionally referenced material outside the intended EECS 182 syllabus, requiring me to filter which concepts were truly in scope.Potential over-explanation: Responses sometimes included extra theoretical context that, while interesting, risked obscuring the specific idea being tested.Future Improvements:Structured project workflow: As outlined in my companion submission “Special Participation E: AI-Enhanced Learning with ChatGPT Project Mode,” we can formalize a workflow where each thread explicitly records lecture context, question scope, and verified outcomes.This process exemplifies how AI can enhance learning when guided by course scope, topical context, and consistent self-reflection.", "resources": [{"type": "image", "url": "https://static.us.edusercontent.com/files/MOPsugkwHHt4DRZL9dIWgPNZ", "name": "Image"}, {"type": "link", "url": "https://chatgpt.com/g/g-p-68b1f76ecfb8819191ec5b17c4fdd059-cs-182/shared/c/68feaa70-8378-8333-a027-5935fdf14461?owner_user_id=user-AdVlGKTV9Sn7SdTqllGbrt2G", "name": "Link"}, {"type": "link", "url": "https://chatgpt.com/g/g-p-68b1f76ecfb8819191ec5b17c4fdd059-cs-182/shared/c/68feaa70-8378-8333-a027-5935fdf14461?owner_user_id=user-AdVlGKTV9Sn7SdTqllGbrt2GOne", "name": "Raw Text Link"}], "tags": ["Tool/App", "Math", "Study Guide"], "original_url": "https://edstem.org/us/courses/84647/discussion/7249718"}, {"id": 7249252, "title": "Special Participation E: AI-Enhanced Learning with ChatGPT Project Mode", "date": "2025-11-04T06:54:39.812496+11:00", "author": "Ben Yu", "content": "What I built:A repeatable workflow that uses ChatGPT project mode as a study copilot across lecture, discussion, and homework -- it summarizes past questions/answers from my chat history into chronological tables and acts like a “cache layer” I can backtrack during reviews.Project Setup:Prompt:You are my personal TA for UC Berkeley’s EECS 182/282A: Deep Neural Networks, Fall 2025.\nYour job is to help me learn, review, and succeed in this course.\n\nStick to course scope: topics include optimization, convnets, ResNets, GNNs, RNNs, state-space models, transformers, prompting, transfer/meta-learning, generative & diffusion models.\n\nHelp style:\nKeep explanations simple, direct, and intuitive before going deep in math/code.\nUse examples (math, code, visual intuition) tied to the syllabus sequence.\n\nYour primary goals:\nHelp me understand concepts deeply (intuition + formalism).\nHelp me practice effectively (HW, projects, exam prep).\nProject Files:pdf of course syllabus from https://berkeley-cs182.github.io/fa25/index.htmlpdf of course textbookExample of backtracking and knowledge retrieval:Trace Link: https://chatgpt.com/share/6908ff92-7774-8000-a975-b454a614f6ceTogether with the project prompt and chat prompt, ChatGPT project mode retrieves my earlier conversation threads (e.g., HW 8 questions like “in unstructured W, why is recurrence faster on CPU?” and “diagW = torch.diag(W) — what does it do?”) and composes a factual summary table.How classmates can reproduce (bullet list):Create a ChatGPT project for EECS 182/282A and paste the prompt above.Tag threads as Hw #, Dis #, Week #; keep each question atomic.After sessions, ask for a chronological project summary with the rule “no invention—mark not recorded when missing.”Why it helps:Turns scattered chats into structured, dated rows for HW/Dis/Week.Makes past findings searchable (e.g., what you asked 3 weeks ago when you were watching that week's lecture).Reduces review time during finals by providing a durable “cache layer” that complements handwritten notes.Comments:Positives (What Worked Well):Provides a systematic and personal way to track conceptual and coding progress across lectures, discussions, and homework.Enables quick summarization of recurring pain points — e.g., topics repeatedly causing confusion (like SSM recurrence vs convolution).Works as a universal workflow, not just for EECS 182, but adaptable to other classes, research projects, or long-term commitments.Negatives (Limitations and Effort Required):Requires manual setup and consistent thread naming (e.g., “Hw 1”, “Dis 3”), which takes discipline and time.If unrelated conversations are accidentally mixed into the project, they can poison the context, causing noisy or misleading summaries.Future Improvements:Explore context condensation techniques — controlling the length and quality of how AI responds even during normal chat sessions so later reviews are cleaner.Organize from the start: define thread templates (e.g., “Concept | Question | Key Takeaway”) to ensure consistent retrievability.Possibly integrate automated tagging or scripts to rename threads and prevent context contamination.Over time, this could evolve into a lightweight personal learning management system --  one that adapts as the AI learns your workflow.", "resources": [{"type": "link", "url": "https://berkeley-cs182.github.io/fa25/index.html", "name": "Link"}, {"type": "link", "url": "https://chatgpt.com/share/6908ff92-7774-8000-a975-b454a614f6ce", "name": "Link"}, {"type": "link", "url": "https://berkeley-cs182.github.io/fa25/index.htmlpdf", "name": "Raw Text Link"}, {"type": "link", "url": "https://chatgpt.com/share/6908ff92-7774-8000-a975-b454a614f6ceTogether", "name": "Raw Text Link"}], "tags": ["Coding", "Study Guide", "Visualization", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7249252"}, {"id": 7240163, "title": "Special Participation E: Quiz and Flash Cards for Adam / SGD", "date": "2025-11-02T10:39:47.878068+11:00", "author": "Andy Zhang", "content": "Special Participation E: Quiz and Flash Cards for Adam / SGDFor background, Gemini claims that they can create quizzes, flash cards & study guides according to https://support.google.com/gemini/answer/16275879?hl=en&co=GENIE.Platform%3DAndroidEspecially since Gemini Pro is free for Berkeley students, I first explored and confirmed that Gemini could indeed create those; it created specific and specialized artifacts for only Quizzes and Flash Cards (and you need to be careful about language) which made it more convenient than text.While the initial the quiz and flash cards were reasonable, they are generally conceptual (e.g. the purpose of the first and second moments of Adam, the purpose of hyperparameters etc.) so I wanted to explore whether the quizzes and flash cards could be more mathematical and cover more rigor similar to our course and see whether latex could properly render in the quiz and flash cards.From there I was able to develop an improved prompt to have more mathematics to be more aligned with our course, formatted properly in latex. And depending on one’s presences, the model can be steered to act accordingly. My recommendation is that these could be helpful to students to review concepts such as Adam and SGD especially after several weeks have passed before the final. My recommended order is to go through the flash cards for a memory refresher and then take the quiz to ensure the concepts are cemented.Traces with detailed comments: https://drive.google.com/file/d/1X6M9JPHW4GRSUKRFckDdFsxYcfWyB-97/view?usp=sharingIndividual traces:Undetailed Prompt Trace Flash Cards:https://gemini.google.com/share/ed66de185158Undetailed Prompt Trace Quiz:https://gemini.google.com/share/598e4b5cfbccUndetailed Flash Cards:https://gemini.google.com/share/cfd44ed946d6Undetailed Quiz:https://gemini.google.com/share/6fab8238136eFlash cards / quizzes:Detailed Prompt Trace for Flash Cards with Math:https://gemini.google.com/share/f7957da6c0d1Detailed Prompt Trace for Quiz:https://gemini.google.com/share/ec87b322ca7eDetailed Flash Cards: https://gemini.google.com/share/6afed4acff7bDetailed Quiz: https://gemini.google.com/share/01910a14266a", "resources": [{"type": "link", "url": "https://support.google.com/gemini/answer/16275879?hl=en&co=GENIE.Platform%3DAndroid", "name": "Link"}, {"type": "link", "url": "https://gemini.google.com/share/ed66de185158", "name": "Link"}, {"type": "link", "url": "https://gemini.google.com/share/598e4b5cfbcc", "name": "Link"}, {"type": "link", "url": "https://gemini.google.com/share/cfd44ed946d6", "name": "Link"}, {"type": "link", "url": "https://gemini.google.com/share/6fab8238136e", "name": "Link"}, {"type": "link", "url": "https://gemini.google.com/share/f7957da6c0d1", "name": "Link"}, {"type": "link", "url": "https://gemini.google.com/share/ec87b322ca7e", "name": "Link"}, {"type": "link", "url": "https://gemini.google.com/share/6afed4acff7b", "name": "Link"}, {"type": "link", "url": "https://gemini.google.com/share/01910a14266a", "name": "Link"}, {"type": "link", "url": "https://support.google.com/gemini/answer/16275879?hl=en&co=GENIE.Platform%3DAndroidEspecially", "name": "Raw Text Link"}, {"type": "link", "url": "https://drive.google.com/file/d/1X6M9JPHW4GRSUKRFckDdFsxYcfWyB-97/view?usp=sharingIndividual", "name": "Raw Text Link"}, {"type": "link", "url": "https://gemini.google.com/share/ed66de185158Undetailed", "name": "Raw Text Link"}, {"type": "link", "url": "https://gemini.google.com/share/598e4b5cfbccUndetailed", "name": "Raw Text Link"}, {"type": "link", "url": "https://gemini.google.com/share/cfd44ed946d6Undetailed", "name": "Raw Text Link"}, {"type": "link", "url": "https://gemini.google.com/share/6fab8238136eFlash", "name": "Raw Text Link"}, {"type": "link", "url": "https://gemini.google.com/share/f7957da6c0d1Detailed", "name": "Raw Text Link"}, {"type": "link", "url": "https://gemini.google.com/share/ec87b322ca7eDetailed", "name": "Raw Text Link"}, {"type": "link", "url": "https://gemini.google.com/share/6afed4acff7bDetailed", "name": "Raw Text Link"}], "tags": ["Study Guide", "Quiz/Drill", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7240163"}, {"id": 7227336, "title": "Special Participation E: How I used Google NotebookLM to understand SSM", "date": "2025-10-30T15:55:36.861101+11:00", "author": "Anders Vestrum", "content": "Special Participation E (Google NotebookLM) - RNNs and SSMsI used Google NotebookLM as a guided tutor to study the relationship between State-Space Models (SSMs) and Recurrent Neural Networks (RNNs), using EECS 182 materials and the S4 paper. Through its Learning Guide mode, the system’s questions helped me understand how SSMs convert sequential recurrence into FFT-based convolution and how diagonalization combined with the Woodbury Matrix Identity makes the S4 model both efficient and stable. I noted one factual correction: the chatbot listed the FFT cost as O(N·L log L), but standard FFT convolution parallelizes across time, giving O(L log L) instead. The session also introduced Ridge-Attention, illustrating how it reframes self-attention from a probabilistic softmax view to a linear-algebraic one.NotebookLM link (video, mind map, quiz, and flashcards in this link: https://notebooklm.google.com/notebook/1da24f39-d172-4725-a38c-5f6366e8ac95", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/bDTJCfOluen1y8BEHkKwa2Ee", "name": "spE_notebookLM_RNN_SSM.pdf"}, {"type": "link", "url": "https://notebooklm.google.com/notebook/1da24f39-d172-4725-a38c-5f6366e8ac95", "name": "Raw Text Link"}], "tags": ["Tutor", "Study Guide", "Quiz/Drill"], "original_url": "https://edstem.org/us/courses/84647/discussion/7227336"}, {"id": 7226661, "title": "Special participation E: Create a custom version of chatGPT,  μP & Modern Optimizers Coach", "date": "2025-10-30T13:40:12.723427+11:00", "author": "Noah Lund Syrdal", "content": "Link: μP & Modern Optimizers CoachPdf: Extensive summary:This custom GPT acts as an interactive study companion for μP scaling, RMSNorm, and modern optimizers.It’s a great way to ask questions about concepts you don’t fully understand. I’ve stress-tested it on common misconceptions about μP invariance, and it consistently provided nuanced, well-grounded answers (tried to get a wrong answer out of it, didn’t manage).You can use my version directly, or follow the steps in the PDF to create your own tailored model on a different concept.It works well both as a pre-lecture active reading tool and a post-lecture review partner; you can even talk with it out loud while learning.I would strongly recommend this approach for anyone in the course. I’ll be creating similar custom GPTs for other core concepts in 182/282 and eventually one that covers the entire course, to explore how well it can guide learning across all modules.", "resources": [{"type": "link", "url": "https://chatgpt.com/g/g-68f2b5f669148191915a03ef03fc69d6-mp-modern-optimizers-coach-eecs182-282", "name": "μP & Modern Optimizers Coach"}, {"type": "file", "url": "https://static.us.edusercontent.com/files/AB1TpLpivYeHk0yo44YDkb3m", "name": "Special_Participation_E-3.pdf"}], "tags": ["Tool/App", "Tutor", "Study Guide"], "original_url": "https://edstem.org/us/courses/84647/discussion/7226661"}, {"id": 7215058, "title": "Special Participation E: Claude Study \"Buddy\"", "date": "2025-10-28T17:20:38.187029+11:00", "author": "Bruno Vieira", "content": "I used Claude's study feature to use it as a study \"buddy\". I pretended to be studying for an exam, trying to review content, and study for a specific topic via pre-lecture notes all using Claude to guide my studies.I started out with this map to see if it could connect all the topics from this class into a graph and assess the relationships between them. Below is the trace with all my comments! Hope this is helpful and happy studying.", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/kFuAKFCnfFtJk8o3u8FVRZpS", "name": "Claude Trace Study Buddy.pdf"}, {"type": "image", "url": "https://static.us.edusercontent.com/files/Eudu0uIW4L6ppMkzDd9hcPgz", "name": "Image"}], "tags": ["Tool/App", "Study Guide", "Visualization"], "original_url": "https://edstem.org/us/courses/84647/discussion/7215058"}, {"id": 7159164, "title": "Special Participation E: A Comprehensive Tutorial for Literature Review", "date": "2025-10-20T08:36:06.64917+11:00", "author": "Yuxiang Liu", "content": "Before we get started with the literature review of the final project, I think it would be worthwhile to spend 5 minutes studying about some sensible ways of applying LLMs for the purpose of literature searching. The link below is one of my personal blogs which concludes a recipe of useful tricks that will help you coorporate with LLMs more smoothly and efficiently when doing deep research :D This blog includes advice from some experienced researchers as well as my personal suggestions. If you have any other valuable insights, feel free to leave a comment here!https://xiang-foothill.github.io/personal-website/blog/make-ai-your-best-assistant.html", "resources": [{"type": "link", "url": "https://xiang-foothill.github.io/personal-website/blog/make-ai-your-best-assistant.html", "name": "Raw Text Link"}], "tags": ["Tool/App", "Tutor", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7159164"}, {"id": 7092540, "title": "Special Participation E: Learning Mode as an Effective Step By Step Tutor", "date": "2025-10-08T11:57:35.487299+11:00", "author": "Andy Zhang", "content": "Special Participation E: Learning Mode as an Effective Step By Step TutorGemini Learning Mode: https://g.co/gemini/share/4e1faf6d804cGemini Non-Learning Mode: https://g.co/gemini/share/c6ce8062f1d6ChatGPT Learning Mode: https://chatgpt.com/share/68e6a057-981c-800b-b06d-2b65a8332d36ChatGPT Non-Learning Mode: https://chatgpt.com/share/68e6bd6d-f24c-800b-a8ba-96be1e554c78Recommendation:I would recommend fellow students to leverage Gemini / ChatGPT learning mode to go through problems in piece meal step by step fashion with a guided tutor. This may be helpful after completing a homework, noticing a discrepancy with the solutions, and deciding to go through the homework again with some guidance to build a stronger understanding. ChatGPT is more helpful if you’re concerned about reward hacking, but Berkeley students have free Gemini Pro which may favor that since it’s easy to hit usage limits with ChatGPT.The learning modes are effective tools for breaking down problems into piecemeal parts, as opposed to generating the entire solution in one go.Executive summary:I was interested in investigating the extent to which Guided Learning modes could help. I experimented with Gemini and ChatGPT which are the two models with learning modes available for free (in contrast, Claude’s learning mode is not accessible). I tested two different problems on two different homework assignments for Gemini and ChatGPT, and experimented with learning and non-learning modes.For Gemini Learning Mode, I was initially curious (1) to what extent it could help guide learning (2) whether it would break things down piece meal (3) how well it would handle latex formatting (4) whether it could produce new insights and (5) whether there would be reward hacking.I applied it to HW0 Vector Calculus Review a-e.For (1-3) it performed admirably, though it did fail to format one part of one response. (4) was more of an issue; I prompted the model to “help me view the problem from the different lenses of vector calculus, and walk through both elementwise, rowwise, columnwise, and examples” and it failed to do so.(5) is a significant concern. If you ask for the answer, it will provide it. In fact, simply asking “Formatting messed up” led to “You correctly calculated the three partial derivatives! That was the toughest part.”My observation is that guided learning is trained on successful learning traces and does not handle incorrect/out of distribution inputs well (and infers it as correct).Also interestingly it converted the questions from a “Show X = Y” to “What is derivative of X”, which could be a plus or minus depending on your use case (in a way, not knowing the answer could be helpful).One nice note is that after the problems were complete, it suggested additional questions, which may be useful for additional practice.In contrast, Gemini directly answered all the parts when not in learning mode which could feel overwhelming.For ChatGPT learning mode, it performed similarly to Gemini, though had the advantage of not simply giving the answer / getting reward hacked. However, Berkeley students have free Gemini Pro which may favor that since it’s easy to hit usage limits with ChatGPT.Similarly without learning mode, it answered all parts which could be overwhelming.", "resources": [{"type": "link", "url": "https://g.co/gemini/share/4e1faf6d804c", "name": "Link"}, {"type": "link", "url": "https://g.co/gemini/share/c6ce8062f1d6", "name": "Link"}, {"type": "link", "url": "https://chatgpt.com/share/68e6a057-981c-800b-b06d-2b65a8332d36", "name": "Link"}, {"type": "link", "url": "https://chatgpt.com/share/68e6bd6d-f24c-800b-a8ba-96be1e554c78", "name": "Link"}, {"type": "link", "url": "https://g.co/gemini/share/4e1faf6d804cGemini", "name": "Raw Text Link"}, {"type": "link", "url": "https://g.co/gemini/share/c6ce8062f1d6ChatGPT", "name": "Raw Text Link"}, {"type": "link", "url": "https://chatgpt.com/share/68e6a057-981c-800b-b06d-2b65a8332d36ChatGPT", "name": "Raw Text Link"}, {"type": "link", "url": "https://chatgpt.com/share/68e6bd6d-f24c-800b-a8ba-96be1e554c78Recommendation:I", "name": "Raw Text Link"}], "tags": ["Tool/App", "Study Guide", "Prompt Eng", "Tutor", "Math"], "original_url": "https://edstem.org/us/courses/84647/discussion/7092540"}, {"id": 7030840, "title": "Special Participation E: ChatGPT as Quiz Tutor", "date": "2025-09-28T11:42:41.568091+10:00", "author": "Nyx Iskandar", "content": "Trace: https://chatgpt.com/share/68d891e8-3f3c-8010-8f9f-edd2aff1297bPrompted ChatGPT to teach me the CNN architecture step-by-step and quiz me after each concept. Pretty fun and useful as a lecture prep or consolidation! Can also extend this to uploading lecture notes and quizzing based on the notes.", "resources": [{"type": "link", "url": "https://chatgpt.com/share/68d891e8-3f3c-8010-8f9f-edd2aff1297b", "name": "Link"}, {"type": "link", "url": "https://chatgpt.com/share/68d891e8-3f3c-8010-8f9f-edd2aff1297bPrompted", "name": "Raw Text Link"}], "tags": ["Tutor", "Study Guide", "Quiz/Drill", "Prompt Eng"], "original_url": "https://edstem.org/us/courses/84647/discussion/7030840"}, {"id": 7027430, "title": "Special Participation E: FlashcardGPT", "date": "2025-09-27T15:47:18.640074+10:00", "author": "Nyx Iskandar", "content": "Use FlashcardGPT to generate flashcards out of lecture notes etc. :)URL: https://github.com/xyntechx/flashcard-gptFull disclosure:I made this app in about 3 hours + I'm not the best designerYou have to run this locally (follow the instructions in the README)You need to use your own OpenAI API keys (sorry haha)When I was testing this, I used a pre-generated set of flashcards so that it won't take too long, and to save API credits, which is why the demo is 🔥 blazingly fast 🔥. The flashcards were indeed generated by GPT-5.Open to feature requests / issues / PRs!", "resources": [{"type": "file", "url": "https://static.us.edusercontent.com/files/2GNHHP8zSUbCiuZhzkvmJvoo", "name": "Screen Recording 2025-09-26 at 22.34.08.mov"}, {"type": "link", "url": "https://github.com/xyntechx/flashcard-gptFull", "name": "Raw Text Link"}], "tags": ["Tool/App", "Study Guide", "Quiz/Drill"], "original_url": "https://edstem.org/us/courses/84647/discussion/7027430"}];
    </script>
    <script>
        let allPosts = [];
        let filteredPosts = [];
        let selectedTags = new Set();
        let allTags = new Set();

        // Load posts from embedded JSON data
        function loadPosts() {
            try {
                // Use embedded JSON data from posts_data.js
                allPosts = POSTS_DATA;
                filteredPosts = allPosts;
                
                // Collect all unique tags
                allPosts.forEach(post => {
                    if (post.tags) {
                        post.tags.forEach(tag => allTags.add(tag));
                    }
                });

                // Sort posts by date (newest first)
                filteredPosts.sort((a, b) => new Date(b.date) - new Date(a.date));

                renderTagFilters();
                renderPosts();
                updateStats();
                document.getElementById('controls').style.display = 'flex';
                document.getElementById('loading').style.display = 'none';
            } catch (error) {
                console.error('Error loading posts:', error);
                document.getElementById('loading').textContent = 'Error loading posts.';
            }
        }

        // Render tag filter buttons
        function renderTagFilters() {
            const tagFilter = document.getElementById('tagFilter');
            tagFilter.innerHTML = '';
            
            const sortedTags = Array.from(allTags).sort();
            sortedTags.forEach(tag => {
                const button = document.createElement('button');
                button.className = 'tag-button';
                button.textContent = tag;
                button.addEventListener('click', () => toggleTag(tag));
                tagFilter.appendChild(button);
            });
        }

        // Toggle tag filter
        function toggleTag(tag) {
            if (selectedTags.has(tag)) {
                selectedTags.delete(tag);
            } else {
                selectedTags.add(tag);
            }
            
            // Update button appearance
            document.querySelectorAll('.tag-button').forEach(btn => {
                if (btn.textContent === tag) {
                    btn.classList.toggle('active', selectedTags.has(tag));
                }
            });
            
            filterPosts();
        }

        // Filter posts based on search and tags
        function filterPosts() {
            const searchTerm = document.getElementById('searchInput').value.toLowerCase();
            
            filteredPosts = allPosts.filter(post => {
                // Search filter
                const matchesSearch = !searchTerm || 
                    post.title.toLowerCase().includes(searchTerm) ||
                    post.author.toLowerCase().includes(searchTerm) ||
                    post.content.toLowerCase().includes(searchTerm);
                
                // Tag filter
                const matchesTags = selectedTags.size === 0 || 
                    (post.tags && post.tags.some(tag => selectedTags.has(tag)));
                
                return matchesSearch && matchesTags;
            });
            
            // Sort by date
            filteredPosts.sort((a, b) => new Date(b.date) - new Date(a.date));
            
            renderPosts();
            updateStats();
        }

        // Update stats
        function updateStats() {
            const stats = document.getElementById('stats');
            stats.textContent = `Showing ${filteredPosts.length} of ${allPosts.length} posts`;
        }

        // Format date
        function formatDate(dateString) {
            const date = new Date(dateString);
            return date.toLocaleDateString('en-US', { 
                year: 'numeric', 
                month: 'short', 
                day: 'numeric',
                hour: '2-digit',
                minute: '2-digit'
            });
        }

        // Render posts
        function renderPosts() {
            const container = document.getElementById('postsContainer');
            
            if (filteredPosts.length === 0) {
                container.innerHTML = '<div class="no-results">No posts found matching your filters.</div>';
                return;
            }
            
            container.innerHTML = filteredPosts.map(post => {
                const tags = post.tags || [];
                const resources = post.resources || [];
                
                return `
                    <div class="post-card">
                        <div class="post-header">
                            <h2 class="post-title">
                                <a href="${post.original_url}" target="_blank">${escapeHtml(post.title)}</a>
                            </h2>
                            <div class="post-meta">
                                <span>👤 ${escapeHtml(post.author)}</span>
                                <span>📅 ${formatDate(post.date)}</span>
                            </div>
                            ${tags.length > 0 ? `
                                <div class="post-tags">
                                    ${tags.map(tag => `<span class="tag">${escapeHtml(tag)}</span>`).join('')}
                                </div>
                            ` : ''}
                        </div>
                        <div class="post-content">
                            <div class="post-content-preview">${escapeHtml(post.content)}</div>
                        </div>
                        ${resources.length > 0 ? `
                            <div class="post-resources">
                                <h4>Resources:</h4>
                                <div class="resource-list">
                                    ${resources.map(resource => `
                                        <a href="${escapeHtml(resource.url)}" target="_blank" class="resource-link">
                                            ${resource.type === 'link' ? '🔗' : resource.type === 'file' ? '📄' : '🖼️'}
                                            ${escapeHtml(resource.name)}
                                        </a>
                                    `).join('')}
                                </div>
                            </div>
                        ` : ''}
                    </div>
                `;
            }).join('');
        }

        // Escape HTML to prevent XSS
        function escapeHtml(text) {
            const div = document.createElement('div');
            div.textContent = text;
            return div.innerHTML;
        }

        // Event listeners
        document.getElementById('searchInput').addEventListener('input', filterPosts);

        // Load posts on page load
        loadPosts();
    </script>
</body>
</html>

